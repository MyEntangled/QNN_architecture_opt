{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218f9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from qiskit  import Aer, QuantumCircuit\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.opflow import AerPauliExpectation\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN, TwoLayerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "# Additional torch-related imports\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (Module, Conv2d, Linear, Dropout2d, NLLLoss,\n",
    "                     MaxPool2d, Flatten, Sequential, ReLU)\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "\n",
    "\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '/Users/trongduong/Dropbox/URP project/Code/PQC_Composer')\n",
    "from utility.quantum_nn import  QuantumNeuralNetwork\n",
    "from utility.ansatz_template import AnsatzTemplate\n",
    "from utility.data_encoding import FeatureMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa54982b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-baf0a862f098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mHybridFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\" Hybrid quantum - classical function definition \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_qubits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mansatz_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Function' is not defined"
     ]
    }
   ],
   "source": [
    "class HybridFunction(Function):\n",
    "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, batch_data, param, model, observable):\n",
    "        \"\"\" Forward pass computation \"\"\"\n",
    "        \n",
    "        ctx.batch_data = batch_data\n",
    "        ctx.model = model\n",
    "        ctx.observable = observable\n",
    "        \n",
    "        num_inputs = batch_data.shape[0]\n",
    "        grid_inputs = batch_data.toarray()\n",
    "        grid_params = np.tile(param.toarray(),(num_inputs,1))\n",
    "        \n",
    "        if isinstance(ctx.observable, str):\n",
    "            obs = ctx.observable\n",
    "        else:\n",
    "            obs = [ctx.observable]\n",
    "        \n",
    "                \n",
    "        exp_results = ctx.model.forward(grid_inputs, grid_params, observables=[ctx.observable])\n",
    "\n",
    "        result = torch.tensor(exp_results).to(device)\n",
    "\n",
    "        ctx.save_for_backward(param, result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\" Backward pass computation \"\"\"\n",
    "\n",
    "        param, result = ctx.saved_tensors\n",
    "        param_array = param.toarray()\n",
    "        batch_data_array = ctx.batch_data.toarray()\n",
    "        \n",
    "        if isinstance(ctx.observable, str):\n",
    "            obs = ctx.observable\n",
    "        else:\n",
    "            obs = [ctx.observable]\n",
    "        \n",
    "        \n",
    "        _, num_params = params_array.shape\n",
    "        gradients = ctx.model.get_gradients(grid_inputs, grid_params, observables=[ctx.observable])\n",
    "        \n",
    "        \n",
    "        gradients = torch.tensor(gradients.reshape(ctx.batch_data.shape[0], num_params)).to(device)\n",
    "        \n",
    "        return None, None, gradients.float() * grad_output.float(), None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08860049",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid(nn.Module):\n",
    "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits, k_qubits, layers, ansatz_id, test, backend, shots, shift):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.autoencoder = AutoencoderQuantumCircuit(n_qubits, k_qubits, layers, ansatz_id, backend=backend, shots=shots)\n",
    "        self.shift = shift\n",
    "        self.ansatz_id = ansatz_id\n",
    "        self.test = test\n",
    "        \n",
    "        self.num_qubits = n_qubits + k_qubits\n",
    "        if ansatz_id == 6:\n",
    "            self.num_params = (self.num_qubits ** 2 + 3*self.num_qubits) * layers\n",
    "        elif ansatz_id == 9:\n",
    "            self.num_params = self.num_qubits * layers\n",
    "        else:\n",
    "            raise Exception(\"Invalid circuit ID\")\n",
    "        \n",
    "        self.params = nn.Parameter(data=torch.rand((1,self.num_params), dtype=torch.float), requires_grad=True)\n",
    "        \n",
    "    def forward(self, batch_data):\n",
    "        return HybridFunction.apply(batch_data, self.num_qubits, self.params, self.ansatz_id, self.test, self.autoencoder, self.shift)b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_qubits, k_qubits, layers, ansatz_id=None, test='Hadamard', backend=provider.get_backend(\"ibmq_qasm_simulator\"), shots=100, shift=np.pi / 2):\n",
    "        super(Net, self).__init__()\n",
    "        self.hybrid = Hybrid(n_qubits,k_qubits,layers,\n",
    "                             ansatz_id, test,\n",
    "                             backend=backend,\n",
    "                             shots=shots,\n",
    "                             shift=shift)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"1: \", x.shape)\n",
    "        x = self.hybrid(x.detach())\n",
    "        #print(\"2: \", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01bcab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLoss(output, weight=None):\n",
    "    if weight is None:\n",
    "        weight = np.ones(len(output)) / len(output)\n",
    "    else:\n",
    "        assert type(weight) == np.ndarray\n",
    "        assert weight.shape == (len(outputs),)\n",
    "        assert sum(weight) == 1\n",
    "        \n",
    "    #print(\"FLoss output = {}\".format(output))\n",
    "    weight = torch.tensor(weight.reshape(len(output),1)).to(device)\n",
    "    loss = 1 - torch.sum(output * weight)\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:QML2] *",
   "language": "python",
   "name": "conda-env-QML2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
