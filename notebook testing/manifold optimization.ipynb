{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea0a3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a5b6143c164513b5503fc401a146fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97be2252c08b4ec3a875b852049f9de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfdddffb0159434a89de62dfbb748131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a656bbdc55c45cdb8f71da0b2eca5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True, num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8325e87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e068a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle Boot  T-shirt/top  Coat  Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d71ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.parametrizations import orthogonal\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.fc4 = orthogonal(nn.Linear(10,10, dtype=torch.cfloat))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e3541193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9392, 0.6962, 0.8568, 0.6395, 0.9127, 0.3396, 0.1583, 0.2288, 0.4228,\n",
      "         0.0489],\n",
      "        [0.2102, 0.3838, 0.4192, 0.2881, 0.8776, 0.3203, 0.0988, 0.5116, 0.7079,\n",
      "         0.3995],\n",
      "        [0.2191, 0.9446, 0.9149, 0.0649, 0.6703, 0.5750, 0.9754, 0.0385, 0.0947,\n",
      "         0.2632],\n",
      "        [0.8200, 0.2511, 0.6460, 0.2973, 0.1401, 0.1723, 0.4637, 0.8902, 0.8790,\n",
      "         0.2816]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.331254720687866\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d9fcb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "472bf505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70e22ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.6806668536812066\n",
      "  batch 2000 loss: 0.8273845522720367\n",
      "  batch 3000 loss: 0.6791668776478619\n",
      "  batch 4000 loss: 0.6176750096506439\n",
      "  batch 5000 loss: 0.6179355203490704\n",
      "  batch 6000 loss: 0.5460427628748584\n",
      "  batch 7000 loss: 0.5196379040140892\n",
      "  batch 8000 loss: 0.5030153584796936\n",
      "  batch 9000 loss: 0.4932342100144015\n",
      "  batch 10000 loss: 0.47388212477834896\n",
      "  batch 11000 loss: 0.46093765488266947\n",
      "  batch 12000 loss: 0.4346990059631062\n",
      "  batch 13000 loss: 0.43531280183733906\n",
      "  batch 14000 loss: 0.4270411509666592\n",
      "  batch 15000 loss: 0.4312904790651519\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k7/xbg0txh97kb_tz_4gnqjl7cm0000gn/T/ipykernel_82776/1661848607.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Make sure gradient tracking is on, and do a pass over the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# We don't need gradients on to do reporting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/k7/xbg0txh97kb_tz_4gnqjl7cm0000gn/T/ipykernel_82776/3515542111.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch_index, tb_writer)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# iter(training_loader) so that we can track the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# index and do some intra-epoch reporting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Every data instance is an input + label pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/QML/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/QML/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0;31m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/QML/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                     \u001b[0;31m# wrong, we set a timeout and if the workers fail to join,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                     \u001b[0;31m# they are killed in the `finally` block.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m                     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_join_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/QML/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/QML/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/QML/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/QML/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6805b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('conv1.weight', Parameter containing:\n",
      "tensor([[[[-0.1093, -0.3171, -0.3943, -0.3184, -0.2577],\n",
      "          [ 0.0076, -0.1184, -0.3599, -0.4771, -0.2750],\n",
      "          [ 0.1886,  0.0881, -0.1252, -0.2308, -0.0442],\n",
      "          [ 0.1691,  0.1386,  0.1533,  0.0881,  0.2115],\n",
      "          [ 0.1532, -0.0469, -0.0805,  0.0945,  0.0597]]],\n",
      "\n",
      "\n",
      "        [[[-0.0746, -0.1390,  0.0094, -0.3348, -0.1648],\n",
      "          [ 0.0068, -0.1851, -0.0846, -0.2756, -0.0712],\n",
      "          [-0.1325,  0.0941, -0.0090,  0.1103,  0.1251],\n",
      "          [ 0.1739,  0.1540,  0.0952,  0.2769, -0.2566],\n",
      "          [ 0.1633,  0.4004,  0.2180,  0.2609, -0.3142]]],\n",
      "\n",
      "\n",
      "        [[[-0.0277, -0.0171, -0.1490, -0.1711, -0.0455],\n",
      "          [ 0.1902,  0.0845, -0.1242, -0.2292, -0.1663],\n",
      "          [ 0.0036, -0.0539, -0.1620,  0.0131,  0.1351],\n",
      "          [-0.2558, -0.3964, -0.3812, -0.1733,  0.1304],\n",
      "          [-0.2008, -0.3143, -0.2151, -0.2177,  0.0506]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2211,  0.2519,  0.0181, -0.6498, -0.2602],\n",
      "          [ 0.2079,  0.3253,  0.0387, -0.5807, -0.1896],\n",
      "          [ 0.2743,  0.5289,  0.0184, -0.3942, -0.1010],\n",
      "          [-0.0559,  0.3602,  0.2971, -0.4146, -0.0383],\n",
      "          [ 0.0269,  0.1277,  0.3011, -0.4306,  0.0148]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2304,  0.0185, -0.0685, -0.1835,  0.0031],\n",
      "          [ 0.0151,  0.0662, -0.0180,  0.0206,  0.0498],\n",
      "          [-0.2955, -0.2550, -0.3880, -0.0631,  0.2075],\n",
      "          [-0.1434, -0.2609, -0.1593,  0.1124,  0.1402],\n",
      "          [ 0.0706, -0.1011, -0.0818,  0.0430,  0.1145]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0588, -0.0635, -0.1575,  0.3206,  0.0959],\n",
      "          [ 0.2687, -0.0509, -0.3967,  0.1922,  0.1739],\n",
      "          [ 0.2707, -0.0596, -0.2928, -0.0756,  0.1028],\n",
      "          [ 0.1687,  0.1765, -0.3999,  0.1500, -0.1859],\n",
      "          [ 0.2872,  0.1362, -0.4439, -0.0712,  0.1175]]]], requires_grad=True))\n",
      "('conv1.bias', Parameter containing:\n",
      "tensor([-0.4428,  0.1912, -0.3371,  0.0514, -0.1972, -0.0077],\n",
      "       requires_grad=True))\n",
      "('conv2.weight', Parameter containing:\n",
      "tensor([[[[-2.4236e-02, -2.4783e-02,  8.9100e-02,  1.5684e-01, -5.6348e-02],\n",
      "          [-2.2697e-02, -1.0178e-01,  9.9667e-02,  1.2155e-01, -3.0350e-02],\n",
      "          [ 2.4885e-02, -1.2020e-01,  6.3784e-02, -4.5549e-02, -1.4442e-02],\n",
      "          [-5.3975e-02, -2.3559e-02,  1.9664e-02, -6.4120e-02, -1.3228e-01],\n",
      "          [-2.1175e-02,  1.2155e-01,  8.6840e-03,  4.2157e-02, -6.3267e-02]],\n",
      "\n",
      "         [[-6.1400e-02, -4.5554e-02,  2.8295e-02, -2.7507e-02, -4.7658e-02],\n",
      "          [ 8.9078e-02, -4.3172e-02,  3.5778e-03,  6.7281e-02,  1.0168e-01],\n",
      "          [ 6.7972e-02, -1.7143e-02,  1.7450e-02,  5.2759e-02,  9.5514e-02],\n",
      "          [ 7.4946e-02, -6.3463e-02, -8.3926e-04,  2.8310e-02,  8.6690e-02],\n",
      "          [ 2.6667e-02, -5.0989e-02,  6.4862e-02, -5.5157e-02,  5.7699e-02]],\n",
      "\n",
      "         [[ 2.1490e-02, -1.6310e-01, -4.5403e-02,  1.6133e-01, -2.1268e-02],\n",
      "          [ 2.7413e-02, -5.4874e-02, -1.0156e-01, -3.0992e-02, -5.2408e-02],\n",
      "          [-4.4468e-02, -3.4163e-02,  4.4056e-02,  9.1585e-02, -1.1977e-01],\n",
      "          [ 1.0760e-01,  4.0448e-02,  5.3720e-02,  1.1345e-02, -1.1875e-01],\n",
      "          [ 1.4647e-02,  4.1609e-02, -4.5305e-02,  3.5055e-02,  6.1244e-04]],\n",
      "\n",
      "         [[-8.1618e-02,  4.2343e-02,  2.4137e-01,  8.5903e-02, -1.8362e-01],\n",
      "          [-2.9421e-02,  8.8274e-02,  1.9215e-01,  1.5674e-02, -9.9451e-02],\n",
      "          [ 6.1691e-02, -5.1404e-02,  6.6986e-02, -6.9542e-02, -5.5262e-02],\n",
      "          [ 1.6322e-01, -1.1673e-02, -2.9830e-02, -8.1029e-02, -2.7129e-02],\n",
      "          [ 1.5724e-01, -4.3884e-02,  7.0095e-02, -8.1303e-02, -1.1402e-01]],\n",
      "\n",
      "         [[ 1.3342e-02, -1.2784e-01, -3.0202e-02,  1.5757e-02,  7.5514e-02],\n",
      "          [-1.5956e-02, -1.0735e-02, -7.1471e-02,  7.7302e-02, -6.1380e-03],\n",
      "          [-5.0482e-02, -9.2621e-02,  2.9654e-02,  1.1663e-01,  2.3047e-02],\n",
      "          [-6.5576e-02,  8.2862e-02,  9.0644e-02,  5.9453e-02, -7.0656e-02],\n",
      "          [ 1.1092e-02,  1.3622e-04, -2.1708e-02,  1.0648e-02, -1.1484e-02]],\n",
      "\n",
      "         [[ 7.6055e-02,  3.7877e-02,  8.4246e-02,  7.3908e-02,  1.7787e-02],\n",
      "          [ 9.5432e-02,  1.5332e-01, -4.1973e-02, -5.7081e-02,  7.3056e-02],\n",
      "          [-7.5310e-02,  3.9129e-02,  1.2109e-01, -1.8216e-03, -7.1497e-02],\n",
      "          [ 4.9229e-02,  6.6549e-02,  2.2465e-02,  3.9210e-02, -6.0229e-02],\n",
      "          [ 3.4589e-02,  2.0096e-01,  8.3809e-02, -3.0826e-03, -6.6714e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3737e-02,  4.2369e-02, -7.9204e-02, -1.6721e-01, -1.0147e-01],\n",
      "          [-3.3621e-03,  9.1578e-02, -3.3052e-02, -6.5367e-02, -2.9911e-02],\n",
      "          [-7.7905e-03,  9.0149e-02, -3.0480e-02,  4.4184e-02,  2.0825e-02],\n",
      "          [-7.3477e-02,  3.1551e-02, -5.5965e-02, -8.0028e-02,  7.2024e-02],\n",
      "          [ 4.9017e-03, -3.1668e-02, -8.9554e-02, -2.9929e-02,  4.6222e-02]],\n",
      "\n",
      "         [[ 1.8014e-03,  8.8117e-02, -6.5988e-02, -9.4298e-02,  4.2923e-02],\n",
      "          [-5.6511e-02,  4.0377e-02, -8.0779e-02, -6.9340e-02, -9.1183e-03],\n",
      "          [-8.3652e-02,  6.2870e-02, -4.3498e-02, -7.5802e-02, -1.5306e-02],\n",
      "          [-4.0085e-02,  1.7186e-02,  9.7306e-02, -5.8518e-02, -4.5584e-02],\n",
      "          [-6.5701e-03,  4.8869e-02,  9.2522e-02,  4.1985e-02, -6.0442e-02]],\n",
      "\n",
      "         [[ 6.0258e-02,  5.6993e-02,  1.1519e-02, -3.6566e-02, -1.0747e-01],\n",
      "          [ 1.0291e-01, -5.0754e-02,  4.9930e-02,  9.4319e-03, -3.0875e-02],\n",
      "          [-6.9549e-02, -5.3910e-02,  6.8147e-02, -5.4386e-02, -3.7270e-02],\n",
      "          [-3.5665e-02,  5.5336e-02,  1.8320e-02, -4.8040e-02, -2.7703e-02],\n",
      "          [-1.3660e-01, -1.2453e-01, -4.8949e-02,  5.5352e-02,  1.1479e-01]],\n",
      "\n",
      "         [[ 1.0259e-03,  6.8790e-02, -1.8353e-01, -5.5034e-02, -3.4233e-02],\n",
      "          [-6.5951e-02,  9.7982e-02, -8.1711e-02, -1.5920e-01, -1.1339e-01],\n",
      "          [-9.2733e-02,  4.6767e-02,  1.5155e-02, -6.2937e-02, -2.8302e-02],\n",
      "          [-8.3338e-02,  3.5450e-02,  3.7669e-02,  1.1252e-01,  1.1091e-01],\n",
      "          [ 4.7140e-02,  9.2581e-02,  1.1206e-01,  1.4197e-01,  2.2082e-01]],\n",
      "\n",
      "         [[ 1.2430e-01,  6.7334e-02,  2.2679e-02, -3.1980e-02, -6.6524e-02],\n",
      "          [ 1.0888e-01,  4.1328e-02, -2.0305e-02,  7.2660e-02,  5.7331e-02],\n",
      "          [ 1.0174e-03, -5.5220e-02, -6.3308e-02,  6.8122e-02, -7.4671e-02],\n",
      "          [ 1.5637e-02,  2.5105e-02, -2.1579e-02, -2.6143e-02,  5.1119e-02],\n",
      "          [ 3.1605e-02, -9.7492e-02,  1.7747e-02, -8.7169e-04, -1.9745e-02]],\n",
      "\n",
      "         [[-1.2995e-01,  6.7223e-02,  8.7982e-02, -3.9783e-02, -1.0326e-01],\n",
      "          [-1.6347e-02, -2.8885e-02,  2.4893e-02,  5.6979e-02,  2.4617e-02],\n",
      "          [ 1.4001e-02, -7.4103e-02,  1.0479e-01,  1.0111e-01,  6.0341e-02],\n",
      "          [-8.8177e-02,  3.0797e-02,  9.6749e-02,  7.7382e-02,  9.2761e-02],\n",
      "          [ 9.9386e-03,  1.2888e-02,  1.4883e-01,  1.2074e-01,  5.5419e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0031e-01, -4.3797e-02, -3.1318e-02, -1.0977e-01,  8.1220e-02],\n",
      "          [-1.1544e-01,  1.0284e-02,  8.0815e-02, -2.1651e-03,  6.8697e-02],\n",
      "          [-9.7493e-02, -4.5754e-02,  1.6321e-02,  6.1773e-02,  3.4593e-02],\n",
      "          [-9.4361e-03,  8.7979e-02,  5.0894e-02, -8.1059e-02, -6.6440e-02],\n",
      "          [ 8.5574e-02,  2.9057e-02,  4.4518e-02,  2.0891e-02,  7.4920e-03]],\n",
      "\n",
      "         [[ 3.6446e-02,  1.1198e-01,  3.8702e-02, -6.8345e-02, -6.5600e-02],\n",
      "          [ 8.0658e-02,  1.1133e-01, -7.7159e-02,  1.6556e-02,  6.1277e-02],\n",
      "          [-8.2468e-02, -2.7923e-02, -7.4756e-02,  3.1483e-02, -7.7079e-02],\n",
      "          [-1.3489e-02, -1.7059e-02, -1.1959e-01, -2.6007e-02,  3.5284e-02],\n",
      "          [-1.3774e-01, -1.3617e-01, -4.1872e-02, -1.0987e-01,  7.1065e-02]],\n",
      "\n",
      "         [[-1.4877e-01, -2.4536e-01,  3.0269e-02, -4.4043e-02,  2.0264e-02],\n",
      "          [-9.4714e-02, -9.2668e-02, -7.8430e-03, -4.7281e-02, -8.3817e-02],\n",
      "          [-3.6842e-02, -4.8272e-02,  7.4505e-02,  3.0806e-02, -5.7433e-02],\n",
      "          [ 1.1166e-01,  1.6861e-01, -5.3306e-03, -8.7035e-02, -8.5539e-05],\n",
      "          [ 1.8207e-01,  3.5220e-01,  2.2124e-01, -5.5318e-02,  7.9142e-03]],\n",
      "\n",
      "         [[-1.6106e-01,  9.2262e-02,  1.3083e-01,  6.5141e-04,  5.0574e-02],\n",
      "          [-2.5635e-02,  9.5147e-02,  1.5793e-01, -9.4438e-02, -2.6464e-03],\n",
      "          [-1.6074e-01,  4.9949e-02,  1.1227e-01, -2.0095e-02,  2.7463e-02],\n",
      "          [-1.1395e-01,  1.1730e-01, -7.0872e-02, -2.2107e-02,  6.6938e-02],\n",
      "          [-1.2942e-02,  1.4087e-01, -1.4524e-01, -1.1288e-01,  1.5469e-02]],\n",
      "\n",
      "         [[-1.5178e-02, -8.7191e-02,  4.4976e-02, -7.1817e-02,  1.9046e-02],\n",
      "          [-4.9131e-02, -5.2992e-02,  3.7317e-02, -8.3912e-02, -3.9407e-02],\n",
      "          [ 3.4394e-02,  1.4122e-02, -1.4347e-02, -1.3625e-02, -9.0794e-02],\n",
      "          [ 6.6429e-02,  1.3743e-01,  4.9922e-04,  1.6780e-02, -1.1806e-01],\n",
      "          [ 2.5736e-02,  2.4073e-01,  1.8965e-01, -2.7691e-02, -1.5968e-02]],\n",
      "\n",
      "         [[ 2.8886e-02, -8.7394e-02,  3.5694e-02,  1.0212e-01, -9.6876e-02],\n",
      "          [-3.5649e-02, -1.1217e-01, -3.8394e-02, -2.5382e-02, -4.9753e-03],\n",
      "          [-1.0091e-01,  3.7861e-02,  8.6870e-02, -2.7455e-02,  7.1267e-03],\n",
      "          [-5.3647e-02, -7.2786e-02, -4.4544e-02, -8.6873e-02,  3.8516e-03],\n",
      "          [-2.7086e-02,  1.2507e-02,  1.1539e-02, -1.1504e-01, -9.1094e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.8881e-02,  7.7731e-02,  4.7806e-03, -7.3074e-02, -7.1121e-02],\n",
      "          [ 1.0166e-02,  7.9212e-05,  2.5536e-02, -1.2581e-01, -2.3209e-02],\n",
      "          [-1.0325e-01, -8.8875e-02,  4.7724e-02,  4.7725e-02, -2.8536e-02],\n",
      "          [ 4.7586e-02, -1.9550e-03, -1.5756e-02,  1.3353e-01,  3.4048e-02],\n",
      "          [ 5.9917e-02, -4.0232e-02,  1.2225e-01,  1.4632e-01,  2.9410e-03]],\n",
      "\n",
      "         [[-7.8791e-02, -8.0335e-02, -1.3392e-01, -5.9460e-02, -2.1735e-02],\n",
      "          [-5.5396e-02, -1.1643e-01, -1.4982e-01, -6.7299e-02,  3.4055e-03],\n",
      "          [ 3.2120e-02, -9.4991e-02, -1.1009e-01, -5.8063e-02, -8.6443e-02],\n",
      "          [ 4.8784e-02, -1.4667e-01, -4.8579e-02, -9.7194e-02, -8.6088e-02],\n",
      "          [ 1.2944e-01, -9.0535e-02,  5.7319e-02, -4.8297e-02, -6.2054e-02]],\n",
      "\n",
      "         [[ 1.8233e-02,  3.6948e-02, -1.9122e-02, -6.2696e-02, -1.0745e-01],\n",
      "          [ 6.5387e-02,  3.7045e-03, -4.8719e-02,  3.7637e-02,  3.0585e-02],\n",
      "          [ 1.3530e-01, -1.8637e-02, -8.2543e-02,  7.2929e-02,  6.7959e-03],\n",
      "          [ 1.6223e-02, -2.6903e-02,  3.4434e-02,  1.3475e-01,  9.2266e-02],\n",
      "          [-7.0095e-02, -5.8822e-02,  2.0974e-02,  1.3751e-01,  1.4189e-01]],\n",
      "\n",
      "         [[ 1.4784e-01, -7.0402e-02,  1.6212e-02, -6.0351e-02,  2.8022e-02],\n",
      "          [ 1.6083e-01, -1.0458e-01, -5.3713e-03, -2.7407e-02, -1.6707e-03],\n",
      "          [ 1.8580e-01, -1.6249e-01,  2.5662e-02,  1.5421e-02,  3.5378e-02],\n",
      "          [ 2.4530e-01, -1.0328e-01,  1.8923e-02,  6.7172e-02, -1.1595e-01],\n",
      "          [ 4.2062e-01, -1.6827e-01,  6.5182e-02,  2.2994e-02,  9.1331e-03]],\n",
      "\n",
      "         [[-2.8916e-02,  5.9749e-02,  5.4458e-02, -7.6008e-02, -2.9052e-02],\n",
      "          [-5.2570e-02,  6.1754e-02,  3.6115e-02, -7.7203e-02,  2.7881e-02],\n",
      "          [-1.6879e-02,  7.1383e-02,  7.2965e-03,  6.7221e-02,  7.0472e-02],\n",
      "          [-3.5921e-02,  1.1957e-02, -1.8149e-02, -1.0924e-02,  4.1057e-02],\n",
      "          [-4.0246e-02,  2.4038e-02, -3.0016e-02,  1.6639e-01, -4.9358e-02]],\n",
      "\n",
      "         [[ 6.4100e-02, -3.5236e-03,  6.5699e-02, -1.5307e-02, -3.6722e-02],\n",
      "          [ 7.4308e-02,  9.4823e-02,  7.6127e-02, -5.7006e-02, -4.5938e-02],\n",
      "          [ 7.0694e-03,  1.5412e-01,  1.4496e-02, -4.2182e-02, -5.0956e-02],\n",
      "          [-7.4816e-03,  1.6697e-01, -4.1431e-03, -6.6941e-03,  3.3375e-03],\n",
      "          [ 9.2896e-02,  1.8779e-01,  6.5550e-02,  5.6501e-02, -6.7601e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4969e-02,  6.8831e-02, -3.0984e-02,  7.2411e-02, -2.5175e-02],\n",
      "          [-1.9068e-03, -2.2392e-02, -1.2171e-01,  1.0524e-01,  2.0485e-01],\n",
      "          [ 3.8479e-03,  5.4754e-03, -1.6677e-02,  9.1081e-02,  2.0904e-01],\n",
      "          [-7.0946e-02, -9.7790e-02, -1.5038e-01,  1.0863e-01,  1.1443e-01],\n",
      "          [ 1.7185e-02, -4.1781e-02,  4.1592e-03, -1.6185e-02,  8.6439e-02]],\n",
      "\n",
      "         [[-1.2119e-01, -7.2147e-02, -4.7102e-03, -1.9783e-02, -1.7041e-01],\n",
      "          [-1.5465e-01, -1.7266e-01,  3.8535e-02, -5.1066e-02, -9.0257e-02],\n",
      "          [ 4.1885e-02, -1.0614e-01, -5.0143e-02, -9.4114e-03, -8.0768e-02],\n",
      "          [ 8.7116e-03,  6.6907e-03, -8.8011e-02, -1.0985e-01, -5.7874e-02],\n",
      "          [ 1.6563e-02,  2.0346e-03,  2.1995e-02, -3.2080e-02,  8.0511e-02]],\n",
      "\n",
      "         [[-6.5797e-02,  8.3834e-02,  3.7813e-02,  1.0452e-02,  2.7958e-01],\n",
      "          [-4.9978e-02,  3.3011e-02, -1.3709e-02,  6.7782e-02,  2.7712e-01],\n",
      "          [-1.0781e-01, -5.5371e-02, -1.1985e-01,  1.3401e-01,  2.8186e-01],\n",
      "          [-2.6842e-02, -4.2895e-02,  4.0513e-02,  6.4894e-03,  1.4594e-01],\n",
      "          [-6.0494e-03,  4.2176e-02,  2.5647e-02, -7.0262e-02,  2.0228e-01]],\n",
      "\n",
      "         [[-7.4755e-02, -1.1133e-02, -6.5264e-02, -2.6783e-02,  1.1721e-02],\n",
      "          [ 7.2165e-02, -1.4961e-01,  2.7889e-02,  8.1115e-02, -9.4152e-03],\n",
      "          [-5.2524e-03, -3.8727e-02, -9.9132e-02,  3.6131e-02,  1.1864e-01],\n",
      "          [-4.7281e-02, -8.0917e-02, -9.5998e-02, -2.1602e-02,  6.6480e-02],\n",
      "          [-4.9687e-02, -8.2486e-02, -2.0976e-01, -1.3388e-01,  9.5641e-02]],\n",
      "\n",
      "         [[-1.2153e-01, -3.3148e-02, -5.2422e-02,  1.6031e-03,  5.1940e-02],\n",
      "          [ 6.0820e-03,  1.0402e-01,  7.0576e-02, -9.5053e-03,  1.0343e-01],\n",
      "          [-9.0393e-02,  3.6356e-03, -3.1653e-03,  1.5631e-02,  2.8318e-02],\n",
      "          [-2.7095e-02, -6.8436e-02, -5.0973e-02, -2.0749e-02,  9.0779e-02],\n",
      "          [-8.9554e-02,  1.0170e-02, -6.9655e-03, -2.8788e-02,  3.2196e-02]],\n",
      "\n",
      "         [[ 2.0858e-02, -1.3434e-02, -1.7902e-01,  1.5179e-02,  7.0012e-02],\n",
      "          [-9.7398e-03, -2.2301e-02, -6.2429e-02, -7.0906e-02, -7.2187e-02],\n",
      "          [-1.9857e-02,  5.7222e-03, -4.6971e-03, -6.2334e-02,  7.9052e-03],\n",
      "          [-7.1837e-02, -4.4116e-02, -8.4724e-02, -8.6214e-04, -1.3121e-02],\n",
      "          [-9.8471e-02, -8.1413e-02, -5.3630e-02, -1.2914e-01, -8.7788e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.2399e-02,  1.9561e-02, -4.4444e-03,  5.0538e-03, -1.5234e-01],\n",
      "          [ 4.7662e-02,  1.4581e-01,  2.3282e-03,  5.8421e-04, -1.8099e-02],\n",
      "          [ 7.0039e-02,  1.5215e-01,  6.1678e-02, -8.4586e-02, -1.1939e-01],\n",
      "          [ 1.9557e-02,  7.1881e-02, -9.7565e-02,  4.0513e-02, -5.8979e-03],\n",
      "          [ 6.8391e-02,  4.0058e-02, -5.6190e-02,  3.5570e-02,  1.9644e-01]],\n",
      "\n",
      "         [[-8.8193e-02, -9.9989e-02, -6.2240e-02, -4.9329e-02,  1.5216e-01],\n",
      "          [-3.1199e-02,  1.1045e-01,  1.2825e-01,  8.7989e-02,  1.3970e-01],\n",
      "          [ 6.7727e-02,  7.2238e-02, -1.0499e-02, -3.0550e-02, -9.9597e-02],\n",
      "          [ 1.1738e-02,  2.3709e-02, -2.2788e-02, -5.0705e-02, -7.8001e-02],\n",
      "          [-5.2911e-02, -6.2938e-02, -6.5205e-02,  3.1502e-02,  5.9266e-02]],\n",
      "\n",
      "         [[ 3.7838e-02,  6.9120e-02,  1.2893e-01, -1.2007e-03, -4.1199e-02],\n",
      "          [ 1.9376e-02,  1.1864e-02,  4.2487e-02, -8.7584e-02, -1.4059e-01],\n",
      "          [-2.6875e-03, -1.8867e-02, -1.3271e-01, -1.3069e-01, -4.9885e-02],\n",
      "          [-2.3545e-02, -9.9825e-02, -1.0431e-01,  5.7625e-02,  1.9325e-01],\n",
      "          [-1.8619e-01, -3.6426e-02, -2.6978e-02,  1.7777e-01,  2.4294e-01]],\n",
      "\n",
      "         [[ 5.9349e-02,  7.7414e-02,  3.9072e-02, -1.5693e-01, -2.8680e-02],\n",
      "          [ 4.0919e-02, -2.3713e-02, -1.1159e-01, -1.3684e-01, -5.1472e-02],\n",
      "          [-2.9862e-02, -6.2636e-02, -1.0675e-01, -6.8677e-02,  9.3130e-02],\n",
      "          [ 3.1250e-02, -4.7512e-02, -7.5553e-02,  1.6670e-01,  1.1305e-01],\n",
      "          [ 6.0091e-03, -9.3860e-02, -4.1821e-02,  1.9270e-01,  5.8220e-02]],\n",
      "\n",
      "         [[-7.5361e-02, -1.2539e-02,  8.6989e-02,  3.3110e-02, -1.6280e-02],\n",
      "          [-3.5210e-02,  5.0386e-02,  8.8195e-02, -3.7387e-02, -4.2019e-02],\n",
      "          [-7.1793e-02, -1.1582e-02,  6.9470e-02, -7.9205e-02,  1.1745e-02],\n",
      "          [-6.2220e-02,  2.4008e-02, -9.4876e-02, -7.7766e-02,  1.0814e-01],\n",
      "          [-8.3352e-02,  1.6774e-02,  2.9727e-02,  4.9540e-02,  1.3745e-01]],\n",
      "\n",
      "         [[-6.4366e-02,  2.3834e-02, -9.0144e-02,  6.3694e-02, -4.6225e-04],\n",
      "          [-5.9821e-03,  3.7938e-02, -9.6775e-02,  5.8682e-02, -1.2296e-02],\n",
      "          [-7.0813e-02, -9.6016e-02, -8.3780e-03,  1.7710e-02, -1.0810e-02],\n",
      "          [-4.8059e-02, -7.9572e-02, -7.5651e-02, -1.0786e-02, -3.4034e-02],\n",
      "          [-1.5974e-02, -1.6110e-02, -2.4217e-02,  6.9583e-02, -2.5191e-02]]]],\n",
      "       requires_grad=True))\n",
      "('conv2.bias', Parameter containing:\n",
      "tensor([-0.0553,  0.0632,  0.0149,  0.1367, -0.0364, -0.1061,  0.0567, -0.0400,\n",
      "        -0.0902,  0.0927, -0.1109, -0.1142, -0.0515, -0.1292, -0.0097, -0.0721],\n",
      "       requires_grad=True))\n",
      "('fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0564, -0.0023,  0.0664,  ..., -0.0670, -0.0622, -0.0602],\n",
      "        [ 0.0012, -0.0575, -0.0559,  ...,  0.0123,  0.0129, -0.0036],\n",
      "        [ 0.0059,  0.0096, -0.0816,  ...,  0.0046, -0.0106, -0.0184],\n",
      "        ...,\n",
      "        [-0.0787, -0.1154, -0.0609,  ..., -0.0311, -0.0144, -0.0049],\n",
      "        [-0.0431,  0.0674,  0.0450,  ..., -0.0292, -0.0039,  0.0338],\n",
      "        [-0.0086,  0.0146,  0.0468,  ...,  0.0335,  0.0226, -0.0362]],\n",
      "       requires_grad=True))\n",
      "('fc1.bias', Parameter containing:\n",
      "tensor([ 0.0516, -0.0579,  0.0094,  0.0051,  0.0449,  0.0004,  0.0055, -0.0518,\n",
      "         0.0288,  0.0583,  0.0564,  0.0112, -0.0526,  0.0404,  0.1048, -0.0024,\n",
      "         0.0107,  0.0339, -0.0358, -0.0490,  0.0185, -0.0202,  0.0527,  0.0021,\n",
      "        -0.0033, -0.0071, -0.0580, -0.0181, -0.0610, -0.0236,  0.0322, -0.0389,\n",
      "         0.0398, -0.0882, -0.0006, -0.0222,  0.0231, -0.0466, -0.0610,  0.0333,\n",
      "        -0.0371,  0.0510,  0.0724,  0.0090, -0.0175,  0.0682,  0.0844, -0.0251,\n",
      "         0.0650, -0.0802, -0.0569, -0.0319, -0.0331,  0.0474,  0.0255, -0.0209,\n",
      "         0.0677, -0.0575,  0.0496,  0.0228, -0.0133,  0.0022,  0.0365, -0.0388,\n",
      "        -0.0131,  0.0422,  0.0581, -0.0366, -0.0342, -0.0414,  0.0545, -0.0158,\n",
      "        -0.0452,  0.0030, -0.0307, -0.0019, -0.0463, -0.0140, -0.0150,  0.0632,\n",
      "         0.0101, -0.0159,  0.0472, -0.0387, -0.0011,  0.0432,  0.0037, -0.0196,\n",
      "         0.0791,  0.0085,  0.0271,  0.0159, -0.0089, -0.0428, -0.0060, -0.0463,\n",
      "        -0.0277, -0.0593, -0.0329,  0.0333, -0.0265,  0.0269,  0.0395,  0.0387,\n",
      "         0.0354,  0.1123,  0.0510,  0.0113,  0.0622, -0.0497, -0.0455,  0.0013,\n",
      "        -0.0161,  0.0532, -0.0359,  0.0169,  0.0490,  0.0292, -0.0088, -0.0425],\n",
      "       requires_grad=True))\n",
      "('fc2.weight', Parameter containing:\n",
      "tensor([[-0.0927, -0.0868,  0.0567,  ..., -0.0408,  0.0846,  0.0046],\n",
      "        [-0.0417,  0.0426,  0.0030,  ...,  0.0466,  0.0346,  0.0887],\n",
      "        [ 0.0578, -0.0608,  0.0287,  ..., -0.0086, -0.0849, -0.1046],\n",
      "        ...,\n",
      "        [ 0.0725, -0.0433, -0.1154,  ...,  0.1026, -0.0935,  0.0901],\n",
      "        [-0.1131, -0.0138, -0.0469,  ..., -0.0591, -0.0923,  0.1021],\n",
      "        [-0.0489,  0.0479,  0.0999,  ..., -0.1150, -0.0655, -0.0835]],\n",
      "       requires_grad=True))\n",
      "('fc2.bias', Parameter containing:\n",
      "tensor([ 0.0511,  0.1584, -0.0214,  0.1208,  0.0675, -0.0751,  0.0978,  0.0209,\n",
      "        -0.0930,  0.1086,  0.0230, -0.0784, -0.0647,  0.1534, -0.0275, -0.0146,\n",
      "         0.0807,  0.1315, -0.0070,  0.0590, -0.0304, -0.0683, -0.0751, -0.0706,\n",
      "         0.0222, -0.0477,  0.0367,  0.0840,  0.0282, -0.0173, -0.0824,  0.0344,\n",
      "        -0.0908, -0.0470, -0.0047, -0.0438,  0.0755,  0.0537, -0.0082,  0.0801,\n",
      "         0.0252,  0.0552, -0.0891, -0.0541, -0.0330,  0.0641,  0.0913,  0.0163,\n",
      "         0.0742, -0.0213, -0.0152,  0.1060,  0.0465, -0.0338, -0.0208, -0.0040,\n",
      "        -0.0743, -0.0588, -0.0426,  0.0354,  0.0639,  0.1191, -0.0002,  0.1698,\n",
      "        -0.0125, -0.0720,  0.0125,  0.0457, -0.0130,  0.0646, -0.0500,  0.1497,\n",
      "         0.0468, -0.0210,  0.0953, -0.0563, -0.0480, -0.0351,  0.0594, -0.0257,\n",
      "         0.0675, -0.0823,  0.0228, -0.0528], requires_grad=True))\n",
      "('fc3.weight', Parameter containing:\n",
      "tensor([[ 6.0801e-02,  4.4708e-02,  6.6292e-02,  4.3269e-02,  1.0756e-01,\n",
      "         -3.9060e-02, -1.2678e-01,  5.1512e-02, -6.3038e-02, -4.2693e-02,\n",
      "          7.9274e-02,  1.1489e-01, -1.0769e-01, -3.3155e-02, -4.0389e-02,\n",
      "         -4.7435e-02,  2.4145e-02,  2.3312e-01, -1.1751e-01,  5.8403e-04,\n",
      "          3.2714e-01,  1.0062e-02, -8.1546e-03, -5.2339e-02, -1.2519e-02,\n",
      "          1.1290e-01,  6.3223e-02, -3.5105e-02,  7.3041e-02, -1.5319e-01,\n",
      "         -5.2717e-02,  1.9016e-02, -1.4459e-02,  4.3680e-06,  7.5346e-02,\n",
      "          9.6621e-02, -1.7688e-03, -4.8222e-02,  9.2431e-02,  4.3129e-02,\n",
      "          2.1154e-01,  2.7842e-01,  5.4556e-02, -5.6678e-02, -1.0313e-01,\n",
      "          6.6197e-03, -1.7006e-01,  9.3760e-02, -9.2813e-03, -1.0280e-02,\n",
      "         -1.3849e-01,  2.3300e-01,  1.0874e-01,  5.0429e-02, -6.4332e-02,\n",
      "         -1.1155e-01,  1.5606e-01, -1.1199e-01,  6.2276e-02,  9.1494e-03,\n",
      "         -1.6407e-01,  4.9547e-02,  2.0513e-01,  2.9081e-01, -9.2660e-02,\n",
      "         -1.3301e-01, -2.2273e-01, -5.6383e-02,  9.1387e-02, -4.4813e-02,\n",
      "          6.0053e-03,  1.5294e-01,  7.7377e-02,  3.4547e-02,  4.3317e-02,\n",
      "         -1.1014e-01, -4.4306e-02,  3.3411e-01, -5.5558e-02,  9.8547e-02,\n",
      "         -1.2616e-03, -1.5554e-01, -5.4649e-02,  2.0108e-01],\n",
      "        [-1.7276e-01,  2.1527e-02, -7.2916e-02, -1.5082e-01, -3.0494e-01,\n",
      "          1.7026e-03, -1.8594e-01, -1.0120e-01,  5.1222e-02, -1.3132e-02,\n",
      "          1.0659e-01, -4.0186e-02, -1.2975e-01, -6.8544e-02, -9.1728e-02,\n",
      "          5.8815e-02, -1.1239e-01, -1.1392e-01,  2.3104e-01, -9.9310e-02,\n",
      "         -1.2543e-01,  1.8804e-01,  1.5032e-01, -1.1972e-01, -8.7943e-02,\n",
      "          5.1218e-02,  2.1314e-01,  1.6323e-01,  7.7798e-02, -1.7266e-01,\n",
      "          2.5624e-02,  2.4446e-01, -3.1600e-02, -1.0525e-01, -3.8915e-02,\n",
      "         -6.3748e-02,  3.8620e-01,  3.7897e-02, -8.9266e-02, -6.5837e-02,\n",
      "          4.2294e-01, -2.0645e-01,  6.5741e-02, -1.0541e-01, -1.9666e-02,\n",
      "         -8.4265e-02, -2.1079e-01, -1.6590e-02, -6.1303e-02,  1.7663e-01,\n",
      "          6.9561e-02,  1.7699e-02,  9.7233e-02,  2.4296e-02, -1.5787e-01,\n",
      "         -1.9650e-01,  1.0655e-02, -3.0193e-02, -1.6854e-01, -8.4776e-03,\n",
      "         -1.0811e-01, -4.5623e-02, -1.3869e-03, -3.4525e-01, -7.7609e-02,\n",
      "          2.2002e-01, -1.3828e-01, -2.4882e-01,  1.2834e-03, -1.3447e-01,\n",
      "         -1.0760e-01,  1.6072e-02, -5.0327e-02, -2.3944e-02, -8.3055e-02,\n",
      "          1.6261e-01, -2.2123e-02, -3.9276e-02,  5.0962e-02, -5.5270e-02,\n",
      "          1.1002e-01,  1.7061e-01, -8.6532e-02, -3.0832e-02],\n",
      "        [-7.4735e-02,  1.7792e-01,  1.3435e-01,  2.8340e-01, -2.5961e-01,\n",
      "         -4.7002e-02,  1.4859e-02, -9.9045e-02,  7.1174e-02,  1.3685e-02,\n",
      "          2.5152e-02,  1.5130e-01, -2.2607e-02,  1.2525e-01,  7.7061e-02,\n",
      "         -1.2059e-01,  6.7377e-02,  2.5048e-01, -2.6661e-01, -8.5454e-02,\n",
      "         -2.6979e-01, -1.0483e-01, -1.3729e-01, -1.4880e-01,  1.5627e-01,\n",
      "         -1.0106e-01,  1.2059e-01, -8.8962e-02, -4.2368e-02,  3.4648e-02,\n",
      "          5.9098e-02, -1.3170e-01, -2.0105e-01, -8.6277e-02,  5.6840e-02,\n",
      "          1.4084e-01,  6.7726e-03, -3.3655e-02, -2.1743e-01,  1.7276e-01,\n",
      "         -2.5364e-01,  3.2189e-01,  2.2680e-02,  2.9374e-02,  1.2174e-02,\n",
      "         -3.7608e-02, -1.0209e-01, -6.7328e-02, -5.8455e-02, -3.8781e-02,\n",
      "         -8.0299e-02,  2.3457e-01, -1.4878e-02, -3.9976e-02, -1.4553e-01,\n",
      "         -9.7463e-02, -1.8825e-01,  8.2638e-02, -8.7341e-02, -4.9581e-02,\n",
      "          2.4190e-01,  2.6294e-01,  2.5614e-02,  8.5571e-02, -1.1936e-01,\n",
      "          1.6995e-01,  2.7789e-01,  2.6669e-01, -5.1856e-02,  3.9041e-02,\n",
      "          2.1262e-01,  3.9469e-01,  3.7026e-02, -3.9773e-02,  2.8557e-02,\n",
      "          2.2695e-01, -1.0045e-01, -2.3935e-01, -2.0396e-01, -3.3764e-02,\n",
      "         -5.0272e-02,  6.2700e-02,  2.6236e-02,  1.9812e-01],\n",
      "        [-1.3218e-01, -1.7562e-01, -2.3745e-01, -6.1548e-02,  1.6922e-01,\n",
      "         -8.5592e-02, -2.2874e-01, -6.5502e-02,  9.1750e-02,  6.4625e-02,\n",
      "          4.1113e-02,  6.8436e-02, -2.6913e-02, -1.5763e-01,  5.2037e-02,\n",
      "          9.0471e-02,  3.1635e-02,  3.7239e-02,  2.7767e-01,  4.5833e-02,\n",
      "         -6.3320e-02, -3.7643e-02, -8.7519e-02,  3.0482e-02, -8.3129e-02,\n",
      "          1.0894e-02,  1.1821e-01, -2.0684e-01,  5.5181e-02,  1.7423e-01,\n",
      "         -1.6741e-02,  2.4164e-01, -1.8357e-01, -1.0748e-01,  2.5336e-02,\n",
      "         -8.0503e-02, -7.3821e-02,  2.6419e-01,  5.9659e-03,  5.3456e-02,\n",
      "          1.5675e-01, -7.1535e-03,  4.7130e-02, -7.5915e-03,  1.0377e-01,\n",
      "          2.2478e-02,  7.4057e-02, -1.5513e-01, -2.0065e-02,  7.4513e-03,\n",
      "         -3.6510e-02,  1.4367e-01, -1.2653e-02, -4.3976e-02, -1.4906e-01,\n",
      "          6.1250e-02,  2.1243e-02, -9.2384e-02,  1.0969e-01, -9.5740e-02,\n",
      "         -3.3859e-01,  7.8206e-02, -1.6042e-01,  3.2068e-02, -1.3779e-01,\n",
      "         -2.0026e-01,  1.1363e-01, -9.1582e-02,  2.8908e-03, -1.4005e-01,\n",
      "          9.1924e-02,  2.4890e-01, -1.1201e-02,  1.9422e-01, -6.3301e-02,\n",
      "         -1.4499e-01, -1.2617e-01,  7.7917e-02,  2.5170e-01,  2.2804e-02,\n",
      "          1.5515e-01, -2.9178e-02, -7.9130e-02, -1.5431e-01],\n",
      "        [-1.4563e-01,  1.5330e-02,  6.6400e-02,  1.1402e-01, -1.1678e-01,\n",
      "          1.8289e-02, -1.3678e-01,  7.8611e-02, -8.7620e-02,  3.0451e-01,\n",
      "         -2.3916e-02, -6.3529e-02,  8.5980e-02,  6.4305e-02,  9.5916e-02,\n",
      "         -1.1173e-01,  5.0338e-02, -2.0908e-01,  7.4560e-03,  2.6585e-02,\n",
      "         -1.8743e-01,  2.5237e-01, -5.0684e-02, -3.3408e-04,  1.2279e-01,\n",
      "          3.3168e-02,  1.3329e-01,  1.7316e-01, -9.6780e-02, -4.3554e-02,\n",
      "          6.9531e-02, -2.2893e-01,  9.9143e-02, -7.6437e-02, -2.3374e-02,\n",
      "         -5.5391e-02, -1.2532e-01,  2.2289e-01, -2.8257e-01,  1.1697e-01,\n",
      "         -2.4244e-01,  4.9187e-02, -1.0245e-01,  1.4365e-01,  4.0714e-02,\n",
      "         -7.4559e-02, -2.0949e-01, -1.4261e-01, -1.2613e-01, -2.4292e-02,\n",
      "          1.7230e-02, -7.4420e-02, -5.3048e-02, -4.3376e-02, -1.2631e-01,\n",
      "          1.2641e-01,  2.5055e-02,  1.7361e-01, -6.3068e-02, -1.1917e-01,\n",
      "          2.6527e-01, -9.7953e-02, -1.4246e-01,  1.0661e-01, -5.1404e-02,\n",
      "          8.9706e-02,  3.8254e-01,  3.5216e-01, -2.2825e-02, -1.2896e-01,\n",
      "          1.9363e-01,  2.1013e-01,  1.1753e-01,  7.4717e-02,  1.0924e-01,\n",
      "          8.6429e-02, -1.4992e-02, -4.1333e-02,  2.1720e-01,  4.2006e-02,\n",
      "          1.8919e-01,  2.7289e-01, -1.4866e-01, -1.2326e-01],\n",
      "        [ 3.1494e-01, -1.1215e-01,  6.9085e-02, -2.1524e-01,  1.0031e-01,\n",
      "         -1.1196e-01,  2.9710e-01, -3.0245e-02, -2.1148e-02, -2.5216e-01,\n",
      "          7.3564e-02,  4.4317e-02, -1.0828e-01, -1.4173e-01, -1.4153e-01,\n",
      "          5.4879e-02, -1.6019e-01, -2.3026e-01, -9.4861e-02, -9.1050e-02,\n",
      "         -1.0534e-01, -1.0496e-01,  1.6422e-01, -1.1474e-01, -8.8581e-02,\n",
      "          1.7791e-02, -5.9712e-02, -9.7123e-02, -1.0705e-01,  2.0791e-01,\n",
      "          2.2934e-02, -3.5256e-04,  3.0073e-01, -1.6000e-03,  1.7723e-02,\n",
      "          8.5558e-02, -1.0605e-01, -2.2399e-01,  2.2828e-01, -6.9182e-02,\n",
      "          7.2513e-02, -2.3397e-01, -2.5381e-02,  1.8274e-03,  3.4221e-04,\n",
      "         -2.7296e-01,  1.8203e-01,  1.4580e-01, -1.6488e-01, -9.0422e-02,\n",
      "          2.1417e-01, -6.0403e-02, -7.1960e-02, -2.0342e-02,  3.8965e-01,\n",
      "          3.9598e-02, -8.2719e-02,  2.8960e-01, -2.5685e-02,  1.1357e-02,\n",
      "          3.0627e-02, -4.7966e-02,  7.9829e-02, -2.6145e-01,  9.7370e-02,\n",
      "          1.9339e-01, -2.8954e-02, -7.4919e-02, -7.7444e-02,  2.9406e-01,\n",
      "         -1.5753e-01, -3.8117e-01, -8.2701e-02,  2.2839e-02,  1.8553e-01,\n",
      "         -1.4964e-01,  2.2993e-02, -7.2534e-02, -2.8294e-02,  1.8746e-01,\n",
      "         -1.5181e-01, -1.4015e-01,  1.5159e-01,  2.8365e-02],\n",
      "        [-1.0904e-01, -2.9508e-02, -1.6287e-01,  1.0899e-01, -7.1691e-02,\n",
      "         -1.1654e-01, -1.4819e-01, -7.1662e-02, -1.4983e-02,  2.5774e-01,\n",
      "         -3.0413e-02, -4.6533e-02,  1.9109e-01, -7.9846e-02,  8.7493e-02,\n",
      "          9.7915e-02, -1.0210e-01,  2.9523e-01, -9.5495e-02,  8.6526e-02,\n",
      "          3.1191e-01,  3.0334e-02, -8.2596e-05,  1.6765e-01, -7.1722e-02,\n",
      "          9.2606e-02,  1.9106e-01, -2.0981e-01, -1.0484e-01, -1.9179e-01,\n",
      "         -5.7622e-02, -2.4023e-02,  4.4807e-02, -1.6622e-01, -3.8788e-02,\n",
      "         -3.2199e-02, -1.6278e-01, -2.1954e-02, -1.4875e-01, -1.5664e-01,\n",
      "          1.1122e-02,  3.0200e-01, -1.1634e-02, -1.9837e-01, -9.1184e-02,\n",
      "         -1.4960e-01, -1.8101e-01, -8.2146e-02,  2.1722e-02, -2.3449e-02,\n",
      "         -1.0503e-01,  7.7791e-02,  8.3259e-02,  7.6662e-02, -1.1944e-01,\n",
      "          2.0287e-01,  4.7337e-03,  1.8762e-01,  4.2860e-02, -7.8581e-02,\n",
      "          2.5427e-01,  1.2948e-01,  5.5818e-02,  3.6871e-01, -2.4835e-02,\n",
      "          4.1476e-02,  1.4629e-01,  7.5698e-03,  2.5634e-01, -1.2776e-01,\n",
      "          1.1616e-02,  2.6979e-01,  4.2583e-03,  6.6841e-02, -9.5002e-02,\n",
      "          8.9012e-02,  1.1057e-01,  2.0944e-01, -6.8291e-02,  5.6139e-02,\n",
      "         -9.1312e-02,  1.1187e-01,  4.9641e-02, -2.1878e-01],\n",
      "        [ 2.3185e-01,  7.3811e-02, -8.7659e-02, -1.1401e-01,  1.1820e-01,\n",
      "          1.2351e-01,  2.5544e-01, -3.7157e-02,  2.6593e-02, -3.2368e-01,\n",
      "          2.2714e-02,  6.6720e-02, -1.4847e-01,  1.0126e-01, -3.4608e-02,\n",
      "         -5.1394e-02, -4.1719e-02, -2.4756e-01,  1.2054e-01, -3.0748e-02,\n",
      "         -3.3873e-02, -1.3371e-01,  5.4968e-02, -5.8074e-02,  8.8850e-02,\n",
      "         -6.6270e-02, -9.8059e-02,  9.8220e-03,  2.3055e-01, -6.1760e-04,\n",
      "          9.4897e-02, -3.3618e-01,  5.9817e-02,  9.2965e-02,  7.2277e-02,\n",
      "          6.5086e-03, -1.4294e-01,  1.5026e-01,  3.9872e-01, -3.7201e-02,\n",
      "         -1.9275e-01, -2.8840e-01, -1.1462e-02, -5.1189e-02,  6.8056e-03,\n",
      "          4.4419e-01,  5.3470e-02,  1.4809e-01, -1.5251e-02, -8.7287e-02,\n",
      "          1.0921e-01, -3.0583e-01,  9.2838e-02, -5.8674e-02,  5.3738e-02,\n",
      "          4.8046e-02, -7.0807e-02, -3.9544e-02,  5.5276e-02,  8.7145e-02,\n",
      "         -5.7232e-02, -1.9635e-01, -1.5868e-01, -2.7844e-01,  2.1804e-01,\n",
      "         -9.2946e-02, -2.7972e-01,  8.8161e-02,  5.1244e-02,  1.3891e-01,\n",
      "         -1.7271e-02, -3.0981e-01,  1.9580e-02, -4.2851e-02, -3.4807e-02,\n",
      "         -7.2866e-02, -1.4882e-01,  1.2042e-02, -2.6573e-02, -1.4433e-02,\n",
      "         -1.3164e-01,  2.4877e-02,  2.2621e-01, -8.5288e-03],\n",
      "        [-2.6049e-01,  1.8588e-01, -1.8525e-01, -3.1785e-02,  2.2796e-01,\n",
      "          8.1628e-02, -5.9128e-02,  1.7231e-02, -2.2844e-02,  1.4559e-01,\n",
      "         -3.5368e-02, -6.7618e-02, -1.9237e-01,  3.2449e-01,  7.4779e-02,\n",
      "         -9.3278e-02,  6.5755e-02, -1.0691e-01, -2.4803e-01, -5.8236e-02,\n",
      "         -2.1634e-01,  1.4315e-01, -1.5660e-01,  3.4255e-02,  5.6292e-02,\n",
      "         -8.7835e-02, -1.2663e-01,  1.5903e-01, -2.5017e-02,  2.4966e-01,\n",
      "          8.2892e-02,  1.0217e-01,  2.8594e-02,  2.4900e-01, -7.0409e-03,\n",
      "         -4.0318e-02,  1.6173e-02, -2.5504e-01,  1.8833e-01,  6.4937e-03,\n",
      "         -9.7692e-02,  8.9716e-02,  1.8862e-02,  5.8621e-02,  8.0605e-02,\n",
      "         -7.1826e-02,  3.6338e-01,  1.6522e-01,  6.2579e-02,  1.2731e-01,\n",
      "         -2.9091e-01, -5.9422e-03,  7.1623e-02,  7.3898e-02,  1.4513e-01,\n",
      "         -8.0472e-02, -1.4337e-01,  6.9690e-02,  1.6134e-01,  1.6844e-01,\n",
      "         -3.1985e-02, -1.1098e-01,  1.7061e-01,  2.4829e-01, -3.5244e-01,\n",
      "         -1.4373e-01, -5.4404e-02, -4.8527e-02,  7.8704e-02, -1.9272e-01,\n",
      "         -9.5686e-02, -2.8028e-01,  4.5970e-02, -2.7076e-03,  3.0380e-01,\n",
      "          6.8101e-03,  1.4484e-01, -5.0334e-03, -1.0585e-01, -1.5928e-01,\n",
      "          2.0124e-01, -1.6475e-01,  1.1432e-01,  1.0661e-02],\n",
      "        [ 3.2106e-02, -1.1448e-01,  2.4868e-01,  5.5575e-02,  1.6285e-01,\n",
      "          9.8400e-02,  2.4605e-01,  2.8167e-02, -8.3202e-02, -2.3192e-01,\n",
      "         -8.8173e-03,  9.6010e-03, -8.2811e-02,  7.4143e-02,  3.6815e-02,\n",
      "         -1.9439e-02,  1.4301e-01, -1.3649e-01,  4.1397e-02,  7.8962e-02,\n",
      "          1.6789e-01, -2.1769e-02,  2.3905e-01, -6.8313e-02,  9.6457e-02,\n",
      "         -1.1594e-02, -1.2128e-01, -1.8352e-02, -1.3697e-01, -8.3942e-04,\n",
      "          4.1624e-02,  5.4129e-02, -2.7806e-01,  2.1284e-01,  4.5595e-02,\n",
      "         -1.0631e-01, -5.7734e-02, -1.3088e-01,  2.7860e-02, -2.0786e-02,\n",
      "         -9.1405e-02, -1.9899e-01,  2.0842e-03, -7.3060e-02, -1.9831e-02,\n",
      "          1.3761e-01,  1.3633e-01,  1.6901e-01,  2.6684e-01,  7.8996e-02,\n",
      "          2.9579e-01, -2.4105e-01,  9.2303e-02,  4.3181e-02,  1.3958e-01,\n",
      "          1.4047e-02, -9.5020e-02, -1.9850e-01, -1.9243e-02,  1.4768e-01,\n",
      "          6.9756e-02, -2.6200e-01, -1.2925e-01, -1.2194e-01,  3.3229e-01,\n",
      "         -1.7489e-01, -2.1546e-01, -2.4807e-01, -8.8332e-02,  8.2161e-02,\n",
      "          6.9972e-02, -2.0545e-01, -4.2551e-02, -1.3983e-01, -2.1791e-01,\n",
      "         -5.9396e-02, -7.6392e-02, -1.4820e-01, -1.7049e-01,  8.2192e-02,\n",
      "         -2.4094e-01, -1.0235e-01, -1.6061e-01, -9.2792e-03]],\n",
      "       requires_grad=True))\n",
      "('fc3.bias', Parameter containing:\n",
      "tensor([-0.0047, -0.2075,  0.2612, -0.0425, -0.1077, -0.2500,  0.2433, -0.1667,\n",
      "         0.2234, -0.1259], requires_grad=True))\n",
      "('fc4.bias', Parameter containing:\n",
      "tensor([ 0.2431+0.0936j,  0.2726+0.0232j,  0.2101-0.0851j, -0.2301-0.1218j,\n",
      "        -0.0116+0.0026j, -0.0374-0.0607j, -0.0901-0.3056j, -0.2038+0.0826j,\n",
      "        -0.0124-0.1110j, -0.1548-0.0129j], requires_grad=True))\n",
      "('fc4.parametrizations.weight.original', Parameter containing:\n",
      "tensor([[-1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j, -1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j, -1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j,  0.+0.j, -1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j, -1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j, -1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j, -1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j, -1.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j, -1.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j, -1.+0.j]],\n",
      "       requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for layer in model.named_parameters():\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "239425bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor([[-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.]])\n"
     ]
    }
   ],
   "source": [
    "Q = model.state_dict()['fc4.parametrizations.weight.original']\n",
    "print(torch.dist(Q.T @ Q, torch.eye(10)))\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a632bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2469e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ced701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88daeaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from complexPyTorch.complexLayers import ComplexBatchNorm2d, ComplexConv2d, ComplexLinear\n",
    "from complexPyTorch.complexFunctions import complex_relu, complex_max_pool2d\n",
    "\n",
    "batch_size = 64\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = datasets.MNIST('../data', train=True, transform=trans, download=True)\n",
    "test_set = datasets.MNIST('../data', train=False, transform=trans, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ba95381",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Module 'ComplexLinear(\n  (fc_r): Linear(in_features=10, out_features=10, bias=True)\n  (fc_i): Linear(in_features=10, out_features=10, bias=True)\n)' has no parameter ot buffer with name 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k7/xbg0txh97kb_tz_4gnqjl7cm0000gn/T/ipykernel_82776/2558428600.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComplexNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/k7/xbg0txh97kb_tz_4gnqjl7cm0000gn/T/ipykernel_82776/2558428600.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComplexLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComplexLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morthogonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mComplexLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/QML/lib/python3.8/site-packages/torch/nn/utils/parametrizations.py\u001b[0m in \u001b[0;36morthogonal\u001b[0;34m(module, name, orthogonal_map, use_trivialization)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0;34m\"Module '{}' has no parameter ot buffer with name '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Module 'ComplexLinear(\n  (fc_r): Linear(in_features=10, out_features=10, bias=True)\n  (fc_i): Linear(in_features=10, out_features=10, bias=True)\n)' has no parameter ot buffer with name 'weight'"
     ]
    }
   ],
   "source": [
    "class ComplexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.conv1 = ComplexConv2d(1, 10, 5, 1)\n",
    "        self.bn  = ComplexBatchNorm2d(10)\n",
    "        self.conv2 = ComplexConv2d(10, 20, 5, 1)\n",
    "        self.fc1 = ComplexLinear(4*4*20, 500)\n",
    "        self.fc2 = ComplexLinear(500, 10)\n",
    "        self.fc3 = orthogonal(ComplexLinear(10,10))\n",
    "             \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = self.bn(x)\n",
    "        x = self.conv2(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1,4*4*20)\n",
    "        x = self.fc1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.abs()\n",
    "        x =  F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ComplexNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f51ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device).type(torch.complex64), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {:3} [{:6}/{:6} ({:3.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(data), \n",
    "                len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), \n",
    "                loss.item())\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "806573a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   0 [     0/ 60000 (  0%)]\tLoss: 2.474864\n",
      "Train Epoch:   0 [  6400/ 60000 ( 11%)]\tLoss: 0.119842\n",
      "Train Epoch:   0 [ 12800/ 60000 ( 21%)]\tLoss: 0.137026\n",
      "Train Epoch:   0 [ 19200/ 60000 ( 32%)]\tLoss: 0.048653\n",
      "Train Epoch:   0 [ 25600/ 60000 ( 43%)]\tLoss: 0.060973\n",
      "Train Epoch:   0 [ 32000/ 60000 ( 53%)]\tLoss: 0.150029\n",
      "Train Epoch:   0 [ 38400/ 60000 ( 64%)]\tLoss: 0.041426\n",
      "Train Epoch:   0 [ 44800/ 60000 ( 75%)]\tLoss: 0.038588\n",
      "Train Epoch:   0 [ 51200/ 60000 ( 85%)]\tLoss: 0.068409\n",
      "Train Epoch:   0 [ 57600/ 60000 ( 96%)]\tLoss: 0.028518\n"
     ]
    }
   ],
   "source": [
    "# Run training on 50 epochs\n",
    "for epoch in range(1):\n",
    "    train(model, device, train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0d614c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('conv1.conv_r.weight', Parameter containing:\n",
      "tensor([[[[ 0.0004,  0.0729, -0.0415, -0.1739,  0.0597],\n",
      "          [ 0.0036, -0.1216, -0.2125, -0.0172, -0.2331],\n",
      "          [ 0.2563,  0.1374,  0.1149, -0.0437, -0.1041],\n",
      "          [-0.0212,  0.1087,  0.1733,  0.1807, -0.1437],\n",
      "          [-0.1079, -0.1205,  0.1751,  0.1483,  0.0077]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2020, -0.0469,  0.1907,  0.2836, -0.0289],\n",
      "          [ 0.1146, -0.1203, -0.0564,  0.1274,  0.1214],\n",
      "          [-0.0680, -0.1652, -0.2407, -0.0627, -0.0725],\n",
      "          [-0.1568, -0.2206, -0.0737, -0.1829,  0.1660],\n",
      "          [-0.1273,  0.1912, -0.0734,  0.0870, -0.0808]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0661, -0.1141, -0.0722, -0.2033, -0.1182],\n",
      "          [-0.0294, -0.0546, -0.1643,  0.1872,  0.0667],\n",
      "          [ 0.1797,  0.1603,  0.2162,  0.1259,  0.1086],\n",
      "          [ 0.0862,  0.1713,  0.1078, -0.1265,  0.1565],\n",
      "          [-0.2527, -0.1983, -0.1668,  0.0207, -0.0845]]],\n",
      "\n",
      "\n",
      "        [[[-0.0747, -0.0135,  0.0982, -0.0624,  0.1952],\n",
      "          [-0.0744,  0.0510,  0.1602, -0.0711,  0.0031],\n",
      "          [ 0.0201,  0.3111, -0.0696, -0.1182, -0.1489],\n",
      "          [-0.0576,  0.3134, -0.1882, -0.0900,  0.1295],\n",
      "          [-0.0506,  0.2949,  0.2246,  0.0603,  0.2374]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1776,  0.0617, -0.1835, -0.2323,  0.0867],\n",
      "          [-0.0839,  0.1237,  0.0223, -0.2239, -0.0579],\n",
      "          [-0.0355,  0.1369,  0.1753,  0.0097,  0.0718],\n",
      "          [ 0.0169, -0.0927,  0.1779,  0.1759,  0.1692],\n",
      "          [ 0.1075,  0.0338,  0.0641,  0.1280, -0.0362]]],\n",
      "\n",
      "\n",
      "        [[[-0.1938, -0.1176,  0.0952, -0.1629, -0.0685],\n",
      "          [-0.0527, -0.1929, -0.0060, -0.0558,  0.0499],\n",
      "          [ 0.1916, -0.1589, -0.0684, -0.1792, -0.0514],\n",
      "          [ 0.2401,  0.2195, -0.0737, -0.1021,  0.0478],\n",
      "          [ 0.1864,  0.2123,  0.0024,  0.0658,  0.0209]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1275,  0.1618, -0.0375, -0.0986,  0.0178],\n",
      "          [ 0.0712,  0.1855, -0.1411, -0.1012, -0.0478],\n",
      "          [ 0.0959,  0.2487, -0.0933,  0.0312, -0.0390],\n",
      "          [-0.1904,  0.1295,  0.1723, -0.1946,  0.1114],\n",
      "          [ 0.1216,  0.1485,  0.1337, -0.1400,  0.1028]]],\n",
      "\n",
      "\n",
      "        [[[-0.1114, -0.0087,  0.1816, -0.0919,  0.0126],\n",
      "          [ 0.0723,  0.0597, -0.0089,  0.0624, -0.2359],\n",
      "          [-0.1681, -0.1637, -0.1072,  0.1682,  0.1355],\n",
      "          [ 0.0956,  0.0669,  0.2188, -0.0441,  0.3045],\n",
      "          [-0.0567,  0.0047, -0.0620, -0.1615, -0.0228]]],\n",
      "\n",
      "\n",
      "        [[[-0.3339,  0.0110,  0.0943,  0.2147,  0.0731],\n",
      "          [ 0.0542,  0.0396,  0.1504, -0.0424, -0.1310],\n",
      "          [ 0.1209,  0.2017, -0.1011, -0.2012,  0.1420],\n",
      "          [ 0.0892, -0.2196, -0.0741, -0.1023,  0.0521],\n",
      "          [-0.0754,  0.0458,  0.0293, -0.0060,  0.0208]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0728,  0.1697,  0.0382,  0.0315,  0.1922],\n",
      "          [-0.1890,  0.2140,  0.0632, -0.0532,  0.0152],\n",
      "          [-0.1585,  0.2028, -0.1448, -0.1112, -0.0487],\n",
      "          [ 0.0654,  0.1549,  0.1593, -0.0006,  0.1363],\n",
      "          [-0.1338, -0.1374,  0.0925, -0.1190, -0.1731]]]], requires_grad=True))\n",
      "('conv1.conv_r.bias', Parameter containing:\n",
      "tensor([-0.1984, -0.1185, -0.1498, -0.1743,  0.0068, -0.0513, -0.1530,  0.0885,\n",
      "        -0.1644,  0.1442], requires_grad=True))\n",
      "('conv1.conv_i.weight', Parameter containing:\n",
      "tensor([[[[-0.1500, -0.0378, -0.0432, -0.0197, -0.1289],\n",
      "          [ 0.0952, -0.1869,  0.1854,  0.0846,  0.1614],\n",
      "          [-0.1104, -0.0589, -0.1407, -0.0914,  0.1776],\n",
      "          [-0.1548, -0.0468, -0.2379, -0.1564, -0.1601],\n",
      "          [ 0.0185,  0.1091,  0.0211, -0.0712, -0.1456]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1226, -0.0839,  0.0487, -0.1764, -0.1326],\n",
      "          [ 0.1574, -0.0062, -0.1877,  0.0330,  0.1321],\n",
      "          [ 0.1431, -0.1171, -0.1527, -0.1234, -0.2227],\n",
      "          [ 0.0984,  0.2021,  0.2056,  0.1237, -0.0711],\n",
      "          [-0.0958, -0.0564,  0.1886, -0.0549,  0.1948]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0560, -0.0512, -0.1681, -0.1474,  0.0937],\n",
      "          [ 0.0061, -0.0640, -0.1158,  0.0230,  0.1025],\n",
      "          [-0.0046,  0.0741, -0.1258,  0.0427,  0.1712],\n",
      "          [-0.1024, -0.0285, -0.1830,  0.1973,  0.1344],\n",
      "          [-0.1632, -0.2005, -0.0958,  0.2953, -0.0653]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1042, -0.0294, -0.1684, -0.1280,  0.2952],\n",
      "          [ 0.0669,  0.0525, -0.2608,  0.0941, -0.0889],\n",
      "          [ 0.0999,  0.1349, -0.0200, -0.1546,  0.0153],\n",
      "          [ 0.0608,  0.2322, -0.0959, -0.0756, -0.1312],\n",
      "          [-0.1239,  0.0398,  0.2247,  0.2029, -0.0581]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1802, -0.0728,  0.0266,  0.0427, -0.0451],\n",
      "          [-0.0747, -0.1957,  0.0945, -0.0808, -0.0571],\n",
      "          [-0.0919, -0.2243, -0.1094, -0.1907,  0.1254],\n",
      "          [ 0.0514,  0.0574,  0.0790,  0.2035,  0.2664],\n",
      "          [ 0.0884,  0.1737,  0.1004,  0.1007, -0.1125]]],\n",
      "\n",
      "\n",
      "        [[[-0.0201, -0.0065, -0.0799, -0.0018, -0.1264],\n",
      "          [ 0.1306, -0.1836,  0.1658, -0.0836,  0.1195],\n",
      "          [ 0.1902, -0.1367, -0.0376, -0.0925,  0.1161],\n",
      "          [ 0.1490,  0.1851, -0.1158, -0.1478,  0.1716],\n",
      "          [ 0.2321, -0.0119, -0.2380,  0.1598, -0.1954]]],\n",
      "\n",
      "\n",
      "        [[[-0.0623, -0.2508,  0.1309, -0.0370,  0.1781],\n",
      "          [-0.1230, -0.0168,  0.0257,  0.0714,  0.1975],\n",
      "          [-0.0447, -0.0490,  0.2547,  0.0113,  0.0186],\n",
      "          [-0.1058, -0.2017,  0.0823,  0.1925, -0.1714],\n",
      "          [ 0.0559, -0.2254,  0.0985,  0.0290,  0.1420]]],\n",
      "\n",
      "\n",
      "        [[[-0.0161, -0.0191,  0.0977,  0.1846, -0.0499],\n",
      "          [ 0.0883,  0.1830,  0.0088, -0.0845,  0.1320],\n",
      "          [ 0.2310,  0.1021, -0.1025, -0.0822, -0.0972],\n",
      "          [-0.1227,  0.1671, -0.0413,  0.1486, -0.1751],\n",
      "          [ 0.1884,  0.1508, -0.0628,  0.1206, -0.2412]]],\n",
      "\n",
      "\n",
      "        [[[-0.2109, -0.1893,  0.0101,  0.2145,  0.1509],\n",
      "          [-0.0057, -0.1436, -0.0382,  0.0283,  0.0061],\n",
      "          [ 0.1897, -0.1226, -0.2311, -0.0078,  0.2328],\n",
      "          [ 0.1902,  0.0750, -0.2029, -0.1932, -0.1448],\n",
      "          [-0.0239,  0.0324, -0.1037, -0.0522, -0.1231]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0154,  0.1196,  0.1667, -0.0860, -0.0320],\n",
      "          [-0.0222,  0.0830, -0.0367, -0.1496, -0.1014],\n",
      "          [ 0.0227,  0.1188,  0.0113,  0.0635, -0.2196],\n",
      "          [-0.1780,  0.0542, -0.1310, -0.2418,  0.1039],\n",
      "          [ 0.1081, -0.2058, -0.2029, -0.1479, -0.0267]]]], requires_grad=True))\n",
      "('conv1.conv_i.bias', Parameter containing:\n",
      "tensor([-0.1150, -0.1619, -0.0641,  0.1453, -0.0639,  0.1137, -0.0192, -0.1056,\n",
      "         0.0281, -0.1993], requires_grad=True))\n",
      "('bn.weight', Parameter containing:\n",
      "tensor([[ 1.4258,  1.3862,  0.1264],\n",
      "        [ 1.3867,  1.3575,  0.0349],\n",
      "        [ 1.4825,  1.3900, -0.1036],\n",
      "        [ 1.4014,  1.3888,  0.0324],\n",
      "        [ 1.3794,  1.4295,  0.1189],\n",
      "        [ 1.4029,  1.3536, -0.0083],\n",
      "        [ 1.3864,  1.3930,  0.0681],\n",
      "        [ 1.3568,  1.3597,  0.0019],\n",
      "        [ 1.4409,  1.3769, -0.0616],\n",
      "        [ 1.3692,  1.3626, -0.0023]], requires_grad=True))\n",
      "('bn.bias', Parameter containing:\n",
      "tensor([[-0.0279, -0.0602],\n",
      "        [ 0.0136,  0.0109],\n",
      "        [ 0.0211, -0.1373],\n",
      "        [-0.0369, -0.0405],\n",
      "        [ 0.0243, -0.0012],\n",
      "        [ 0.0169, -0.0077],\n",
      "        [-0.0679,  0.0181],\n",
      "        [-0.0203, -0.0697],\n",
      "        [ 0.0192, -0.1012],\n",
      "        [ 0.0733, -0.0510]], requires_grad=True))\n",
      "('conv2.conv_r.weight', Parameter containing:\n",
      "tensor([[[[-3.3319e-02,  3.7023e-02,  2.5945e-02, -4.5494e-02, -3.8844e-02],\n",
      "          [ 6.5263e-02,  6.5854e-02,  7.3711e-02, -5.4646e-02, -2.6909e-04],\n",
      "          [-2.8100e-02,  5.5864e-03,  7.1783e-02,  4.1798e-02, -2.1516e-02],\n",
      "          [ 4.3165e-02,  4.4602e-02,  8.7713e-02, -1.0149e-02,  3.3897e-02],\n",
      "          [-7.3083e-02, -3.0296e-02,  6.4026e-03,  1.5366e-02, -4.5384e-02]],\n",
      "\n",
      "         [[ 3.3627e-02, -2.6836e-03, -6.3834e-02, -3.0747e-02, -1.0827e-02],\n",
      "          [ 3.1848e-02,  3.4394e-03, -4.3260e-02, -5.5030e-02, -2.0906e-02],\n",
      "          [ 2.4658e-02, -5.3621e-02, -1.7269e-02,  3.5876e-02, -5.5793e-02],\n",
      "          [-2.0953e-02, -1.2548e-02, -4.2187e-02, -5.7611e-02, -5.4716e-02],\n",
      "          [-1.8129e-02, -2.5473e-03,  6.9138e-03,  6.3409e-02,  1.9846e-03]],\n",
      "\n",
      "         [[-1.2356e-02, -7.4211e-02,  2.0522e-02, -7.2603e-02, -5.7315e-02],\n",
      "          [ 2.2441e-02, -2.7114e-02,  2.9841e-02,  1.9234e-02,  3.5096e-02],\n",
      "          [ 5.8661e-02, -3.9222e-02, -6.6767e-02, -7.4786e-02, -4.2585e-02],\n",
      "          [-3.0163e-02, -4.7598e-02, -1.3294e-02, -6.1028e-03,  1.9098e-02],\n",
      "          [ 3.0643e-02, -1.0663e-02,  2.5557e-02,  6.2507e-03,  4.4397e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.8723e-03, -8.9533e-03,  1.9395e-02, -8.3134e-03, -1.6911e-02],\n",
      "          [ 1.2246e-03,  3.3751e-03, -6.3584e-02,  1.7662e-02,  1.7092e-02],\n",
      "          [-2.5552e-02, -4.8885e-03,  2.5113e-02,  1.4507e-02, -3.0983e-02],\n",
      "          [-3.2198e-03,  1.2326e-02,  7.0538e-03,  2.4793e-02, -7.5025e-03],\n",
      "          [-4.5965e-02, -3.0277e-02,  5.4304e-02,  4.1803e-02, -2.6928e-02]],\n",
      "\n",
      "         [[-2.4334e-02,  1.0723e-02, -2.8136e-02,  2.3288e-02,  4.5481e-02],\n",
      "          [-7.3694e-03, -1.2462e-02,  3.9839e-02,  5.1123e-02, -3.0602e-02],\n",
      "          [ 3.1748e-02,  9.6874e-02,  8.5081e-02, -8.3575e-03,  2.6205e-02],\n",
      "          [ 5.4398e-02, -1.6148e-03,  9.6048e-03, -6.7328e-02, -4.0567e-02],\n",
      "          [-4.9010e-02, -1.0941e-02, -1.8188e-03, -8.5422e-02, -4.9149e-03]],\n",
      "\n",
      "         [[-2.6815e-02,  1.1105e-02,  2.5401e-02,  5.1940e-02,  3.4371e-02],\n",
      "          [-1.9065e-02, -1.3278e-02,  1.0914e-02,  2.1223e-02, -2.5292e-02],\n",
      "          [-5.6822e-03, -2.9267e-02,  3.3923e-02,  5.8351e-02,  5.0902e-02],\n",
      "          [ 5.5749e-02, -6.2502e-02,  1.0071e-02, -2.1712e-02,  4.0345e-02],\n",
      "          [-2.5952e-02, -3.9127e-02,  1.7279e-02, -2.6605e-02, -5.6938e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8420e-02,  8.3027e-03,  2.2691e-02, -1.4090e-02, -6.6238e-02],\n",
      "          [ 4.2335e-02, -4.6162e-02, -6.0072e-02,  2.7645e-02, -6.1693e-02],\n",
      "          [ 5.8809e-02, -2.9883e-02, -6.4260e-02, -5.2834e-02,  1.1400e-03],\n",
      "          [-9.2260e-03,  8.0294e-03, -1.8285e-02, -3.0425e-02,  3.4186e-02],\n",
      "          [-7.7974e-04,  7.4198e-03,  2.6437e-02,  1.3879e-02,  7.3543e-02]],\n",
      "\n",
      "         [[-7.3709e-02, -6.6534e-02,  5.1659e-02, -4.6771e-02, -6.2145e-03],\n",
      "          [-1.3032e-02,  1.0066e-02, -2.9228e-02, -2.6299e-02, -1.1659e-02],\n",
      "          [ 2.0304e-02, -3.2177e-02, -5.4939e-02, -1.2882e-02, -3.5254e-02],\n",
      "          [-1.1280e-02, -1.5881e-02, -4.0091e-02,  1.2838e-02,  3.7316e-03],\n",
      "          [-2.5683e-02, -3.5816e-02,  4.1187e-02,  2.6967e-03,  2.7865e-02]],\n",
      "\n",
      "         [[-7.7344e-02, -6.6392e-02, -6.2887e-02,  3.3175e-02,  4.7181e-02],\n",
      "          [ 2.5044e-02, -2.2690e-02,  7.6209e-02,  4.0137e-02, -2.7007e-02],\n",
      "          [ 4.9956e-02,  7.2504e-02,  5.8539e-02,  2.9649e-02, -3.7256e-04],\n",
      "          [ 7.7704e-02,  7.3857e-03,  9.7780e-02, -2.0178e-02,  7.6620e-03],\n",
      "          [ 1.4425e-02,  2.7547e-02,  3.1219e-02,  3.6186e-02,  3.5683e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.6458e-02, -6.1872e-02,  1.4727e-02,  4.0771e-02,  1.6543e-02],\n",
      "          [-7.0017e-02, -9.9621e-02, -4.9875e-04, -1.5910e-02, -1.0960e-02],\n",
      "          [ 1.7116e-02,  4.2750e-03,  5.0280e-02,  2.8898e-02,  2.7339e-02],\n",
      "          [-3.7161e-02,  7.7018e-03,  2.8048e-02,  7.9319e-03, -8.9130e-03],\n",
      "          [ 2.4902e-02, -5.9828e-02,  1.0412e-02,  2.1828e-02,  3.9185e-02]],\n",
      "\n",
      "         [[ 2.2538e-02,  2.2286e-03, -6.4245e-02, -4.8516e-02,  1.6134e-02],\n",
      "          [-2.0159e-02, -5.2361e-02,  4.7654e-03, -2.3794e-02, -5.3278e-02],\n",
      "          [-2.0382e-02,  6.0402e-04,  1.7456e-02, -4.9631e-02, -6.3323e-03],\n",
      "          [-7.1133e-02, -7.7136e-02, -3.9334e-02,  7.8875e-02,  3.2140e-03],\n",
      "          [-5.6860e-02, -4.7199e-02,  1.9722e-02,  1.5323e-02, -5.4179e-02]],\n",
      "\n",
      "         [[-4.1630e-02, -5.6993e-02,  4.1707e-02,  2.2028e-02,  2.0275e-02],\n",
      "          [ 6.0916e-02,  1.3541e-02, -4.6878e-02,  1.6728e-02, -8.1379e-03],\n",
      "          [ 4.6596e-03,  1.2085e-02, -5.4551e-02,  5.5370e-02, -2.1041e-02],\n",
      "          [-1.8023e-02, -5.1533e-02, -2.7896e-02,  8.3342e-03,  4.9223e-02],\n",
      "          [-4.8399e-02, -2.2631e-02,  3.2325e-02, -5.0294e-02, -4.6996e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.9212e-03,  3.4061e-02, -1.4279e-02, -7.3444e-02, -6.2922e-02],\n",
      "          [ 3.6251e-02,  2.1833e-02,  1.2161e-02, -3.2365e-02, -2.9564e-02],\n",
      "          [-3.7480e-02, -3.0237e-02,  4.8447e-02,  5.6114e-02,  5.9333e-02],\n",
      "          [ 5.4431e-02,  8.5710e-03,  5.4543e-02,  7.6609e-02, -2.2317e-02],\n",
      "          [ 6.3647e-03,  9.2148e-02, -6.7322e-03, -5.2328e-02, -4.6256e-02]],\n",
      "\n",
      "         [[ 7.5655e-03,  7.9918e-03, -5.0599e-02, -6.4274e-02, -1.6156e-02],\n",
      "          [-3.4352e-02, -6.7013e-02,  3.4443e-02, -3.6981e-02, -1.7128e-02],\n",
      "          [ 9.1291e-03, -3.3499e-02, -5.6377e-02, -3.6219e-02, -4.8875e-02],\n",
      "          [-3.6263e-03,  7.2909e-02,  9.9441e-02,  2.4233e-02,  1.2567e-02],\n",
      "          [ 3.9761e-02,  6.3884e-02, -1.6633e-02,  5.3811e-03,  5.6824e-02]],\n",
      "\n",
      "         [[ 1.1242e-01,  1.7167e-02, -5.3910e-02,  3.0280e-02,  5.2715e-02],\n",
      "          [ 8.6893e-02,  5.1355e-02,  5.8869e-02,  6.5821e-02,  3.5257e-03],\n",
      "          [ 4.8569e-02, -1.5796e-02, -1.6888e-02,  2.0691e-02,  3.4211e-02],\n",
      "          [ 2.9237e-02, -5.0208e-02,  1.0815e-02,  5.8366e-02,  1.5307e-01],\n",
      "          [-1.3897e-02, -6.7277e-03,  2.7825e-02, -1.2893e-02,  7.5784e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.0443e-03, -3.9519e-02,  1.5632e-02,  6.7772e-02,  3.5106e-02],\n",
      "          [ 6.7100e-03, -8.9751e-02, -3.0030e-02,  9.3926e-03, -4.0216e-02],\n",
      "          [-4.2496e-02,  4.2557e-02,  5.8406e-02, -1.0232e-02, -4.2600e-03],\n",
      "          [ 4.4815e-02,  2.4153e-02,  5.9267e-02,  3.3610e-02,  5.1050e-02],\n",
      "          [-3.8834e-02,  2.4059e-02, -1.0209e-02,  4.6896e-03, -7.2971e-02]],\n",
      "\n",
      "         [[-1.0838e-02, -2.1252e-02,  3.9517e-02, -6.2540e-03,  6.8130e-03],\n",
      "          [ 5.6742e-02, -1.6484e-02,  6.8887e-02,  3.2262e-02, -1.8255e-04],\n",
      "          [-1.2284e-02, -1.1767e-02, -4.2241e-02,  3.4072e-02, -5.1517e-02],\n",
      "          [-1.9844e-02, -2.1231e-02, -6.9071e-02,  1.8602e-02,  4.6788e-03],\n",
      "          [-3.7039e-02, -1.8391e-02, -1.1609e-03, -4.9665e-02,  7.5852e-02]],\n",
      "\n",
      "         [[ 7.4210e-02, -1.0526e-03, -5.3455e-02,  4.9659e-03,  1.0219e-02],\n",
      "          [-7.1579e-03,  5.2975e-02,  4.1107e-02, -1.6705e-03,  8.9039e-02],\n",
      "          [ 2.1269e-02,  6.1641e-02,  7.2690e-02, -7.9272e-03,  4.7380e-02],\n",
      "          [ 1.6299e-02,  2.7052e-02, -1.6916e-02,  1.1761e-02,  2.2225e-02],\n",
      "          [-1.1391e-02, -2.3593e-02, -8.3854e-02,  1.3739e-02, -5.8718e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.3560e-02, -1.5461e-02, -2.5998e-02,  6.6834e-03, -7.3600e-03],\n",
      "          [-3.4886e-02,  6.4809e-02,  1.0430e-02, -2.5171e-03,  1.1100e-02],\n",
      "          [ 8.2634e-02,  3.6599e-02,  1.7207e-02, -1.0014e-03, -1.7321e-03],\n",
      "          [-2.9603e-02,  4.3678e-02,  2.7161e-04,  2.3823e-02, -5.5624e-02],\n",
      "          [ 2.2967e-02, -4.1703e-02, -3.5501e-02, -6.0384e-02,  1.6082e-02]],\n",
      "\n",
      "         [[-3.9112e-02, -6.7253e-02, -3.2898e-03,  9.0530e-03, -5.6432e-02],\n",
      "          [-7.0631e-02, -1.9916e-02, -3.6723e-02,  1.5575e-02,  1.3091e-03],\n",
      "          [ 3.5594e-02,  1.2898e-01, -1.4587e-02,  7.0002e-02, -3.6344e-02],\n",
      "          [-2.4497e-02, -3.6494e-02, -1.6155e-02,  3.6772e-02,  2.8347e-02],\n",
      "          [ 8.4805e-02,  2.6709e-02,  3.7258e-02,  8.2729e-02,  7.2254e-02]],\n",
      "\n",
      "         [[-6.2765e-02, -3.4340e-02, -1.3613e-02,  4.2407e-02, -2.4784e-02],\n",
      "          [-2.1863e-02, -5.3931e-02,  3.8528e-02,  4.6473e-02, -2.3682e-03],\n",
      "          [-7.8102e-02, -3.5095e-02, -9.1094e-02,  3.5163e-02,  4.6860e-03],\n",
      "          [ 3.1401e-03, -1.8210e-02, -3.7140e-02, -5.1916e-03,  2.5122e-04],\n",
      "          [-7.0928e-03, -3.3652e-02,  1.2989e-02,  1.3793e-02,  5.2580e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5638e-04, -1.5711e-02, -2.6920e-02, -1.3802e-02, -3.9415e-02],\n",
      "          [ 5.7551e-02,  2.0927e-03,  3.9308e-02, -2.3146e-02,  3.4759e-04],\n",
      "          [ 2.5868e-02,  2.4539e-02, -2.1889e-02, -3.8082e-02, -3.4023e-02],\n",
      "          [ 2.5889e-02, -2.0227e-02,  2.2482e-02,  3.3930e-03, -2.4718e-02],\n",
      "          [-4.8964e-02, -1.3474e-02, -2.8212e-02,  3.2487e-02, -4.2263e-02]],\n",
      "\n",
      "         [[ 5.4235e-02,  3.3777e-02,  4.7943e-02,  3.2884e-02,  5.3251e-03],\n",
      "          [-1.3903e-02, -6.3498e-02,  2.4179e-02,  1.4557e-02,  1.2037e-02],\n",
      "          [-3.6715e-02,  6.5046e-02,  9.6480e-02,  1.8254e-02,  9.7499e-03],\n",
      "          [ 3.9236e-02, -6.2095e-02,  3.2982e-02,  6.5537e-02,  2.0054e-02],\n",
      "          [-4.5561e-02,  3.1608e-02, -3.9843e-02, -7.2511e-05,  7.3349e-02]],\n",
      "\n",
      "         [[-4.6165e-02,  5.3601e-03, -2.1125e-02, -4.3451e-02, -5.0962e-03],\n",
      "          [-5.9944e-02,  3.3890e-02,  3.5943e-03, -4.7607e-02, -1.0700e-02],\n",
      "          [ 1.6625e-02, -2.9375e-02, -3.6673e-02,  4.6829e-02,  2.8796e-02],\n",
      "          [-2.6133e-02,  2.2339e-02,  8.6054e-03, -6.4203e-02, -1.4534e-02],\n",
      "          [-6.4016e-02, -3.9230e-02, -3.7036e-02, -6.5566e-04, -3.6432e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5334e-02,  5.5753e-02,  3.8762e-02, -1.6469e-02,  4.2511e-02],\n",
      "          [-2.4232e-02,  3.3125e-02,  8.2749e-02,  8.0733e-02,  2.8634e-02],\n",
      "          [-7.1395e-02,  5.3451e-02,  4.8185e-03,  9.5661e-02, -1.6952e-02],\n",
      "          [-6.9895e-02, -5.1635e-02, -9.1635e-02,  4.6331e-02, -5.6995e-03],\n",
      "          [-4.2365e-02, -1.2213e-02, -6.6550e-02,  1.3843e-02, -3.9855e-02]],\n",
      "\n",
      "         [[-3.4232e-02,  4.0990e-02,  8.3296e-03, -1.9037e-02, -6.9066e-03],\n",
      "          [-3.8271e-02, -4.6034e-02,  6.1213e-03,  8.3884e-04,  4.5250e-02],\n",
      "          [ 4.6938e-02,  2.6043e-02,  1.6916e-03,  2.9399e-02, -3.3880e-02],\n",
      "          [-2.3210e-02,  5.8473e-02,  1.3209e-02,  2.6487e-02,  6.8186e-03],\n",
      "          [-4.1003e-02, -3.3079e-02,  3.1582e-04, -6.6857e-02, -7.6005e-02]],\n",
      "\n",
      "         [[ 1.8740e-02,  3.8452e-02, -5.3688e-02, -5.2209e-02, -1.4071e-02],\n",
      "          [-4.0548e-02,  4.0809e-03,  2.1596e-02, -6.3605e-02, -3.3975e-02],\n",
      "          [ 8.6369e-02,  5.7444e-02, -7.7438e-02, -7.9211e-02, -1.0575e-01],\n",
      "          [-1.5055e-02, -1.8478e-02, -4.4905e-02, -2.5858e-02,  4.0252e-03],\n",
      "          [ 2.6835e-02,  2.5061e-03, -1.8301e-02, -1.3036e-02, -6.5167e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7474e-03, -1.9646e-02,  1.3314e-03, -4.1444e-02, -2.1372e-02],\n",
      "          [-6.2388e-03,  1.7499e-02,  3.9249e-02, -7.9968e-02, -3.9754e-02],\n",
      "          [ 3.8308e-02,  6.5162e-02, -1.6153e-02, -4.9533e-02, -3.0486e-02],\n",
      "          [ 1.5027e-02, -3.9287e-03, -5.4382e-02, -3.4887e-02,  4.9633e-02],\n",
      "          [ 6.5100e-02,  7.2770e-02, -5.7369e-03, -1.3674e-02,  8.3709e-03]],\n",
      "\n",
      "         [[ 1.1540e-02, -6.3398e-02,  6.0182e-03, -2.0394e-02,  3.7891e-02],\n",
      "          [ 6.0653e-02,  2.2276e-02, -6.8576e-02, -4.8849e-02,  4.2144e-02],\n",
      "          [ 1.6092e-02,  2.0986e-02, -6.7586e-03, -7.3163e-02, -2.5064e-02],\n",
      "          [-5.9543e-02, -5.8993e-02, -5.1600e-02, -5.0274e-02, -2.9960e-02],\n",
      "          [ 2.1121e-02,  3.8556e-02,  1.1109e-01,  7.8785e-02, -1.2367e-02]],\n",
      "\n",
      "         [[ 6.5701e-02, -2.4084e-02,  6.8618e-02,  5.8984e-02, -2.6606e-02],\n",
      "          [-2.8325e-02, -9.4319e-03, -1.9317e-02,  7.6158e-02, -4.0330e-02],\n",
      "          [-3.2602e-02, -2.8446e-02, -1.3055e-02, -3.9625e-02,  1.4996e-02],\n",
      "          [-8.6600e-02, -5.8837e-02, -1.8352e-02, -5.1377e-02, -8.5587e-03],\n",
      "          [ 1.6188e-02,  2.1761e-02,  4.0437e-02, -2.0488e-02,  2.9766e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5879e-02,  1.0139e-01,  1.0253e-01, -3.4832e-02, -1.4867e-02],\n",
      "          [-1.0746e-02,  5.8497e-02,  2.7823e-02,  1.1361e-03,  1.2549e-02],\n",
      "          [ 8.2024e-03, -5.0366e-02,  2.7619e-02, -4.3095e-02, -1.2376e-02],\n",
      "          [-5.8021e-03,  3.5412e-02, -5.1694e-02, -4.4143e-02,  5.4946e-02],\n",
      "          [ 2.0528e-03, -4.6393e-02,  4.6983e-02, -1.3044e-02,  2.8307e-02]],\n",
      "\n",
      "         [[-1.6705e-02, -3.1507e-03, -2.2280e-02, -9.7063e-02, -4.3936e-02],\n",
      "          [-7.3407e-02, -2.5294e-02, -3.0201e-02, -3.0929e-02,  2.6317e-02],\n",
      "          [ 9.3026e-02,  8.9636e-02,  1.1966e-01,  5.5362e-02, -3.7032e-03],\n",
      "          [ 2.5151e-03,  6.9326e-02,  9.2040e-02,  1.9764e-02, -1.2822e-02],\n",
      "          [-3.3501e-02,  2.4104e-02, -1.2691e-02, -3.6874e-02, -1.8219e-02]],\n",
      "\n",
      "         [[ 7.5023e-03,  9.8212e-02,  1.2708e-01,  1.3749e-01,  7.2404e-02],\n",
      "          [ 5.4577e-02,  1.2866e-01,  1.1687e-01,  1.1772e-01,  9.2808e-02],\n",
      "          [-7.1995e-03, -6.9932e-03, -3.5253e-02, -3.3788e-02, -7.4246e-02],\n",
      "          [-1.1091e-01,  1.3182e-02,  2.5633e-03, -3.8359e-03, -5.6651e-02],\n",
      "          [-3.4443e-02, -4.2195e-02, -5.2566e-03, -4.6981e-03, -3.1224e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.3056e-02,  7.6646e-02,  5.2254e-02,  4.6657e-02,  6.4188e-02],\n",
      "          [ 5.2129e-02,  7.7894e-02,  7.3706e-02,  8.3555e-02,  1.8707e-02],\n",
      "          [-2.2589e-02, -9.8044e-02,  4.4397e-03, -5.0783e-04, -4.2665e-02],\n",
      "          [ 7.8134e-03,  5.8410e-02, -9.9104e-02, -2.5106e-02, -6.2121e-02],\n",
      "          [ 2.5352e-02,  4.6706e-02, -1.0182e-02, -6.7019e-02,  2.5617e-03]],\n",
      "\n",
      "         [[-5.2482e-02, -5.3408e-02, -3.5136e-02,  4.4048e-02,  1.3765e-02],\n",
      "          [ 3.1004e-02, -7.4449e-02,  6.3259e-02,  4.5511e-03,  6.8254e-02],\n",
      "          [-1.2840e-02,  1.9139e-02, -3.2746e-02, -6.4663e-03,  2.7928e-02],\n",
      "          [-2.1330e-02,  1.9789e-04, -4.5850e-02,  5.7471e-03,  2.3240e-02],\n",
      "          [-7.3826e-02, -4.8975e-02, -3.2842e-02,  3.1501e-02,  3.4471e-02]],\n",
      "\n",
      "         [[-1.0889e-02, -2.3852e-02, -2.4420e-02,  1.7883e-02, -9.6106e-03],\n",
      "          [-1.3568e-02,  3.2082e-03,  1.4006e-02,  4.0624e-02,  7.2581e-03],\n",
      "          [ 6.9430e-02,  7.5984e-02, -3.8245e-02,  8.9257e-03,  1.6891e-02],\n",
      "          [-4.7217e-02, -3.8291e-02,  2.9806e-02, -7.6501e-02, -4.4524e-02],\n",
      "          [ 2.3063e-02,  5.6953e-03, -8.2803e-02, -2.9048e-02, -4.1140e-02]]]],\n",
      "       requires_grad=True))\n",
      "('conv2.conv_r.bias', Parameter containing:\n",
      "tensor([-0.0985, -0.0749, -0.0538,  0.0028, -0.0369, -0.0804, -0.0634, -0.0501,\n",
      "        -0.0518,  0.0080,  0.0209, -0.0069,  0.0035, -0.0069, -0.0374, -0.0774,\n",
      "        -0.0333, -0.1036, -0.0484,  0.0101], requires_grad=True))\n",
      "('conv2.conv_i.weight', Parameter containing:\n",
      "tensor([[[[ 3.2031e-02, -1.0489e-02, -5.0212e-02,  5.7212e-02, -5.1160e-02],\n",
      "          [ 8.1215e-02,  9.4156e-02,  9.3127e-02, -2.2028e-02, -3.3724e-02],\n",
      "          [ 5.6812e-02,  2.6344e-02,  7.5157e-02,  6.8815e-02,  2.6142e-02],\n",
      "          [-7.3189e-02, -4.7541e-02,  4.7850e-02,  4.6313e-02,  1.0654e-02],\n",
      "          [-2.0698e-02, -6.9940e-02,  2.2609e-02, -3.1747e-02, -3.2768e-02]],\n",
      "\n",
      "         [[ 3.5011e-02,  8.5965e-03,  4.3479e-02, -4.0790e-03, -3.6063e-04],\n",
      "          [ 1.7295e-02,  4.6185e-02,  4.2821e-02,  1.4543e-02, -2.1353e-02],\n",
      "          [ 8.5452e-02,  2.8255e-02,  2.3483e-02, -1.1113e-02, -6.5963e-02],\n",
      "          [ 1.7579e-02, -5.3207e-02,  9.9322e-03, -2.6738e-02, -5.8535e-02],\n",
      "          [ 2.5146e-02,  4.8776e-02, -6.5721e-04, -6.6713e-02, -2.9189e-02]],\n",
      "\n",
      "         [[ 3.6089e-02, -2.4835e-03,  2.7294e-02, -3.4831e-02, -6.3582e-02],\n",
      "          [-9.6224e-04,  3.2921e-02, -8.1494e-02, -5.8671e-02, -4.7048e-02],\n",
      "          [ 1.0085e-01, -1.2864e-03, -3.7125e-02,  1.3677e-02, -5.6471e-02],\n",
      "          [-1.0530e-02, -5.3894e-03, -1.6425e-02, -4.1291e-02, -7.8893e-03],\n",
      "          [ 4.4703e-02, -5.9397e-02,  3.3458e-02, -2.5505e-02, -4.7022e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5118e-02,  9.8659e-03, -6.4567e-04, -7.2046e-02, -6.2136e-02],\n",
      "          [ 1.8075e-02, -6.4657e-02, -3.1505e-02, -3.5187e-02,  1.8493e-02],\n",
      "          [ 1.3138e-02, -8.1264e-02, -3.2286e-02, -3.7933e-02, -4.5394e-02],\n",
      "          [-7.3277e-02,  2.2793e-02,  7.0630e-03,  7.5162e-03,  4.0243e-02],\n",
      "          [ 2.0812e-02,  1.6156e-02,  1.9205e-03, -4.9997e-02,  4.7122e-02]],\n",
      "\n",
      "         [[ 4.5581e-02,  4.4685e-02, -3.6077e-02, -1.8973e-02, -6.5237e-02],\n",
      "          [ 8.7995e-04,  1.0592e-02,  1.0490e-02, -6.1270e-02, -4.7076e-02],\n",
      "          [ 1.7883e-02, -5.8713e-02,  1.6150e-02, -4.4347e-02, -1.6324e-02],\n",
      "          [-4.9960e-03,  1.1122e-02,  4.6629e-03, -2.4891e-02,  2.5161e-02],\n",
      "          [ 3.7385e-03, -5.4260e-02,  6.6829e-03, -3.5595e-02,  2.6348e-02]],\n",
      "\n",
      "         [[-2.6611e-02,  2.2210e-02, -3.5416e-02, -3.5705e-02, -6.0800e-02],\n",
      "          [-3.9578e-02, -4.4930e-02, -6.9616e-02, -5.1009e-02, -7.5900e-02],\n",
      "          [ 4.1154e-02, -5.6804e-02, -7.4743e-02, -4.7588e-02, -1.7447e-02],\n",
      "          [ 1.1167e-02,  6.5105e-03,  4.6417e-03,  2.6320e-02, -7.1989e-02],\n",
      "          [ 1.3909e-02, -2.0782e-03, -3.9241e-02, -5.0400e-02, -2.3491e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1296e-02, -4.8596e-03,  6.1297e-02,  6.1359e-02,  7.4497e-03],\n",
      "          [-5.0063e-02, -4.0280e-02, -3.4444e-02, -3.7358e-04, -5.5598e-02],\n",
      "          [-3.6739e-02, -5.5308e-03, -5.5700e-02, -7.3124e-02,  2.0247e-02],\n",
      "          [ 9.7149e-03,  9.3209e-03, -1.7703e-02, -3.9807e-02,  4.9620e-02],\n",
      "          [-1.2970e-02,  1.4959e-04, -3.1263e-02, -3.0905e-02, -8.1255e-03]],\n",
      "\n",
      "         [[ 6.3815e-02,  7.2678e-02,  4.7787e-02,  3.1452e-02,  1.7417e-02],\n",
      "          [-4.1685e-02,  4.7531e-04, -3.1224e-02, -4.8002e-02, -7.0750e-02],\n",
      "          [ 9.2655e-02,  2.1368e-02,  2.1211e-02,  5.7646e-02, -2.5455e-02],\n",
      "          [ 1.6886e-02,  6.1664e-02, -6.9309e-02, -6.4908e-03, -5.8740e-02],\n",
      "          [ 4.3989e-02, -1.6741e-02, -5.7399e-03,  4.0544e-02,  4.9668e-02]],\n",
      "\n",
      "         [[ 1.8957e-02, -2.2482e-02, -6.4243e-02,  1.0233e-02, -2.7412e-02],\n",
      "          [ 2.7036e-02, -1.0365e-02, -9.2971e-02, -1.9334e-02, -7.2866e-02],\n",
      "          [-3.5394e-02, -1.1594e-02, -1.1525e-01, -8.3220e-03, -5.8283e-02],\n",
      "          [ 3.5126e-02, -3.0045e-02, -2.3536e-02, -3.8665e-02,  3.8172e-02],\n",
      "          [-4.9988e-04,  3.9421e-02, -5.2275e-02,  4.3886e-02, -4.4661e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.0119e-02,  1.4823e-02, -3.0635e-03,  5.6470e-03, -6.1022e-02],\n",
      "          [ 1.6885e-02, -2.7137e-02, -4.2106e-02,  1.1943e-02,  5.0475e-02],\n",
      "          [ 2.1862e-02, -4.9501e-03, -5.7308e-02,  9.7420e-03, -6.9681e-02],\n",
      "          [-6.7692e-02, -4.9476e-03,  3.6386e-02, -1.4494e-02, -1.7744e-02],\n",
      "          [-3.8345e-02,  4.3379e-02, -4.4305e-02,  6.1985e-02, -2.0955e-02]],\n",
      "\n",
      "         [[-6.0246e-02, -8.1132e-02,  2.7031e-02, -1.9576e-02,  9.1625e-03],\n",
      "          [-8.9999e-03, -9.3494e-03,  3.2095e-02, -3.4493e-02, -2.2120e-02],\n",
      "          [-6.6137e-02, -5.8852e-02,  4.6542e-02, -2.2588e-04,  3.2057e-02],\n",
      "          [-6.9335e-03,  5.1463e-02,  1.8704e-03, -3.8901e-02,  9.3330e-03],\n",
      "          [-3.2975e-02,  1.8106e-02,  3.9876e-02, -6.6888e-02, -2.5606e-02]],\n",
      "\n",
      "         [[-5.0309e-02,  3.3191e-03, -2.6787e-02, -1.8145e-02,  7.0312e-03],\n",
      "          [-4.3937e-02, -6.0438e-02,  2.8417e-02,  2.0618e-02, -4.0538e-02],\n",
      "          [ 1.2566e-02, -3.9332e-02, -5.3865e-02, -3.4761e-02, -4.0615e-02],\n",
      "          [-1.2442e-02, -4.2187e-03, -2.3837e-02, -1.5225e-02, -7.2284e-02],\n",
      "          [ 1.1625e-02, -4.4535e-02, -4.2323e-02,  1.4945e-02,  3.4127e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4363e-02,  4.2880e-02, -4.2714e-02, -6.9150e-02, -8.2804e-02],\n",
      "          [-8.0704e-03,  3.7066e-02, -5.8406e-02, -1.8765e-02, -5.8103e-02],\n",
      "          [-1.8276e-02, -7.3514e-02, -3.9283e-02, -2.2467e-02, -5.9155e-02],\n",
      "          [-7.8653e-02, -2.7904e-02, -6.4354e-02, -8.2781e-02,  2.0380e-02],\n",
      "          [-3.2973e-02,  1.1398e-02, -1.4272e-02, -5.4888e-02, -4.9231e-04]],\n",
      "\n",
      "         [[ 1.0914e-02,  1.6973e-02,  7.2011e-03,  1.3590e-02,  1.0401e-01],\n",
      "          [ 3.4139e-02, -4.0501e-02,  8.0781e-02,  6.7214e-02,  6.9018e-02],\n",
      "          [-4.8837e-02, -4.9594e-02,  6.0191e-02,  3.0558e-02, -2.6984e-03],\n",
      "          [-7.9021e-03, -7.1674e-02, -9.2134e-02, -6.3623e-02,  2.6153e-03],\n",
      "          [-3.3797e-02, -7.3295e-02, -7.3201e-02, -2.5808e-02,  7.9280e-03]],\n",
      "\n",
      "         [[-3.4735e-02, -1.5290e-02, -1.1015e-01, -2.2887e-02, -4.3395e-02],\n",
      "          [-6.9043e-02, -1.3423e-02, -7.2157e-02, -3.0946e-02, -1.7420e-02],\n",
      "          [-3.5617e-02, -5.0025e-02, -1.7837e-02, -2.8563e-02,  4.0577e-02],\n",
      "          [ 1.5286e-02, -3.9294e-02,  4.9176e-02, -3.4968e-02, -1.4046e-02],\n",
      "          [ 5.2931e-02,  3.5558e-02,  1.1608e-02, -2.7856e-03, -2.8454e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.6655e-03,  3.5382e-02,  2.9582e-02, -8.4619e-03, -3.5540e-03],\n",
      "          [-1.4321e-02, -1.7124e-02,  3.6451e-02, -5.7362e-02,  2.8341e-02],\n",
      "          [-7.7310e-02, -5.7850e-02,  7.5280e-03, -5.5488e-03, -5.1540e-02],\n",
      "          [-2.1806e-02,  3.4409e-02,  1.7671e-03,  8.4318e-02,  7.3357e-02],\n",
      "          [ 9.5592e-02,  2.6665e-02,  1.3875e-02,  5.7462e-02,  2.8891e-03]],\n",
      "\n",
      "         [[-6.7239e-03, -1.3880e-02,  1.5078e-02,  6.3089e-02,  5.9483e-02],\n",
      "          [-3.2512e-02, -4.2049e-02,  1.1254e-01,  7.3592e-02,  5.6123e-02],\n",
      "          [-2.8380e-02,  2.7911e-02,  5.9591e-02,  4.3384e-03,  6.8230e-02],\n",
      "          [ 1.3506e-02, -7.4765e-02, -4.8277e-02, -1.9900e-02, -4.8679e-02],\n",
      "          [-3.5704e-02, -2.0044e-02,  7.4176e-03,  2.0529e-02, -7.4045e-02]],\n",
      "\n",
      "         [[-2.2490e-02, -4.3169e-02, -3.6882e-03,  3.8010e-02,  4.3565e-03],\n",
      "          [-5.2026e-02, -1.2048e-02,  5.7809e-04, -2.1969e-02,  2.4760e-02],\n",
      "          [ 2.6242e-02,  5.2318e-02,  5.7445e-02,  7.1636e-02, -2.4686e-02],\n",
      "          [ 1.7459e-02,  2.2675e-02,  2.0404e-02, -4.3322e-02, -8.2705e-02],\n",
      "          [ 2.1781e-02,  2.9728e-02,  6.9447e-03, -4.4905e-02, -3.7915e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-9.3765e-03, -5.5979e-02,  2.3085e-02, -4.5720e-02, -2.5261e-02],\n",
      "          [-6.1844e-03,  6.5988e-02,  3.2972e-02, -2.2090e-02, -2.8802e-02],\n",
      "          [ 5.3229e-02,  1.1673e-01,  9.9194e-02,  4.8521e-02, -6.6265e-03],\n",
      "          [-9.4872e-02,  2.3076e-02,  6.0109e-02, -3.2815e-02,  2.6301e-02],\n",
      "          [ 1.1384e-02, -7.6821e-02, -6.9722e-02, -4.9577e-02,  2.4932e-02]],\n",
      "\n",
      "         [[-7.2584e-03, -6.8964e-02, -2.2309e-03, -1.3091e-02, -4.8463e-02],\n",
      "          [-7.1982e-02,  9.1430e-03, -3.0973e-02, -1.8715e-02,  3.9065e-02],\n",
      "          [-1.6313e-02, -7.0551e-02, -1.1402e-01, -7.5740e-02, -2.1322e-02],\n",
      "          [ 9.3744e-02,  5.6498e-02, -5.8522e-02, -4.2845e-02,  4.4963e-02],\n",
      "          [-1.9619e-02,  6.8768e-02,  3.8746e-02,  3.6968e-02,  4.6964e-02]],\n",
      "\n",
      "         [[-5.2927e-02, -7.7734e-02,  3.4437e-02, -1.7818e-02, -3.7142e-02],\n",
      "          [-3.9300e-02, -7.9803e-02, -3.5967e-02, -5.4876e-02, -1.0046e-02],\n",
      "          [ 1.0746e-01,  2.0413e-02,  6.4784e-02, -5.7629e-02,  3.3276e-02],\n",
      "          [ 2.3017e-02, -3.8299e-02, -8.2216e-03, -9.0521e-03, -9.6573e-03],\n",
      "          [ 4.1567e-02,  6.8008e-03,  1.5857e-02, -4.5904e-03,  3.5869e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3065e-02, -5.2168e-02, -6.1708e-02,  7.5962e-02,  3.6904e-02],\n",
      "          [-5.2223e-02, -6.9814e-02, -8.3912e-02, -2.1082e-02,  6.1008e-03],\n",
      "          [ 8.2201e-02, -4.8677e-02,  2.4832e-02,  5.3314e-02,  7.3226e-02],\n",
      "          [ 1.6781e-03,  3.3189e-02, -8.2555e-03, -5.8369e-03,  6.6301e-02],\n",
      "          [-3.0223e-02,  4.0631e-02, -3.8174e-03,  2.4432e-02,  2.1462e-02]],\n",
      "\n",
      "         [[-5.2830e-03,  3.4880e-02,  7.6602e-02,  2.6404e-02, -3.8917e-02],\n",
      "          [ 2.9951e-02,  3.7303e-02,  9.1196e-02,  5.7942e-02,  2.1088e-02],\n",
      "          [-8.1003e-02, -5.3172e-03, -1.2394e-02, -3.3885e-02,  3.4690e-03],\n",
      "          [-7.0004e-02, -4.1984e-02,  2.2576e-02,  4.6245e-02, -1.9513e-02],\n",
      "          [-4.4671e-02, -1.4571e-02,  2.5116e-03,  3.1606e-02,  1.3288e-02]],\n",
      "\n",
      "         [[ 7.0391e-03, -3.8896e-02,  5.5104e-02, -2.4599e-02,  6.7941e-02],\n",
      "          [ 3.8492e-03,  3.9375e-02, -6.5113e-02,  4.9676e-02,  6.9846e-02],\n",
      "          [ 1.7182e-02,  4.6570e-02, -1.5924e-02,  1.3113e-02,  3.6666e-02],\n",
      "          [ 3.2516e-02, -4.0226e-02, -1.0724e-04, -5.7782e-02,  8.5592e-03],\n",
      "          [-1.1438e-02, -4.5751e-03,  5.5141e-02, -3.1963e-02,  3.9378e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.5878e-03, -6.0088e-02, -1.4908e-02, -7.7328e-02, -4.4164e-02],\n",
      "          [-2.4127e-02, -3.4079e-02, -3.3281e-02,  1.5445e-02, -2.1266e-02],\n",
      "          [-4.5795e-02,  2.5739e-03,  9.1665e-03,  1.4367e-03, -5.5795e-02],\n",
      "          [ 7.3413e-02,  3.9419e-02,  3.0681e-02, -1.1591e-02,  2.0041e-02],\n",
      "          [-4.5910e-02,  6.4493e-02, -4.1782e-02, -4.7574e-03,  6.3226e-03]],\n",
      "\n",
      "         [[ 4.6297e-02,  4.0807e-02, -3.8076e-02,  3.4357e-02,  5.0040e-02],\n",
      "          [-7.1111e-02,  2.1918e-02, -5.9729e-02,  5.8429e-02,  3.3265e-02],\n",
      "          [ 1.6926e-02, -2.3157e-02, -9.1035e-03,  7.1821e-02,  5.8066e-02],\n",
      "          [-3.6434e-02,  3.1806e-02, -1.7104e-02,  1.0791e-02,  1.1319e-02],\n",
      "          [ 1.5020e-02,  2.7307e-02,  7.7412e-02, -4.9466e-02, -6.8324e-03]],\n",
      "\n",
      "         [[-1.5521e-02,  2.8180e-03, -7.4065e-02, -2.0892e-02, -4.9307e-02],\n",
      "          [-2.5130e-03, -2.1891e-02, -6.9936e-02, -5.7798e-02, -8.0785e-02],\n",
      "          [-1.4297e-02, -7.8678e-02, -1.5567e-03,  1.2376e-02, -3.5361e-02],\n",
      "          [ 8.9896e-03, -1.9421e-02,  1.9599e-02,  5.7889e-02,  2.3456e-02],\n",
      "          [ 5.5495e-02,  9.8853e-02,  4.6646e-02,  5.2015e-03, -5.1796e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6866e-02, -5.7591e-02,  3.1493e-03, -4.0816e-02,  6.0441e-02],\n",
      "          [ 2.3565e-02, -4.5875e-02, -2.1572e-02, -1.0109e-01, -5.1173e-02],\n",
      "          [ 6.6626e-04, -2.8133e-02, -1.0331e-02, -2.8030e-02,  2.1308e-02],\n",
      "          [ 4.0688e-03, -4.4783e-02, -3.3728e-02,  1.5481e-02,  1.4099e-02],\n",
      "          [-1.8948e-02,  2.4930e-02, -5.5822e-03,  8.0848e-04,  6.2247e-02]],\n",
      "\n",
      "         [[ 1.7089e-03, -1.4260e-03, -2.9649e-02, -5.6904e-03, -8.7299e-02],\n",
      "          [-7.0125e-02,  8.4223e-03, -4.9111e-02,  2.9835e-02, -9.9270e-02],\n",
      "          [-2.9016e-02, -2.6785e-02,  2.0733e-02, -3.3618e-02, -4.3039e-02],\n",
      "          [-4.3436e-02,  8.7250e-02,  1.2015e-02, -4.3854e-02, -5.2172e-03],\n",
      "          [ 6.0079e-02,  6.6515e-02, -5.1182e-02, -6.2026e-02, -3.6293e-03]],\n",
      "\n",
      "         [[-5.9858e-02, -6.3491e-02, -6.1353e-02, -4.9699e-02, -5.5503e-02],\n",
      "          [ 1.0492e-02,  2.3532e-02, -2.7406e-02, -5.2743e-02,  1.6500e-02],\n",
      "          [ 4.0293e-02,  3.7683e-02,  2.0171e-02, -6.0324e-02,  6.5306e-03],\n",
      "          [-2.5716e-02,  3.2979e-02, -1.2356e-03, -6.4065e-02,  3.4638e-02],\n",
      "          [-3.6774e-02,  2.9745e-02, -4.8901e-02, -4.3989e-02, -4.5289e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.7590e-02, -6.4207e-02, -5.2724e-02, -8.0992e-02, -4.1277e-02],\n",
      "          [-1.8134e-02, -3.5735e-02, -6.0987e-02, -2.7789e-02, -2.8962e-02],\n",
      "          [-6.2637e-02, -8.3024e-02, -3.1093e-02,  1.7744e-02, -3.6911e-02],\n",
      "          [ 1.5997e-02,  1.6787e-02, -1.8647e-02,  5.5755e-02, -3.3706e-02],\n",
      "          [-3.4657e-02,  8.3804e-02,  6.0545e-02, -5.0329e-02,  3.6894e-02]],\n",
      "\n",
      "         [[-1.0667e-02, -8.5392e-02,  2.6632e-03,  7.8371e-02, -1.0318e-02],\n",
      "          [ 7.1239e-03, -6.8405e-03, -2.1118e-02, -2.8758e-02, -1.5621e-02],\n",
      "          [ 4.4714e-02, -9.9590e-03, -8.3868e-03,  5.3878e-02, -2.0221e-02],\n",
      "          [ 3.6293e-02,  2.5353e-02,  5.7997e-02, -3.0839e-02,  4.6672e-03],\n",
      "          [ 2.0540e-02, -1.3558e-02,  7.3120e-02,  1.7634e-04, -6.8220e-03]],\n",
      "\n",
      "         [[-3.1518e-02, -3.8990e-02, -5.8727e-02,  6.5725e-04,  5.9327e-02],\n",
      "          [-3.7364e-02, -7.7916e-02,  8.6798e-03, -7.1459e-02, -7.1187e-02],\n",
      "          [-2.1398e-02, -5.4379e-03,  3.4405e-02, -7.1477e-02,  4.1129e-03],\n",
      "          [-1.0182e-02, -7.4666e-03,  2.9904e-02,  6.9493e-04, -6.7241e-03],\n",
      "          [-4.9562e-02,  1.5155e-02,  3.7462e-02, -1.8511e-02, -4.8280e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.1339e-03,  8.4189e-03,  4.3440e-02, -7.9852e-03, -3.7726e-02],\n",
      "          [ 5.2255e-03,  4.4103e-02,  5.8329e-02, -1.8623e-02,  1.0667e-02],\n",
      "          [ 3.2406e-02,  3.9169e-02, -2.5899e-02,  2.9971e-02,  5.7922e-02],\n",
      "          [ 1.4326e-03,  3.8192e-02,  2.6525e-02,  9.3516e-03,  1.1026e-02],\n",
      "          [ 3.0788e-02, -7.1708e-04, -3.2048e-02, -5.2492e-02, -8.5100e-03]],\n",
      "\n",
      "         [[-1.3711e-02,  1.0046e-01,  2.1563e-02, -7.1808e-03, -8.6099e-03],\n",
      "          [ 5.2438e-02, -5.6260e-03, -5.3521e-03,  1.4941e-02,  4.2586e-02],\n",
      "          [-6.8937e-02, -1.8444e-02,  1.9024e-03,  3.2972e-02,  9.4033e-02],\n",
      "          [ 4.0607e-02, -1.2591e-02, -1.0298e-02,  4.5793e-02, -2.0688e-02],\n",
      "          [ 2.3729e-02,  9.6843e-03, -5.6781e-02, -3.9078e-03, -4.9404e-02]],\n",
      "\n",
      "         [[ 5.7335e-02, -7.6890e-03, -1.8533e-02,  4.6999e-02, -1.8375e-02],\n",
      "          [-1.9228e-02,  5.5115e-02,  3.8307e-03, -6.7483e-02,  1.5592e-02],\n",
      "          [-4.8174e-02, -4.6984e-02, -7.0075e-02, -5.4064e-02, -3.2775e-02],\n",
      "          [-3.7309e-02, -3.6993e-02, -8.0007e-02,  1.4629e-02, -9.6550e-02],\n",
      "          [-4.4021e-02,  2.6853e-02, -4.2519e-02, -2.5301e-02, -4.4486e-02]]]],\n",
      "       requires_grad=True))\n",
      "('conv2.conv_i.bias', Parameter containing:\n",
      "tensor([ 0.0205, -0.0040, -0.0325,  0.0702,  0.0389, -0.0284,  0.0456, -0.0406,\n",
      "         0.0054, -0.0554,  0.0348, -0.0223,  0.0347, -0.0023,  0.0424, -0.0081,\n",
      "         0.0323, -0.0533,  0.0646, -0.0379], requires_grad=True))\n",
      "('fc1.fc_r.weight', Parameter containing:\n",
      "tensor([[ 0.0445, -0.0200, -0.0417,  ..., -0.0239,  0.0028,  0.0524],\n",
      "        [-0.0505, -0.0293, -0.0392,  ..., -0.0406,  0.0452, -0.0174],\n",
      "        [-0.0419, -0.0322,  0.0456,  ...,  0.0541,  0.0025, -0.0541],\n",
      "        ...,\n",
      "        [-0.0353, -0.0377,  0.0161,  ...,  0.0282, -0.0167, -0.0621],\n",
      "        [-0.0268,  0.0423,  0.0332,  ..., -0.0033,  0.0334,  0.0428],\n",
      "        [ 0.0353, -0.0255, -0.0181,  ...,  0.0005, -0.0260, -0.0111]],\n",
      "       requires_grad=True))\n",
      "('fc1.fc_r.bias', Parameter containing:\n",
      "tensor([ 0.0457, -0.0572,  0.0068,  0.0434, -0.0066, -0.0496, -0.0042, -0.0529,\n",
      "        -0.0368,  0.0295, -0.0120,  0.0472, -0.0109, -0.0485, -0.0246,  0.0494,\n",
      "        -0.0175, -0.0204,  0.0310, -0.0347, -0.0083, -0.0107, -0.0560, -0.0223,\n",
      "        -0.0529,  0.0244,  0.0527,  0.0393, -0.0427,  0.0025,  0.0132,  0.0020,\n",
      "         0.0533,  0.0014, -0.0287,  0.0054,  0.0159, -0.0488,  0.0452,  0.0285,\n",
      "        -0.0264,  0.0366,  0.0371, -0.0514,  0.0296,  0.0071, -0.0556,  0.0451,\n",
      "         0.0401, -0.0014, -0.0201, -0.0554, -0.0545,  0.0087, -0.0447,  0.0287,\n",
      "         0.0446,  0.0148,  0.0234, -0.0499, -0.0179,  0.0290,  0.0437,  0.0443,\n",
      "        -0.0372,  0.0012,  0.0452, -0.0348, -0.0036,  0.0218, -0.0229, -0.0176,\n",
      "         0.0081,  0.0210,  0.0265,  0.0279, -0.0432,  0.0418,  0.0442,  0.0289,\n",
      "         0.0413, -0.0371, -0.0059, -0.0392,  0.0479, -0.0508,  0.0065,  0.0119,\n",
      "        -0.0040, -0.0407,  0.0186,  0.0205,  0.0005,  0.0371,  0.0349,  0.0146,\n",
      "        -0.0086,  0.0342,  0.0198, -0.0099,  0.0337,  0.0168, -0.0156, -0.0334,\n",
      "         0.0039, -0.0278, -0.0037, -0.0307, -0.0267, -0.0203, -0.0468, -0.0129,\n",
      "         0.0293, -0.0506, -0.0087, -0.0234,  0.0238,  0.0322,  0.0439,  0.0301,\n",
      "         0.0182,  0.0159, -0.0203, -0.0079, -0.0045, -0.0370,  0.0413, -0.0211,\n",
      "        -0.0037,  0.0104, -0.0277,  0.0302,  0.0184, -0.0059, -0.0480, -0.0181,\n",
      "         0.0551,  0.0220, -0.0050, -0.0275, -0.0468, -0.0484, -0.0340,  0.0007,\n",
      "         0.0361,  0.0478,  0.0142, -0.0238, -0.0222, -0.0287,  0.0395, -0.0030,\n",
      "        -0.0233, -0.0118,  0.0234,  0.0077,  0.0348,  0.0186, -0.0432, -0.0258,\n",
      "        -0.0029,  0.0103, -0.0145,  0.0029,  0.0239, -0.0428,  0.0425, -0.0341,\n",
      "        -0.0287, -0.0487, -0.0127, -0.0235, -0.0420, -0.0468,  0.0048,  0.0199,\n",
      "         0.0403, -0.0488, -0.0097, -0.0490,  0.0561, -0.0333,  0.0005, -0.0107,\n",
      "         0.0445,  0.0192,  0.0371,  0.0540,  0.0394, -0.0531,  0.0523, -0.0230,\n",
      "         0.0475, -0.0605, -0.0551,  0.0259, -0.0253,  0.0028, -0.0014, -0.0403,\n",
      "        -0.0145,  0.0491,  0.0443, -0.0496,  0.0464, -0.0474, -0.0528,  0.0395,\n",
      "         0.0363,  0.0528,  0.0197, -0.0236, -0.0024,  0.0504,  0.0365, -0.0365,\n",
      "        -0.0361,  0.0576, -0.0474,  0.0171, -0.0283, -0.0526, -0.0062, -0.0200,\n",
      "         0.0101,  0.0434, -0.0455, -0.0484,  0.0049,  0.0475, -0.0549,  0.0255,\n",
      "        -0.0068,  0.0476, -0.0367, -0.0193, -0.0114, -0.0117,  0.0163,  0.0449,\n",
      "        -0.0472, -0.0431, -0.0140, -0.0540, -0.0284, -0.0248,  0.0541, -0.0111,\n",
      "         0.0461, -0.0376,  0.0412, -0.0058, -0.0393, -0.0317, -0.0487, -0.0264,\n",
      "        -0.0267,  0.0527,  0.0008, -0.0133, -0.0294,  0.0399,  0.0494, -0.0492,\n",
      "         0.0251,  0.0095,  0.0545,  0.0343, -0.0186, -0.0317, -0.0201,  0.0465,\n",
      "        -0.0497, -0.0145, -0.0517, -0.0268, -0.0285, -0.0071,  0.0035,  0.0175,\n",
      "         0.0085, -0.0209, -0.0219,  0.0185,  0.0376, -0.0031, -0.0060, -0.0335,\n",
      "        -0.0394,  0.0320,  0.0109,  0.0020, -0.0288, -0.0218, -0.0092,  0.0496,\n",
      "        -0.0095,  0.0411,  0.0534, -0.0550,  0.0378, -0.0140,  0.0491, -0.0125,\n",
      "        -0.0482,  0.0245, -0.0579, -0.0373, -0.0214, -0.0543, -0.0042,  0.0359,\n",
      "        -0.0168,  0.0287, -0.0355,  0.0399,  0.0338, -0.0129,  0.0333,  0.0282,\n",
      "        -0.0521, -0.0079, -0.0129,  0.0460, -0.0336,  0.0182,  0.0438, -0.0137,\n",
      "         0.0082, -0.0021,  0.0170,  0.0256, -0.0574, -0.0227, -0.0183,  0.0508,\n",
      "        -0.0322,  0.0427,  0.0183,  0.0329,  0.0511, -0.0007, -0.0039,  0.0410,\n",
      "         0.0123, -0.0525, -0.0504,  0.0185,  0.0341,  0.0367, -0.0527, -0.0297,\n",
      "        -0.0425,  0.0434, -0.0330, -0.0467,  0.0011,  0.0034,  0.0465,  0.0412,\n",
      "         0.0145, -0.0448, -0.0327,  0.0336, -0.0210,  0.0512, -0.0343,  0.0089,\n",
      "         0.0271,  0.0380, -0.0105, -0.0478,  0.0450,  0.0080,  0.0092,  0.0104,\n",
      "         0.0375, -0.0275, -0.0114, -0.0206, -0.0409,  0.0407,  0.0449,  0.0133,\n",
      "        -0.0360,  0.0522, -0.0025,  0.0415, -0.0517, -0.0373, -0.0182, -0.0273,\n",
      "         0.0214, -0.0091, -0.0111, -0.0479,  0.0158,  0.0301,  0.0288, -0.0257,\n",
      "         0.0208,  0.0408,  0.0353, -0.0523,  0.0005,  0.0396, -0.0451, -0.0209,\n",
      "         0.0159,  0.0283, -0.0062,  0.0161, -0.0343, -0.0547, -0.0105, -0.0529,\n",
      "        -0.0255, -0.0314, -0.0541,  0.0527, -0.0275,  0.0446, -0.0091,  0.0499,\n",
      "        -0.0158,  0.0436,  0.0195, -0.0427,  0.0049, -0.0470,  0.0225,  0.0518,\n",
      "         0.0207,  0.0110, -0.0513,  0.0440,  0.0146, -0.0049, -0.0304, -0.0554,\n",
      "        -0.0192, -0.0167, -0.0255, -0.0313,  0.0276,  0.0088, -0.0217,  0.0344,\n",
      "        -0.0464, -0.0457, -0.0077, -0.0541,  0.0459,  0.0142,  0.0355,  0.0395,\n",
      "         0.0491,  0.0242,  0.0353,  0.0075,  0.0479,  0.0096, -0.0136, -0.0545,\n",
      "         0.0124, -0.0114,  0.0236,  0.0015, -0.0180,  0.0032,  0.0335, -0.0327,\n",
      "         0.0320,  0.0302,  0.0289,  0.0309, -0.0392,  0.0204, -0.0218,  0.0392,\n",
      "        -0.0527,  0.0430, -0.0057, -0.0360,  0.0054, -0.0426,  0.0379, -0.0059,\n",
      "         0.0087, -0.0034,  0.0261, -0.0545, -0.0073, -0.0177, -0.0256,  0.0321,\n",
      "        -0.0022, -0.0510, -0.0118, -0.0175], requires_grad=True))\n",
      "('fc1.fc_i.weight', Parameter containing:\n",
      "tensor([[-0.0286,  0.0577,  0.0207,  ...,  0.0403,  0.0176,  0.0141],\n",
      "        [-0.0356, -0.0066,  0.0053,  ...,  0.0112, -0.0410, -0.0419],\n",
      "        [ 0.0003,  0.0370,  0.0006,  ...,  0.0434, -0.0049,  0.0236],\n",
      "        ...,\n",
      "        [-0.0224,  0.0655,  0.0175,  ...,  0.0261,  0.0345,  0.0540],\n",
      "        [ 0.0375, -0.0287, -0.0337,  ..., -0.0444, -0.0368,  0.0011],\n",
      "        [-0.0069, -0.0034,  0.0287,  ...,  0.0043, -0.0027, -0.0612]],\n",
      "       requires_grad=True))\n",
      "('fc1.fc_i.bias', Parameter containing:\n",
      "tensor([ 3.2389e-02,  1.9889e-03, -1.1884e-02,  2.8917e-02, -5.1455e-02,\n",
      "        -5.1518e-02,  2.0275e-02, -5.2103e-02,  4.2096e-02,  3.0876e-02,\n",
      "         5.1434e-02, -2.1321e-02,  2.5542e-02,  1.4896e-02, -2.3489e-02,\n",
      "        -4.9444e-02, -7.8162e-03,  4.5750e-02, -2.1923e-02, -3.3797e-02,\n",
      "        -2.2862e-02, -2.4647e-02,  1.0145e-02, -3.2660e-02,  3.4906e-02,\n",
      "        -3.4524e-02, -1.9640e-02, -2.0401e-02, -4.7079e-02, -7.9265e-03,\n",
      "         5.0065e-02,  1.1346e-02,  1.2745e-02, -1.5263e-02, -3.3063e-02,\n",
      "         3.6145e-03,  2.6483e-02,  3.2358e-02,  4.6673e-02, -2.4199e-03,\n",
      "        -4.2743e-02, -5.8426e-03, -3.4221e-02,  4.4290e-02, -4.8655e-02,\n",
      "         1.9076e-03, -5.4509e-02, -3.5197e-02, -4.9811e-02, -4.0874e-02,\n",
      "        -2.9955e-02, -5.4249e-02, -3.8733e-02, -8.7510e-03,  5.5490e-03,\n",
      "         2.9353e-02, -4.2009e-02,  9.1579e-03, -3.3093e-02,  2.3092e-02,\n",
      "         2.7620e-02, -3.5831e-02,  2.3794e-03, -5.1472e-02,  5.4670e-02,\n",
      "        -4.0056e-02,  2.3322e-02, -5.2622e-02,  4.0080e-02,  5.1029e-02,\n",
      "         4.4409e-02,  4.2416e-02, -1.4521e-02,  1.4223e-02,  2.0558e-03,\n",
      "        -6.7828e-03, -1.7969e-02, -3.9822e-03,  4.9543e-03, -7.1521e-03,\n",
      "         3.6793e-02,  2.0123e-03,  5.2516e-02,  2.9753e-02, -3.3768e-02,\n",
      "         4.2534e-02, -4.7527e-02,  2.7086e-02, -8.3894e-03,  5.2711e-02,\n",
      "        -3.0818e-03,  4.2498e-02, -5.3039e-02, -5.9323e-03, -2.4913e-02,\n",
      "         2.8549e-02, -1.0754e-02,  2.3739e-02,  1.5402e-02, -1.4540e-03,\n",
      "         3.5349e-02, -1.2282e-02,  1.3562e-02,  2.4954e-02, -5.1331e-02,\n",
      "        -5.1591e-02, -1.4022e-02,  5.1016e-02, -5.4209e-03,  5.8324e-03,\n",
      "         4.6636e-02,  4.3384e-02, -2.5081e-02, -2.3059e-02, -4.9583e-03,\n",
      "         2.0455e-02, -2.8726e-03,  2.6824e-02, -3.0931e-02, -4.4318e-02,\n",
      "         2.0719e-02,  6.1609e-03, -3.7164e-02, -2.3431e-02, -2.8227e-02,\n",
      "        -2.8352e-02, -2.2106e-02, -4.1332e-02,  2.0869e-02,  3.1628e-02,\n",
      "        -3.7731e-02,  2.3826e-02, -1.9430e-02,  3.6193e-02,  2.0416e-02,\n",
      "         4.6462e-02, -4.8712e-02, -2.0248e-02,  7.1989e-03,  3.7540e-02,\n",
      "        -1.4859e-02,  1.8016e-02, -3.5639e-02, -2.5066e-02,  1.7607e-02,\n",
      "        -3.6569e-02,  9.1169e-03,  2.0105e-02,  3.7447e-02, -3.9527e-02,\n",
      "         5.0215e-02,  3.5527e-02, -1.2025e-02,  3.1800e-02, -4.2875e-02,\n",
      "         3.1840e-04, -9.5859e-03,  6.9982e-03, -2.2200e-03, -4.7073e-02,\n",
      "         5.3237e-02,  1.4371e-02, -5.4815e-02, -3.5069e-02,  2.8537e-02,\n",
      "         1.8622e-03,  1.2604e-03,  1.4072e-02, -1.3389e-02,  3.8850e-02,\n",
      "        -6.9807e-03,  1.1681e-02, -5.0488e-02,  4.3517e-02, -2.7397e-03,\n",
      "         4.7865e-02, -3.8263e-03,  6.6322e-03, -2.3224e-03, -5.5011e-02,\n",
      "         3.7877e-02, -5.3795e-03, -4.6243e-02, -3.6912e-02,  1.8449e-02,\n",
      "        -1.6262e-02, -5.6030e-03, -4.0856e-02,  3.7604e-02, -1.2392e-02,\n",
      "         3.2619e-02, -2.1386e-02,  4.4500e-03,  4.6737e-02, -4.3810e-03,\n",
      "        -4.9459e-03, -3.7585e-02,  4.4631e-02, -1.0011e-02, -7.8060e-03,\n",
      "        -8.4254e-03,  5.6669e-02, -1.4771e-02,  4.2844e-02,  3.7069e-02,\n",
      "        -4.7478e-02, -5.2985e-02, -5.4755e-02,  2.5405e-03, -1.3493e-02,\n",
      "        -5.5281e-02, -3.6695e-02, -5.3290e-02,  1.6013e-02,  3.8711e-02,\n",
      "         4.7594e-02, -5.3894e-02, -5.2851e-02, -3.7962e-02, -5.5021e-03,\n",
      "         6.5572e-03,  1.5511e-02,  4.4717e-02, -3.4693e-02, -3.0046e-02,\n",
      "        -5.0401e-05,  4.7665e-02, -2.1851e-02, -1.7937e-02,  2.5462e-02,\n",
      "        -5.2538e-02, -4.5503e-02,  4.6881e-02,  4.3828e-02,  4.4107e-02,\n",
      "         3.2017e-02,  2.3617e-02, -5.1162e-02,  1.1144e-02,  5.0098e-02,\n",
      "        -5.2033e-02, -4.5680e-02,  4.1186e-02, -4.7375e-02,  3.2124e-02,\n",
      "         3.7550e-02,  3.9416e-02, -5.1522e-02, -1.8101e-02, -1.1745e-02,\n",
      "        -6.4035e-03, -5.1726e-03,  2.6462e-02, -4.2679e-02, -4.9016e-02,\n",
      "         3.6708e-02, -7.6271e-04, -3.5803e-03,  5.4453e-02,  4.5405e-02,\n",
      "        -2.1692e-02, -9.9758e-04,  4.4515e-02, -2.0316e-02,  4.6812e-02,\n",
      "         3.5750e-02, -1.3145e-02,  3.6877e-02,  5.1149e-02,  3.5009e-02,\n",
      "         3.9715e-02, -1.2061e-02, -4.4173e-02,  2.1619e-02, -1.7033e-02,\n",
      "         1.2144e-02,  4.3436e-02, -2.2238e-02, -5.9837e-03,  4.6023e-04,\n",
      "        -5.3063e-02,  1.3123e-02,  1.2743e-02, -1.7295e-02, -4.1753e-02,\n",
      "         4.7224e-03, -2.2732e-02,  4.2290e-02,  3.1464e-02,  7.7600e-03,\n",
      "         4.9686e-02,  3.7627e-04, -3.3484e-02,  2.0641e-02, -4.9450e-02,\n",
      "        -2.2570e-02, -4.8848e-02, -3.3383e-02,  5.2751e-03,  5.3685e-02,\n",
      "         8.7551e-03,  1.1712e-02, -4.5901e-02,  2.0623e-02, -1.1822e-02,\n",
      "        -2.9861e-02, -5.0329e-03,  1.9210e-02,  3.5805e-02,  5.2742e-02,\n",
      "         8.3413e-03,  2.4075e-02, -1.4240e-02, -4.8082e-02, -5.4725e-02,\n",
      "         3.3681e-02, -3.5508e-03,  4.1298e-03, -1.1731e-02,  9.9929e-03,\n",
      "        -3.7244e-03, -4.4241e-02, -2.5410e-02, -3.5739e-02,  7.8935e-03,\n",
      "        -5.2255e-02, -4.9571e-02,  1.5412e-02, -1.2455e-02,  1.0798e-02,\n",
      "         3.0444e-02,  5.3912e-02, -2.8988e-02,  2.9783e-02, -5.0199e-02,\n",
      "         5.0699e-02,  2.3838e-02, -3.2264e-02, -5.5170e-02,  6.0136e-03,\n",
      "        -5.4603e-02, -4.9630e-02,  6.3465e-03,  4.2081e-02,  2.2814e-02,\n",
      "        -1.2979e-02, -9.1230e-03,  1.6409e-02, -5.2562e-02,  1.3257e-02,\n",
      "        -4.7370e-04, -1.6967e-02,  1.4435e-02, -1.8003e-02,  2.1207e-02,\n",
      "         7.6429e-03, -2.4496e-02, -1.0325e-02,  4.4827e-02, -4.1591e-02,\n",
      "        -1.0265e-02,  3.2165e-02, -4.1711e-02,  7.4615e-03, -3.0825e-02,\n",
      "         4.6604e-02, -1.9685e-02, -1.4398e-02,  5.8787e-03, -5.3629e-02,\n",
      "        -5.6061e-02, -2.0403e-02,  1.2355e-02, -5.2846e-02,  3.3960e-02,\n",
      "        -4.4224e-02, -5.1269e-02, -1.5760e-02, -4.4154e-02, -4.9846e-02,\n",
      "        -1.9088e-02,  2.9114e-02, -1.6385e-02,  2.7860e-02,  2.2321e-02,\n",
      "         3.2100e-02, -4.0834e-02, -5.1467e-02,  6.5143e-03,  2.6889e-02,\n",
      "         4.4890e-02, -5.0198e-03, -4.1945e-02,  4.9303e-02,  1.7093e-02,\n",
      "        -4.3745e-02,  2.2209e-02,  3.1400e-02,  2.1832e-03,  5.2187e-02,\n",
      "        -4.8918e-02,  5.4164e-02, -1.9909e-02,  1.7018e-02, -5.6583e-03,\n",
      "        -4.5789e-02,  1.4669e-02,  3.8549e-02, -1.8964e-02, -4.2187e-02,\n",
      "        -6.9114e-03, -1.6780e-02,  5.7814e-02, -3.3142e-02, -4.8421e-02,\n",
      "        -4.2245e-02,  1.6135e-02,  5.3405e-02, -3.3589e-03,  2.8906e-02,\n",
      "         2.2320e-02, -4.1060e-02,  2.9618e-02,  4.0162e-03, -3.7249e-02,\n",
      "        -1.5626e-02, -1.6688e-02, -4.4405e-03,  3.6383e-02, -5.0076e-02,\n",
      "        -5.1269e-02,  3.0512e-02, -3.1205e-02,  7.9881e-03, -9.2847e-03,\n",
      "         7.8348e-04, -1.7487e-02,  4.7844e-02, -1.7282e-02, -3.9525e-02,\n",
      "        -4.9505e-02, -2.9977e-02,  3.0806e-02, -5.4188e-02, -3.2561e-02,\n",
      "        -4.1847e-02, -5.2595e-02, -3.3552e-02, -8.3076e-03, -2.8032e-02,\n",
      "        -3.5820e-03,  5.5497e-04, -4.6331e-02,  4.1674e-02,  1.6678e-02,\n",
      "         3.7043e-02, -1.0678e-02,  4.4867e-02,  2.6106e-02,  2.7595e-02,\n",
      "         3.4034e-02, -3.6400e-02,  2.6678e-02,  8.2648e-03,  4.6130e-02,\n",
      "        -1.0827e-02,  3.1663e-02,  4.4499e-03, -1.0750e-02,  2.3626e-02,\n",
      "        -3.2213e-02, -5.2760e-02,  5.2077e-02,  2.6892e-02,  2.8116e-02,\n",
      "         1.2735e-06, -1.5990e-02,  4.1067e-02, -4.5851e-02,  1.4319e-02,\n",
      "        -2.0429e-03, -3.9127e-02, -4.9260e-02, -2.1402e-02,  1.6803e-02,\n",
      "        -1.1537e-02, -6.3896e-03, -3.3333e-02, -4.8992e-02,  4.2154e-02,\n",
      "         4.5755e-02,  9.0198e-03,  5.3029e-02,  7.0688e-03,  3.7743e-03,\n",
      "        -3.6553e-02,  3.3872e-02, -2.0056e-02, -8.8857e-04,  4.2275e-02],\n",
      "       requires_grad=True))\n",
      "('fc2.fc_r.weight', Parameter containing:\n",
      "tensor([[-0.0123,  0.0065, -0.0335,  ...,  0.0040, -0.0320,  0.0669],\n",
      "        [ 0.0553, -0.0553, -0.0042,  ..., -0.0689,  0.0320, -0.0037],\n",
      "        [ 0.0022,  0.0149,  0.0568,  ...,  0.0371, -0.0507,  0.0126],\n",
      "        ...,\n",
      "        [ 0.0292, -0.0215,  0.0825,  ...,  0.0153,  0.0073, -0.0283],\n",
      "        [-0.0205, -0.0106,  0.0438,  ..., -0.1447, -0.0017, -0.0673],\n",
      "        [-0.0665, -0.0208, -0.0673,  ..., -0.0479, -0.0003,  0.0185]],\n",
      "       requires_grad=True))\n",
      "('fc2.fc_r.bias', Parameter containing:\n",
      "tensor([ 0.0531,  0.0202, -0.0037,  0.0055, -0.0113,  0.0138,  0.0413, -0.0134,\n",
      "        -0.0371,  0.0053], requires_grad=True))\n",
      "('fc2.fc_i.weight', Parameter containing:\n",
      "tensor([[ 0.0246, -0.0028,  0.0021,  ..., -0.0408, -0.0226,  0.0220],\n",
      "        [-0.0097,  0.0522, -0.0062,  ...,  0.0305,  0.0498, -0.0200],\n",
      "        [ 0.0739,  0.0031, -0.0013,  ..., -0.0152,  0.0197, -0.0091],\n",
      "        ...,\n",
      "        [ 0.0748, -0.0262,  0.0001,  ..., -0.0778,  0.0073, -0.0128],\n",
      "        [ 0.0456,  0.0418, -0.0371,  ...,  0.0464, -0.0052,  0.0149],\n",
      "        [-0.0392, -0.0462, -0.0065,  ..., -0.0101,  0.0300,  0.0257]],\n",
      "       requires_grad=True))\n",
      "('fc2.fc_i.bias', Parameter containing:\n",
      "tensor([-0.0249, -0.0532,  0.0281,  0.0207, -0.0277,  0.0063,  0.0286,  0.0096,\n",
      "        -0.0271,  0.0219], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for layer in model.named_parameters():\n",
    "    print(layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML",
   "language": "python",
   "name": "qml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
