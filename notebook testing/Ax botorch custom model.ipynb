{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce0ec227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.priors import GammaPrior\n",
    "\n",
    "\n",
    "class SimpleCustomGP(ExactGP, GPyTorchModel):\n",
    "\n",
    "    _num_outputs = 1  # to inform GPyTorchModel API\n",
    "    \n",
    "    def __init__(self, train_X, train_Y):\n",
    "        # squeeze output dim before passing train_Y to ExactGP\n",
    "        super().__init__(train_X, train_Y.squeeze(-1), GaussianLikelihood())\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.covar_module = ScaleKernel(\n",
    "            base_kernel=RBFKernel(ard_num_dims=train_X.shape[-1]),\n",
    "        )\n",
    "        self.to(train_X)  # make sure we're on the right device/dtype\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d1c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.fit import fit_gpytorch_model\n",
    "\n",
    "def _get_and_fit_simple_custom_gp(Xs, Ys, **kwargs):\n",
    "    model = SimpleCustomGP(Xs[0], Ys[0])\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c39b4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def branin(parameterization, *args):\n",
    "    x1, x2 = parameterization[\"x1\"], parameterization[\"x2\"]\n",
    "    y = (x2 - 5.1 / (4 * np.pi ** 2) * x1 ** 2 + 5 * x1 / np.pi - 6) ** 2\n",
    "    y += 10 * (1 - 1 / (8 * np.pi)) * np.cos(x1) + 10\n",
    "    # let's add some synthetic observation noise\n",
    "    y += random.normalvariate(0, 0.1)\n",
    "    return {\"branin\": (y, 0.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61f670d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax import ParameterType, RangeParameter, SearchSpace\n",
    "\n",
    "search_space = SearchSpace(\n",
    "    parameters=[\n",
    "        RangeParameter(\n",
    "            name=\"x1\", parameter_type=ParameterType.FLOAT, lower=-5, upper=10\n",
    "        ),\n",
    "        RangeParameter(\n",
    "            name=\"x2\", parameter_type=ParameterType.FLOAT, lower=0, upper=15\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb0546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax import SimpleExperiment\n",
    "\n",
    "exp = SimpleExperiment(\n",
    "    name=\"test_branin\",\n",
    "    search_space=search_space,\n",
    "    evaluation_function=branin,\n",
    "    objective_name=\"branin\",\n",
    "    minimize=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0ed5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchTrial(experiment_name='test_branin', index=0, status=TrialStatus.CANDIDATE)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ax.modelbridge import get_sobol\n",
    "\n",
    "sobol = get_sobol(exp.search_space)\n",
    "exp.new_batch_trial(generator_run=sobol.gen(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51353f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization batch 1/5...\n",
      "Running optimization batch 2/5...\n",
      "Running optimization batch 3/5...\n",
      "Running optimization batch 4/5...\n",
      "Running optimization batch 5/5...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from ax.modelbridge.factory import get_botorch\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Running optimization batch {i+1}/5...\")\n",
    "    model = get_botorch(\n",
    "        experiment=exp,\n",
    "        data=exp.eval(),\n",
    "        search_space=exp.search_space,\n",
    "        model_constructor=_get_and_fit_simple_custom_gp,\n",
    "    )\n",
    "    batch = exp.new_trial(generator_run=model.gen(1))\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "120f6057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TorchModelBridge in module ax.modelbridge.torch object:\n",
      "\n",
      "class TorchModelBridge(ax.modelbridge.array.ArrayModelBridge)\n",
      " |  TorchModelBridge(experiment: ax.core.experiment.Experiment, search_space: ax.core.search_space.SearchSpace, data: ax.core.data.Data, model: ax.models.torch_base.TorchModel, transforms: List[Type[ax.modelbridge.transforms.base.Transform]], transform_configs: Union[Dict[str, Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any], NoneType]]], NoneType] = None, torch_dtype: Union[torch.dtype, NoneType] = None, torch_device: Union[torch.device, NoneType] = None, status_quo_name: Union[str, NoneType] = None, status_quo_features: Union[ax.core.observation.ObservationFeatures, NoneType] = None, optimization_config: Union[ax.core.optimization_config.OptimizationConfig, NoneType] = None, fit_out_of_design: bool = False, default_model_gen_options: Union[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any], NoneType]], NoneType] = None) -> None\n",
      " |  \n",
      " |  A model bridge for using torch-based models.\n",
      " |  \n",
      " |  Specifies an interface that is implemented by TorchModel. In particular,\n",
      " |  model should have methods fit, predict, and gen. See TorchModel for the\n",
      " |  API for each of these methods.\n",
      " |  \n",
      " |  Requires that all parameters have been transformed to RangeParameters\n",
      " |  or FixedParameters with float type and no log scale.\n",
      " |  \n",
      " |  This class converts Ax parameter types to torch tensors before passing\n",
      " |  them to the model.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TorchModelBridge\n",
      " |      ax.modelbridge.array.ArrayModelBridge\n",
      " |      ax.modelbridge.base.ModelBridge\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, experiment: ax.core.experiment.Experiment, search_space: ax.core.search_space.SearchSpace, data: ax.core.data.Data, model: ax.models.torch_base.TorchModel, transforms: List[Type[ax.modelbridge.transforms.base.Transform]], transform_configs: Union[Dict[str, Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any], NoneType]]], NoneType] = None, torch_dtype: Union[torch.dtype, NoneType] = None, torch_device: Union[torch.device, NoneType] = None, status_quo_name: Union[str, NoneType] = None, status_quo_features: Union[ax.core.observation.ObservationFeatures, NoneType] = None, optimization_config: Union[ax.core.optimization_config.OptimizationConfig, NoneType] = None, fit_out_of_design: bool = False, default_model_gen_options: Union[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any], NoneType]], NoneType] = None) -> None\n",
      " |      Applies transforms and fits model.\n",
      " |      \n",
      " |      Args:\n",
      " |          experiment: Is used to get arm parameters. Is not mutated.\n",
      " |          search_space: Search space for fitting the model. Constraints need\n",
      " |              not be the same ones used in gen.\n",
      " |          data: Ax Data.\n",
      " |          model: Interface will be specified in subclass. If model requires\n",
      " |              initialization, that should be done prior to its use here.\n",
      " |          transforms: List of uninitialized transform classes. Forward\n",
      " |              transforms will be applied in this order, and untransforms in\n",
      " |              the reverse order.\n",
      " |          transform_configs: A dictionary from transform name to the\n",
      " |              transform config dictionary.\n",
      " |          status_quo_name: Name of the status quo arm. Can only be used if\n",
      " |              Data has a single set of ObservationFeatures corresponding to\n",
      " |              that arm.\n",
      " |          status_quo_features: ObservationFeatures to use as status quo.\n",
      " |              Either this or status_quo_name should be specified, not both.\n",
      " |          optimization_config: Optimization config defining how to optimize\n",
      " |              the model.\n",
      " |          fit_out_of_design: If specified, all training data is returned.\n",
      " |              Otherwise, only in design points are returned.\n",
      " |          fit_abandoned: Whether data for abandoned arms or trials should be\n",
      " |              included in model training data. If ``False``, only\n",
      " |              non-abandoned points are returned.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_default_model_gen_options': typing.Dict[str, typi...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ax.modelbridge.array.ArrayModelBridge:\n",
      " |  \n",
      " |  feature_importances(self, metric_name: str) -> Dict[str, float]\n",
      " |  \n",
      " |  model_best_point(self, search_space: Union[ax.core.search_space.SearchSpace, NoneType] = None, optimization_config: Union[ax.core.optimization_config.OptimizationConfig, NoneType] = None, pending_observations: Union[Dict[str, List[ax.core.observation.ObservationFeatures]], NoneType] = None, fixed_features: Union[ax.core.observation.ObservationFeatures, NoneType] = None, model_gen_options: Union[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any], NoneType]], NoneType] = None) -> Union[Tuple[ax.core.arm.Arm, Union[Tuple[Dict[str, float], Union[Dict[str, Dict[str, float]], NoneType]], NoneType]], NoneType]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ax.modelbridge.base.ModelBridge:\n",
      " |  \n",
      " |  cross_validate(self, cv_training_data: List[ax.core.observation.Observation], cv_test_points: List[ax.core.observation.ObservationFeatures]) -> List[ax.core.observation.ObservationData]\n",
      " |      Make a set of cross-validation predictions.\n",
      " |      \n",
      " |      Args:\n",
      " |          cv_training_data: The training data to use for cross validation.\n",
      " |          cv_test_points: The test points at which predictions will be made.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of predictions at the test points.\n",
      " |  \n",
      " |  evaluate_acquisition_function(self, observation_features: List[ax.core.observation.ObservationFeatures], search_space_digest: ax.core.search_space.SearchSpaceDigest, objective_weights: numpy.ndarray, objective_thresholds: Union[numpy.ndarray, NoneType] = None, outcome_constraints: Union[Tuple[numpy.ndarray, numpy.ndarray], NoneType] = None, linear_constraints: Union[Tuple[numpy.ndarray, numpy.ndarray], NoneType] = None, fixed_features: Union[Dict[int, float], NoneType] = None, pending_observations: Union[List[numpy.ndarray], NoneType] = None, acq_options: Union[Dict[str, Any], NoneType] = None) -> List[float]\n",
      " |      Evaluate the acquisition function for given set of observation\n",
      " |      features.\n",
      " |      \n",
      " |      Args:\n",
      " |          observation_features: A list of observation features, representing\n",
      " |              parameterizations, for which to evaluate the acquisition function.\n",
      " |          search_space_digest: A dataclass used to compactly represent a search space.\n",
      " |          objective_weights: The objective is to maximize a weighted sum of the\n",
      " |              columns of f(x). These are the weights.\n",
      " |          objective_thresholds:  The `m`-dim tensor of objective thresholds. There is\n",
      " |              one for each modeled metric.\n",
      " |          outcome_constraints: A tuple of (A, b). For k outcome constraints and m\n",
      " |              outputs at f(x), A is (k x m) and b is (k x 1) such that A f(x) <= b.\n",
      " |              (Not used by single task models)\n",
      " |          linear_constraints: A tuple of (A, b). For k linear constraints on\n",
      " |              d-dimensional x, A is (k x d) and b is (k x 1) such that A x <= b.\n",
      " |          fixed_features: A map {feature_index: value} for features that should be\n",
      " |              held fixed during the evaluation.\n",
      " |          pending_observations:  A list of m (k_i x d) feature tensors X for m\n",
      " |              outcomes and k_i pending observations for outcome i.\n",
      " |          acq_options: Keyword arguments used to contruct the acquisition function.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of acquisition function values, in the same order as the\n",
      " |          input observation features.\n",
      " |  \n",
      " |  gen(self, n: int, search_space: Union[ax.core.search_space.SearchSpace, NoneType] = None, optimization_config: Union[ax.core.optimization_config.OptimizationConfig, NoneType] = None, pending_observations: Union[Dict[str, List[ax.core.observation.ObservationFeatures]], NoneType] = None, fixed_features: Union[ax.core.observation.ObservationFeatures, NoneType] = None, model_gen_options: Union[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any], NoneType]], NoneType] = None) -> ax.core.generator_run.GeneratorRun\n",
      " |      Args:\n",
      " |          n: Number of points to generate\n",
      " |          search_space: Search space\n",
      " |          optimization_config: Optimization config\n",
      " |          pending_observations: A map from metric name to pending\n",
      " |              observations for that metric.\n",
      " |          fixed_features: An ObservationFeatures object containing any\n",
      " |              features that should be fixed at specified values during\n",
      " |              generation.\n",
      " |          model_gen_options: A config dictionary that is passed along to the\n",
      " |              model.\n",
      " |  \n",
      " |  get_training_data(self) -> List[ax.core.observation.Observation]\n",
      " |      A copy of the (untransformed) data with which the model was fit.\n",
      " |  \n",
      " |  predict(self, observation_features: List[ax.core.observation.ObservationFeatures]) -> Tuple[Dict[str, List[float]], Dict[str, Dict[str, List[float]]]]\n",
      " |      Make model predictions (mean and covariance) for the given\n",
      " |      observation features.\n",
      " |      \n",
      " |      Predictions are made for all outcomes.\n",
      " |      If an out-of-design observation can successfully be transformed,\n",
      " |      the predicted value will be returned.\n",
      " |      Othwerise, we will attempt to find that observation in the training data\n",
      " |      and return the raw value.\n",
      " |      \n",
      " |      Args:\n",
      " |          observation_features: observation features\n",
      " |      \n",
      " |      Returns:\n",
      " |          2-element tuple containing\n",
      " |      \n",
      " |          - Dictionary from metric name to list of mean estimates, in same\n",
      " |            order as observation_features.\n",
      " |          - Nested dictionary with cov['metric1']['metric2'] a list of\n",
      " |            cov(metric1@x, metric2@x) for x in observation_features.\n",
      " |  \n",
      " |  transform_observation_data(self, observation_data: List[ax.core.observation.ObservationData]) -> Any\n",
      " |      Applies transforms to given observation features and returns them in the\n",
      " |      model space.\n",
      " |      \n",
      " |      Args:\n",
      " |          observation_features: ObservationFeatures to be transformed.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Transformed values. This could be e.g. a torch Tensor, depending\n",
      " |          on the ModelBridge subclass.\n",
      " |  \n",
      " |  transform_observation_features(self, observation_features: List[ax.core.observation.ObservationFeatures]) -> Any\n",
      " |      Applies transforms to given observation features and returns them in the\n",
      " |      model space.\n",
      " |      \n",
      " |      Args:\n",
      " |          observation_features: ObservationFeatures to be transformed.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Transformed values. This could be e.g. a torch Tensor, depending\n",
      " |          on the ModelBridge subclass.\n",
      " |  \n",
      " |  transform_optimization_config(self, optimization_config: ax.core.optimization_config.OptimizationConfig, fixed_features: ax.core.observation.ObservationFeatures) -> Any\n",
      " |      Applies transforms to given optimization config.\n",
      " |      \n",
      " |      Args:\n",
      " |          optimization_config: OptimizationConfig to transform.\n",
      " |          fixed_features: features which should not be transformed.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Transformed values. This could be e.g. a torch Tensor, depending\n",
      " |          on the ModelBridge subclass.\n",
      " |  \n",
      " |  update(self, new_data: ax.core.data.Data, experiment: ax.core.experiment.Experiment) -> None\n",
      " |      Update the model bridge and the underlying model with new data. This\n",
      " |      method should be used instead of `fit`, in cases where the underlying\n",
      " |      model does not need to be re-fit from scratch, but rather updated.\n",
      " |      \n",
      " |      Note: `update` expects only new data (obtained since the model initialization\n",
      " |      or last update) to be passed in, not all data in the experiment.\n",
      " |      \n",
      " |      Args:\n",
      " |          new_data: Data from the experiment obtained since the last call to\n",
      " |              `update`.\n",
      " |          experiment: Experiment, in which this data was obtained.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from ax.modelbridge.base.ModelBridge:\n",
      " |  \n",
      " |  metric_names\n",
      " |      Metric names present in training data.\n",
      " |  \n",
      " |  model_space\n",
      " |      SearchSpace used to fit model.\n",
      " |  \n",
      " |  status_quo\n",
      " |      Observation corresponding to status quo, if any.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ax.modelbridge.base.ModelBridge:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  training_in_design\n",
      " |      For each observation in the training data, a bool indicating if it\n",
      " |      is in-design for the model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML",
   "language": "python",
   "name": "qml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
