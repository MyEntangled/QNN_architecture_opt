{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1fa1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "X = torch.rand(20, 2) - 0.5\n",
    "Y = (torch.sin(2 * math.pi * X[:, 0]) + torch.cos(2 * math.pi * X[:, 1])).unsqueeze(-1)\n",
    "Y += 0.1 * torch.randn_like(Y)\n",
    "\n",
    "gp = SingleTaskGP(X, Y)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_model(mll);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d58dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import UpperConfidenceBound\n",
    "\n",
    "UCB = UpperConfidenceBound(gp, beta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b29f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.unsqueeze(-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "732a9cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CMAOptions in module cma.evolution_strategy:\n",
      "\n",
      "class CMAOptions(builtins.dict)\n",
      " |  CMAOptions(s=None, **kwargs)\n",
      " |  \n",
      " |  a dictionary with the available options and their default values\n",
      " |  for class `CMAEvolutionStrategy`.\n",
      " |  \n",
      " |  ``CMAOptions()`` returns a `dict` with all available options and their\n",
      " |  default values with a comment string.\n",
      " |  \n",
      " |  ``CMAOptions('verb')`` returns a subset of recognized options that\n",
      " |  contain 'verb' in there keyword name or (default) value or\n",
      " |  description.\n",
      " |  \n",
      " |  ``CMAOptions(opts)`` returns the subset of recognized options in\n",
      " |  ``dict(opts)``.\n",
      " |  \n",
      " |  Option values can be \"written\" in a string and, when passed to `fmin`\n",
      " |  or `CMAEvolutionStrategy`, are evaluated using \"N\" and \"popsize\" as\n",
      " |  known values for dimension and population size (sample size, number\n",
      " |  of new solutions per iteration). All default option values are given\n",
      " |  as such a string.\n",
      " |  \n",
      " |  Details\n",
      " |  -------\n",
      " |  `CMAOptions` entries starting with ``tol`` are termination\n",
      " |  \"tolerances\".\n",
      " |  \n",
      " |  For `tolstagnation`, the median over the first and the second half\n",
      " |  of at least `tolstagnation` iterations are compared for both, the\n",
      " |  per-iteration best and per-iteration median function value.\n",
      " |  \n",
      " |  Example\n",
      " |  -------\n",
      " |  ::\n",
      " |  \n",
      " |      import cma\n",
      " |      cma.CMAOptions('tol')\n",
      " |  \n",
      " |  is a shortcut for ``cma.CMAOptions().match('tol')`` that returns all\n",
      " |  options that contain 'tol' in their name or description.\n",
      " |  \n",
      " |  To set an option::\n",
      " |  \n",
      " |      import cma\n",
      " |      opts = cma.CMAOptions()\n",
      " |      opts.set('tolfun', 1e-12)\n",
      " |      opts['tolx'] = 1e-11\n",
      " |  \n",
      " |  todo: this class is overly complex and should be re-written, possibly\n",
      " |  with reduced functionality.\n",
      " |  \n",
      " |  :See also: `fmin` (), `CMAEvolutionStrategy`, `_CMAParameters`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CMAOptions\n",
      " |      builtins.dict\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, key, default=None, loc=None)\n",
      " |      evaluate and return the value of option `key` on the fly, or\n",
      " |      return those options whose name or description contains `key`,\n",
      " |      case disregarded.\n",
      " |      \n",
      " |      Details\n",
      " |      -------\n",
      " |      Keys that contain `filename` are not evaluated.\n",
      " |      For ``loc==None``, `self` is used as environment\n",
      " |      but this does not define ``N``.\n",
      " |      \n",
      " |      :See: `eval()`, `evalall()`\n",
      " |  \n",
      " |  __init__(self, s=None, **kwargs)\n",
      " |      return an `CMAOptions` instance.\n",
      " |      \n",
      " |      Return default options if ``s is None and not kwargs``,\n",
      " |      or all options whose name or description contains `s`, if\n",
      " |      `s` is a (search) string (case is disregarded in the match),\n",
      " |      or with entries from dictionary `s` as options,\n",
      " |      or with kwargs as options if ``s is None``,\n",
      " |      in any of the latter cases not complemented with default options\n",
      " |      or settings.\n",
      " |      \n",
      " |      Returns: see above.\n",
      " |      \n",
      " |      Details: as several options start with ``'s'``, ``s=value`` is\n",
      " |      not valid as an option setting.\n",
      " |  \n",
      " |  check(self, options=None)\n",
      " |      check for ambiguous keys and move attributes into dict\n",
      " |  \n",
      " |  check_attributes(self, opts=None)\n",
      " |      check for attributes and moves them into the dictionary\n",
      " |  \n",
      " |  check_values(self, options=None)\n",
      " |  \n",
      " |  complement(self)\n",
      " |      add all missing options with their default values\n",
      " |  \n",
      " |  corrected_key(self, key)\n",
      " |      return the matching valid key, if ``key.lower()`` is a unique\n",
      " |      starting sequence to identify the valid key, ``else None``\n",
      " |  \n",
      " |  eval(self, key, default=None, loc=None, correct_key=True)\n",
      " |      Evaluates and sets the specified option value in\n",
      " |      environment `loc`. Many options need ``N`` to be defined in\n",
      " |      `loc`, some need `popsize`.\n",
      " |      \n",
      " |      Details\n",
      " |      -------\n",
      " |      Keys that contain 'filename' are not evaluated.\n",
      " |      For `loc` is None, the self-dict is used as environment\n",
      " |      \n",
      " |      :See: `evalall()`, `__call__`\n",
      " |  \n",
      " |  evalall(self, loc=None, defaults=None)\n",
      " |      Evaluates all option values in environment `loc`.\n",
      " |      \n",
      " |      :See: `eval()`\n",
      " |  \n",
      " |  from_namedtuple(self, t)\n",
      " |      update options from a `collections.namedtuple`.\n",
      " |      :See also: `to_namedtuple`\n",
      " |  \n",
      " |  init(self, dict_or_str, val=None, warn=True)\n",
      " |      initialize one or several options.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |          `dict_or_str`\n",
      " |              a dictionary if ``val is None``, otherwise a key.\n",
      " |              If `val` is provided `dict_or_str` must be a valid key.\n",
      " |          `val`\n",
      " |              value for key\n",
      " |      \n",
      " |      Details\n",
      " |      -------\n",
      " |      Only known keys are accepted. Known keys are in `CMAOptions.defaults()`\n",
      " |  \n",
      " |  match(self, s='')\n",
      " |      return all options that match, in the name or the description,\n",
      " |      with string `s`, case is disregarded.\n",
      " |      \n",
      " |      Example: ``cma.CMAOptions().match('verb')`` returns the verbosity\n",
      " |      options.\n",
      " |  \n",
      " |  pprint(self, linebreak=80)\n",
      " |  \n",
      " |  set(self, dic, val=None, force=False)\n",
      " |      assign versatile options.\n",
      " |      \n",
      " |      Method `CMAOptions.versatile_options` () gives the versatile\n",
      " |      options, use `init()` to set the others.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |          `dic`\n",
      " |              either a dictionary or a key. In the latter\n",
      " |              case, `val` must be provided\n",
      " |          `val`\n",
      " |              value for `key`, approximate match is sufficient\n",
      " |          `force`\n",
      " |              force setting of non-versatile options, use with caution\n",
      " |      \n",
      " |      This method will be most probably used with the ``opts`` attribute of\n",
      " |      a `CMAEvolutionStrategy` instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  defaults()\n",
      " |      return a dictionary with default option values and description\n",
      " |  \n",
      " |  versatile_options()\n",
      " |      return list of options that can be changed at any time (not\n",
      " |      only be initialized).\n",
      " |      \n",
      " |      Consider that this list might not be entirely up\n",
      " |      to date.\n",
      " |      \n",
      " |      The string ' #v ' in the default value indicates a versatile\n",
      " |      option that can be changed any time, however a string will not \n",
      " |      necessarily be evaluated again.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  settable\n",
      " |      return the subset of those options that are settable at any\n",
      " |      time.\n",
      " |      \n",
      " |      Settable options are in `versatile_options` (), but the\n",
      " |      list might be incomplete.\n",
      " |  \n",
      " |  to_namedtuple\n",
      " |      return options as const attributes of the returned object,\n",
      " |      only useful for inspection.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from builtins.dict:\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      True if the dictionary has the specified key, else False.\n",
      " |  \n",
      " |  __delitem__(self, key, /)\n",
      " |      Delete self[key].\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setitem__(self, key, value, /)\n",
      " |      Set self[key] to value.\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      D.__sizeof__() -> size of D in memory, in bytes\n",
      " |  \n",
      " |  clear(...)\n",
      " |      D.clear() -> None.  Remove all items from D.\n",
      " |  \n",
      " |  copy(...)\n",
      " |      D.copy() -> a shallow copy of D\n",
      " |  \n",
      " |  get(self, key, default=None, /)\n",
      " |      Return the value for key if key is in the dictionary, else default.\n",
      " |  \n",
      " |  items(...)\n",
      " |      D.items() -> a set-like object providing a view on D's items\n",
      " |  \n",
      " |  keys(...)\n",
      " |      D.keys() -> a set-like object providing a view on D's keys\n",
      " |  \n",
      " |  pop(...)\n",
      " |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      " |      If key is not found, d is returned if given, otherwise KeyError is raised\n",
      " |  \n",
      " |  popitem(...)\n",
      " |      D.popitem() -> (k, v), remove and return some (key, value) pair as a\n",
      " |      2-tuple; but raise KeyError if D is empty.\n",
      " |  \n",
      " |  setdefault(self, key, default=None, /)\n",
      " |      Insert key with a value of default if key is not in the dictionary.\n",
      " |      \n",
      " |      Return the value for key if key is in the dictionary, else default.\n",
      " |  \n",
      " |  update(...)\n",
      " |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
      " |      If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\n",
      " |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      " |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      " |  \n",
      " |  values(...)\n",
      " |      D.values() -> an object providing a view on D's values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from builtins.dict:\n",
      " |  \n",
      " |  fromkeys(iterable, value=None, /) from builtins.type\n",
      " |      Create a new dictionary with keys from iterable and values set to value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from builtins.dict:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from builtins.dict:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cma.CMAOptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ad64b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CMAEvolutionStrategy in module cma.evolution_strategy:\n",
      "\n",
      "class CMAEvolutionStrategy(cma.interfaces.OOOptimizer)\n",
      " |  CMAEvolutionStrategy(x0, sigma0, inopts=None)\n",
      " |  \n",
      " |  CMA-ES stochastic optimizer class with ask-and-tell interface.\n",
      " |  \n",
      " |  Calling Sequences\n",
      " |  =================\n",
      " |  \n",
      " |  - ``es = CMAEvolutionStrategy(x0, sigma0)``\n",
      " |  \n",
      " |  - ``es = CMAEvolutionStrategy(x0, sigma0, opts)``\n",
      " |  \n",
      " |  - ``es = CMAEvolutionStrategy(x0, sigma0).optimize(objective_fct)``\n",
      " |  \n",
      " |  - ::\n",
      " |  \n",
      " |      res = CMAEvolutionStrategy(x0, sigma0,\n",
      " |                              opts).optimize(objective_fct).result\n",
      " |  \n",
      " |  Arguments\n",
      " |  =========\n",
      " |  `x0`\n",
      " |      initial solution, starting point. `x0` is given as \"phenotype\"\n",
      " |      which means, if::\n",
      " |  \n",
      " |          opts = {'transformation': [transform, inverse]}\n",
      " |  \n",
      " |      is given and ``inverse is None``, the initial mean is not\n",
      " |      consistent with `x0` in that ``transform(mean)`` does not\n",
      " |      equal to `x0` unless ``transform(mean)`` equals ``mean``.\n",
      " |  `sigma0`\n",
      " |      initial standard deviation.  The problem variables should\n",
      " |      have been scaled, such that a single standard deviation\n",
      " |      on all variables is useful and the optimum is expected to\n",
      " |      lie within about `x0` +- ``3*sigma0``. Often one wants to\n",
      " |      check for solutions close to the initial point. This allows,\n",
      " |      for example, for an easier check of consistency of the\n",
      " |      objective function and its interfacing with the optimizer.\n",
      " |      In this case, a much smaller `sigma0` is advisable.\n",
      " |  `opts`\n",
      " |      options, a dictionary with optional settings,\n",
      " |      see class `CMAOptions`.\n",
      " |  \n",
      " |  Main interface / usage\n",
      " |  ======================\n",
      " |  The interface is inherited from the generic `OOOptimizer`\n",
      " |  class (see also there). An object instance is generated from::\n",
      " |  \n",
      " |      es = cma.CMAEvolutionStrategy(8 * [0.5], 0.2)\n",
      " |  \n",
      " |  The least verbose interface is via the optimize method::\n",
      " |  \n",
      " |      es.optimize(objective_func)\n",
      " |      res = es.result\n",
      " |  \n",
      " |  More verbosely, the optimization is done using the\n",
      " |  methods `stop`, `ask`, and `tell`::\n",
      " |  \n",
      " |      while not es.stop():\n",
      " |          solutions = es.ask()\n",
      " |          es.tell(solutions, [cma.ff.rosen(s) for s in solutions])\n",
      " |          es.disp()\n",
      " |      es.result_pretty()\n",
      " |  \n",
      " |  \n",
      " |  where `ask` delivers new candidate solutions and `tell` updates\n",
      " |  the `optim` instance by passing the respective function values\n",
      " |  (the objective function `cma.ff.rosen` can be replaced by any\n",
      " |  properly defined objective function, see `cma.ff` for more\n",
      " |  examples).\n",
      " |  \n",
      " |  To change an option, for example a termination condition to\n",
      " |  continue the optimization, call::\n",
      " |  \n",
      " |      es.opts.set({'tolfacupx': 1e4})\n",
      " |  \n",
      " |  The class `CMAEvolutionStrategy` also provides::\n",
      " |  \n",
      " |      (solutions, func_values) = es.ask_and_eval(objective_func)\n",
      " |  \n",
      " |  and an entire optimization can also be written like::\n",
      " |  \n",
      " |      while not es.stop():\n",
      " |          es.tell(*es.ask_and_eval(objective_func))\n",
      " |  \n",
      " |  Besides for termination criteria, in CMA-ES only the ranks of the\n",
      " |  `func_values` are relevant.\n",
      " |  \n",
      " |  Attributes and Properties\n",
      " |  =========================\n",
      " |  - `inputargs`: passed input arguments\n",
      " |  - `inopts`: passed options\n",
      " |  - `opts`: actually used options, some of them can be changed any\n",
      " |    time via ``opts.set``, see class `CMAOptions`\n",
      " |  - `popsize`: population size lambda, number of candidate\n",
      " |    solutions returned by `ask` ()\n",
      " |  - `logger`: a `CMADataLogger` instance utilized by `optimize`\n",
      " |  \n",
      " |  Examples\n",
      " |  ========\n",
      " |  Super-short example, with output shown:\n",
      " |  \n",
      " |  >>> import cma\n",
      " |  >>> # construct an object instance in 4-D, sigma0=1:\n",
      " |  >>> es = cma.CMAEvolutionStrategy(4 * [1], 1, {'seed':234})\n",
      " |  ...      # doctest: +ELLIPSIS\n",
      " |  (4_w,8)-aCMA-ES (mu_w=2.6,w_1=52%) in dimension 4 (seed=234...)\n",
      " |  \n",
      " |  and optimize the ellipsoid function\n",
      " |  \n",
      " |  >>> es.optimize(cma.ff.elli, verb_disp=1)  # doctest: +ELLIPSIS\n",
      " |  Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      " |      1      8 2.09...\n",
      " |  >>> assert len(es.result) == 8\n",
      " |  >>> assert es.result[1] < 1e-9\n",
      " |  \n",
      " |  The optimization loop can also be written explicitly:\n",
      " |  \n",
      " |  >>> es = cma.CMAEvolutionStrategy(4 * [1], 1)  # doctest: +ELLIPSIS\n",
      " |  (4_w,8)-aCMA-ES (mu_w=2.6,w_1=52%) in dimension 4 (seed=...\n",
      " |  >>> while not es.stop():\n",
      " |  ...    X = es.ask()\n",
      " |  ...    es.tell(X, [cma.ff.elli(x) for x in X])\n",
      " |  ...    es.disp()  # doctest: +ELLIPSIS\n",
      " |  Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      " |      1      8 ...\n",
      " |  \n",
      " |  achieving the same result as above.\n",
      " |  \n",
      " |  An example with lower bounds (at zero) and handling infeasible\n",
      " |  solutions:\n",
      " |  \n",
      " |  >>> import numpy as np\n",
      " |  >>> es = cma.CMAEvolutionStrategy(10 * [0.2], 0.5,\n",
      " |  ...         {'bounds': [0, np.inf]})  #doctest: +ELLIPSIS\n",
      " |  (5_w,...\n",
      " |  >>> while not es.stop():\n",
      " |  ...     fit, X = [], []\n",
      " |  ...     while len(X) < es.popsize:\n",
      " |  ...         curr_fit = None\n",
      " |  ...         while curr_fit in (None, np.NaN):\n",
      " |  ...             x = es.ask(1)[0]\n",
      " |  ...             curr_fit = cma.ff.somenan(x, cma.ff.elli) # might return np.NaN\n",
      " |  ...         X.append(x)\n",
      " |  ...         fit.append(curr_fit)\n",
      " |  ...     es.tell(X, fit)\n",
      " |  ...     es.logger.add()\n",
      " |  ...     es.disp()  #doctest: +ELLIPSIS\n",
      " |  Itera...\n",
      " |  >>>\n",
      " |  >>> assert es.result[1] < 1e-9\n",
      " |  >>> assert es.result[2] < 9000  # by internal termination\n",
      " |  >>> # es.logger.plot()  # will plot data\n",
      " |  >>> # cma.s.figshow()  # display plot window\n",
      " |  \n",
      " |  An example with user-defined transformation, in this case to realize\n",
      " |  a lower bound of 2.\n",
      " |  \n",
      " |  >>> import warnings\n",
      " |  >>> with warnings.catch_warnings(record=True) as warns:\n",
      " |  ...     es = cma.CMAEvolutionStrategy(5 * [3], 0.1,\n",
      " |  ...                 {\"transformation\": [lambda x: x**2+1.2, None],\n",
      " |  ...                  \"verbose\": -2,})\n",
      " |  >>> warns[0].message  # doctest:+ELLIPSIS\n",
      " |  UserWarning('in class GenoPheno: user defined transformations have not been tested thoroughly ()'...\n",
      " |  >>> warns[1].message  # doctest:+ELLIPSIS\n",
      " |  UserWarning('computed initial point...\n",
      " |  >>> es.optimize(cma.ff.rosen, verb_disp=0)  #doctest: +ELLIPSIS\n",
      " |  <cma...\n",
      " |  >>> assert cma.ff.rosen(es.result[0]) < 1e-7 + 5.54781521192\n",
      " |  >>> assert es.result[2] < 3300\n",
      " |  \n",
      " |  The inverse transformation is (only) necessary if the `BoundPenalty`\n",
      " |  boundary handler is used at the same time.\n",
      " |  \n",
      " |  The `CMAEvolutionStrategy` class also provides a default logger\n",
      " |  (cave: files are overwritten when the logger is used with the same\n",
      " |  filename prefix):\n",
      " |  \n",
      " |  >>> es = cma.CMAEvolutionStrategy(4 * [0.2], 0.5, {'verb_disp': 0})\n",
      " |  >>> es.logger.disp_header()  # annotate the print of disp\n",
      " |  Iterat Nfevals  function value    axis ratio maxstd  minstd\n",
      " |  >>> while not es.stop():\n",
      " |  ...     X = es.ask()\n",
      " |  ...     es.tell(X, [cma.ff.sphere(x) for x in X])\n",
      " |  ...     es.logger.add()  # log current iteration\n",
      " |  ...     es.logger.disp([-1])  # display info for last iteration   #doctest: +ELLIPSIS\n",
      " |      1  ...\n",
      " |  >>> es.logger.disp_header()\n",
      " |  Iterat Nfevals  function value    axis ratio maxstd  minstd\n",
      " |  >>> # es.logger.plot() # will make a plot\n",
      " |  \n",
      " |  Example implementing restarts with increasing popsize (IPOP):\n",
      " |  \n",
      " |  >>> bestever = cma.optimization_tools.BestSolution()\n",
      " |  >>> for lam in 10 * 2**np.arange(8):  # 10, 20, 40, 80, ..., 10 * 2**7\n",
      " |  ...     es = cma.CMAEvolutionStrategy(6 - 8 * np.random.rand(4),  # 4-D\n",
      " |  ...                                   5,  # initial std sigma0\n",
      " |  ...                                   {'popsize': lam,  # options\n",
      " |  ...                                    'verb_append': bestever.evalsall})\n",
      " |  ...     # logger = cma.CMADataLogger().register(es, append=bestever.evalsall)\n",
      " |  ...     while not es.stop():\n",
      " |  ...         X = es.ask()    # get list of new solutions\n",
      " |  ...         fit = [cma.ff.rastrigin(x) for x in X]  # evaluate each solution\n",
      " |  ...         es.tell(X, fit) # besides for termination only the ranking in fit is used\n",
      " |  ...\n",
      " |  ...         # display some output\n",
      " |  ...         # logger.add()  # add a \"data point\" to the log, writing in files\n",
      " |  ...         es.disp()  # uses option verb_disp with default 100\n",
      " |  ...\n",
      " |  ...     print('termination:', es.stop())\n",
      " |  ...     cma.s.pprint(es.best.__dict__)\n",
      " |  ...\n",
      " |  ...     bestever.update(es.best)\n",
      " |  ...\n",
      " |  ...     # show a plot\n",
      " |  ...     # logger.plot();\n",
      " |  ...     if bestever.f < 1e-8:  # global optimum was hit\n",
      " |  ...         break  #doctest: +ELLIPSIS\n",
      " |  (5_w,...\n",
      " |  >>> assert es.result[1] < 1e-8\n",
      " |  \n",
      " |  On the Rastrigin function, usually after five restarts the global\n",
      " |  optimum is located.\n",
      " |  \n",
      " |  Using the `multiprocessing` module, we can evaluate the function in\n",
      " |  parallel with a simple modification of the example (however\n",
      " |  multiprocessing seems not always reliable):\n",
      " |  \n",
      " |  >>> from cma.fitness_functions import elli  # cannot be an instance method\n",
      " |  >>> from cma.optimization_tools import EvalParallel2\n",
      " |  >>> es = cma.CMAEvolutionStrategy(22 * [0.0], 1.0, {'maxiter':10})  # doctest:+ELLIPSIS\n",
      " |  (6_w,13)-aCMA-ES (mu_w=...\n",
      " |  >>> with EvalParallel2(elli, es.popsize + 1) as eval_all:\n",
      " |  ...     while not es.stop():\n",
      " |  ...         X = es.ask()\n",
      " |  ...         es.tell(X, eval_all(X))\n",
      " |  ...         es.disp()\n",
      " |  ...         # es.logger.add()  # doctest:+ELLIPSIS\n",
      " |  Iterat...\n",
      " |  \n",
      " |  The final example shows how to resume:\n",
      " |  \n",
      " |  >>> import pickle\n",
      " |  >>>\n",
      " |  >>> es0 = cma.CMAEvolutionStrategy(12 * [0.1],  # a new instance, 12-D\n",
      " |  ...                                0.12)         # initial std sigma0\n",
      " |  ...   #doctest: +ELLIPSIS\n",
      " |  (5_w,...\n",
      " |  >>> es0.optimize(cma.ff.rosen, iterations=100)  #doctest: +ELLIPSIS\n",
      " |  I...\n",
      " |  >>> s = es0.pickle_dumps()  # return pickle.dumps(es) with safeguards\n",
      " |  >>> # save string s to file like open(filename, 'wb').write(s)\n",
      " |  >>> del es0  # let's start fresh\n",
      " |  >>> # s = open(filename, 'rb').read()  # load string s from file\n",
      " |  >>> es = pickle.loads(s)  # read back es instance from string\n",
      " |  >>> # resuming\n",
      " |  >>> es.optimize(cma.ff.rosen, verb_disp=200)  #doctest: +ELLIPSIS\n",
      " |    200 ...\n",
      " |  >>> assert es.result[2] < 15000\n",
      " |  >>> assert cma.s.Mh.vequals_approximately(es.result[0], 12 * [1], 1e-5)\n",
      " |  >>> assert len(es.result) == 8\n",
      " |  \n",
      " |  Details\n",
      " |  =======\n",
      " |  The following two enhancements are implemented, the latter is only\n",
      " |  turned on by default for very small population sizes.\n",
      " |  \n",
      " |  *Active CMA* is implemented with option ``CMA_active`` and\n",
      " |  conducts an update of the covariance matrix with negative weights.\n",
      " |  The negative update is implemented, such that positive definiteness\n",
      " |  is guarantied. A typical speed up factor (number of f-evaluations)\n",
      " |  is between 1.1 and two.\n",
      " |  \n",
      " |  References: Jastrebski and Arnold, Improving evolution strategies\n",
      " |  through active covariance matrix adaptation, CEC 2006.\n",
      " |  Hansen, The CMA evolution strategy: a tutorial, arXiv 2016.\n",
      " |  \n",
      " |  *Selective mirroring* is implemented with option ``CMA_mirrors``\n",
      " |  in the method `get_mirror` and `get_selective_mirrors`.\n",
      " |  The method `ask_and_eval` (used by `fmin`) will then sample\n",
      " |  selectively mirrored vectors within the iteration\n",
      " |  (``CMA_mirrormethod==1``). Otherwise, or if ``CMA_mirromethod==2``,\n",
      " |  selective mirrors are injected for the next iteration.\n",
      " |  In selective mirroring, only the worst solutions are mirrored. With\n",
      " |  the default small number of mirrors, *pairwise selection* (where at\n",
      " |  most one of the two mirrors contribute to the update of the\n",
      " |  distribution mean) is implicitly guarantied under selective\n",
      " |  mirroring and therefore not explicitly implemented.\n",
      " |  \n",
      " |  Update: pairwise selection for injected mirrors is also applied in the\n",
      " |  covariance matrix update: for all injected solutions, as for those from\n",
      " |  TPA, this is now implemented in that the recombination weights are\n",
      " |  constrained to be nonnegative for injected solutions in the covariance\n",
      " |  matrix (otherwise recombination weights are anyway nonnegative). This\n",
      " |  is a precaution to prevent failure when injected solutions are\n",
      " |  systematically bad (see e.g. https://github.com/CMA-ES/pycma/issues/124),\n",
      " |  but may not be \"optimal\" for mirrors.\n",
      " |  \n",
      " |  References: Brockhoff et al, PPSN 2010, Auger et al, GECCO 2011.\n",
      " |  \n",
      " |  :See also: `fmin` (), `OOOptimizer`, `CMAOptions`, `plot` (), `ask` (),\n",
      " |      `tell` (), `ask_and_eval` ()\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CMAEvolutionStrategy\n",
      " |      cma.interfaces.OOOptimizer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, x0, sigma0, inopts=None)\n",
      " |      see class `CMAEvolutionStrategy`\n",
      " |  \n",
      " |  alleviate_conditioning(self, condition=1000000000000.0)\n",
      " |      pass conditioning of `C` to linear transformation in `self.gp`.\n",
      " |      \n",
      " |      Argument `condition` defines the limit condition number above\n",
      " |      which the action is taken.\n",
      " |      \n",
      " |      Details: the action applies only if `self.gp.isidentity`. Then,\n",
      " |      the covariance matrix `C` is set (back) to identity and a\n",
      " |      respective linear transformation is \"added\" to `self.gp`.\n",
      " |  \n",
      " |  alleviate_conditioning_in_coordinates(self, condition=100000000.0)\n",
      " |      pass scaling from `C` to `sigma_vec`.\n",
      " |      \n",
      " |      As a result, `C` is a correlation matrix, i.e., all diagonal\n",
      " |      entries of `C` are `1`.\n",
      " |  \n",
      " |  ask(self, number=None, xmean=None, sigma_fac=1, gradf=None, args=(), **kwargs)\n",
      " |      get/sample new candidate solutions.\n",
      " |      \n",
      " |      Solutions are sampled from a multi-variate\n",
      " |      normal distribution and transformed to f-representation\n",
      " |      (phenotype) to be evaluated.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |          `number`\n",
      " |              number of returned solutions, by default the\n",
      " |              population size ``popsize`` (AKA ``lambda``).\n",
      " |          `xmean`\n",
      " |              distribution mean, phenotyp?\n",
      " |          `sigma_fac`\n",
      " |              multiplier for internal sample width (standard\n",
      " |              deviation)\n",
      " |          `gradf`\n",
      " |              gradient, ``len(gradf(x)) == len(x)``, if\n",
      " |              ``gradf is not None`` the third solution in the\n",
      " |              returned list is \"sampled\" in supposedly Newton\n",
      " |              direction ``np.dot(C, gradf(xmean, *args))``.\n",
      " |          `args`\n",
      " |              additional arguments passed to gradf\n",
      " |      \n",
      " |      Return\n",
      " |      ------\n",
      " |      A list of N-dimensional candidate solutions to be evaluated\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      >>> import cma\n",
      " |      >>> es = cma.CMAEvolutionStrategy([0,0,0,0], 0.3)  #doctest: +ELLIPSIS\n",
      " |      (4_w,...\n",
      " |      >>> while not es.stop() and es.best.f > 1e-6:\n",
      " |      ...     X = es.ask()  # get list of new solutions\n",
      " |      ...     fit = [cma.ff.rosen(x) for x in X]  # call fct with each solution\n",
      " |      ...     es.tell(X, fit)  # feed values\n",
      " |      \n",
      " |      :See: `ask_and_eval`, `ask_geno`, `tell`\n",
      " |  \n",
      " |  ask_and_eval(self, func, args=(), gradf=None, number=None, xmean=None, sigma_fac=1, evaluations=1, aggregation=<function median at 0x7fb28a1e8830>, kappa=1, parallel_mode=False)\n",
      " |      sample `number` solutions and evaluate them on `func`.\n",
      " |      \n",
      " |      Each solution ``s`` is resampled until\n",
      " |      ``self.is_feasible(s, func(s)) is True``.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      `func`:\n",
      " |          objective function, ``func(x)`` accepts a `numpy.ndarray`\n",
      " |          and returns a scalar ``if not parallel_mode``. Else returns a\n",
      " |          `list` of scalars from a `list` of `numpy.ndarray`.\n",
      " |      `args`:\n",
      " |          additional parameters for `func`\n",
      " |      `gradf`:\n",
      " |          gradient of objective function, ``g = gradf(x, *args)``\n",
      " |          must satisfy ``len(g) == len(x)``\n",
      " |      `number`:\n",
      " |          number of solutions to be sampled, by default\n",
      " |          population size ``popsize`` (AKA lambda)\n",
      " |      `xmean`:\n",
      " |          mean for sampling the solutions, by default ``self.mean``.\n",
      " |      `sigma_fac`:\n",
      " |          multiplier for sampling width, standard deviation, for example\n",
      " |          to get a small perturbation of solution `xmean`\n",
      " |      `evaluations`:\n",
      " |          number of evaluations for each sampled solution\n",
      " |      `aggregation`:\n",
      " |          function that aggregates `evaluations` values to\n",
      " |          as single value.\n",
      " |      `kappa`:\n",
      " |          multiplier used for the evaluation of the solutions, in\n",
      " |          that ``func(m + kappa*(x - m))`` is the f-value for ``x``.\n",
      " |      \n",
      " |      Return\n",
      " |      ------\n",
      " |      ``(X, fit)``, where\n",
      " |      \n",
      " |      - `X`: list of solutions\n",
      " |      - `fit`: list of respective function values\n",
      " |      \n",
      " |      Details\n",
      " |      -------\n",
      " |      While ``not self.is_feasible(x, func(x))`` new solutions are\n",
      " |      sampled. By default\n",
      " |      ``self.is_feasible == cma.feasible == lambda x, f: f not in (None, np.NaN)``.\n",
      " |      The argument to `func` can be freely modified within `func`.\n",
      " |      \n",
      " |      Depending on the ``CMA_mirrors`` option, some solutions are not\n",
      " |      sampled independently but as mirrors of other bad solutions. This\n",
      " |      is a simple derandomization that can save 10-30% of the\n",
      " |      evaluations in particular with small populations, for example on\n",
      " |      the cigar function.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      >>> import cma\n",
      " |      >>> x0, sigma0 = 8 * [10], 1  # 8-D\n",
      " |      >>> es = cma.CMAEvolutionStrategy(x0, sigma0)  #doctest: +ELLIPSIS\n",
      " |      (5_w,...\n",
      " |      >>> while not es.stop():\n",
      " |      ...     X, fit = es.ask_and_eval(cma.ff.elli)  # handles NaN with resampling\n",
      " |      ...     es.tell(X, fit)  # pass on fitness values\n",
      " |      ...     es.disp(20) # print every 20-th iteration  #doctest: +ELLIPSIS\n",
      " |      Iterat #Fevals...\n",
      " |      >>> print('terminated on ' + str(es.stop()))  #doctest: +ELLIPSIS\n",
      " |      terminated on ...\n",
      " |      \n",
      " |      A single iteration step can be expressed in one line, such that\n",
      " |      an entire optimization after initialization becomes::\n",
      " |      \n",
      " |          while not es.stop():\n",
      " |              es.tell(*es.ask_and_eval(cma.ff.elli))\n",
      " |  \n",
      " |  ask_geno(self, number=None, xmean=None, sigma_fac=1)\n",
      " |      get new candidate solutions in genotyp.\n",
      " |      \n",
      " |      Solutions are sampled from a multi-variate normal distribution.\n",
      " |      \n",
      " |      Arguments are\n",
      " |          `number`\n",
      " |              number of returned solutions, by default the\n",
      " |              population size `popsize` (AKA lambda).\n",
      " |          `xmean`\n",
      " |              distribution mean\n",
      " |          `sigma_fac`\n",
      " |              multiplier for internal sample width (standard\n",
      " |              deviation)\n",
      " |      \n",
      " |      `ask_geno` returns a list of N-dimensional candidate solutions\n",
      " |      in genotyp representation and is called by `ask`.\n",
      " |      \n",
      " |      Details: updates the sample distribution if needed and might\n",
      " |      change the geno-pheno transformation during this update.\n",
      " |      \n",
      " |      :See: `ask`, `ask_and_eval`\n",
      " |  \n",
      " |  disp(self, modulo=None)\n",
      " |      print current state variables in a single-line.\n",
      " |      \n",
      " |      Prints only if ``iteration_counter % modulo == 0``.\n",
      " |      \n",
      " |      :See also: `disp_annotation`.\n",
      " |  \n",
      " |  disp_annotation(self)\n",
      " |      print annotation line for `disp` ()\n",
      " |  \n",
      " |  feed_for_resume(self, X, function_values)\n",
      " |      Resume a run using the solution history.\n",
      " |      \n",
      " |      CAVEAT: this hasn't been thoroughly tested or in intensive use.\n",
      " |      \n",
      " |      Given all \"previous\" candidate solutions and their respective\n",
      " |      function values, the state of a `CMAEvolutionStrategy` object\n",
      " |      can be reconstructed from this history. This is the purpose of\n",
      " |      function `feed_for_resume`.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      `X`:\n",
      " |        (all) solution points in chronological order, phenotypic\n",
      " |        representation. The number of points must be a multiple\n",
      " |        of popsize.\n",
      " |      `function_values`:\n",
      " |        respective objective function values\n",
      " |      \n",
      " |      Details\n",
      " |      -------\n",
      " |      `feed_for_resume` can be called repeatedly with only parts of\n",
      " |      the history. The part must have the length of a multiple\n",
      " |      of the population size.\n",
      " |      `feed_for_resume` feeds the history in popsize-chunks into `tell`.\n",
      " |      The state of the random number generator might not be\n",
      " |      reconstructed, but this would be only relevant for the future.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      ::\n",
      " |      \n",
      " |          import cma\n",
      " |      \n",
      " |          # prepare\n",
      " |          (x0, sigma0) = ... # initial values from previous trial\n",
      " |          X = ... # list of generated solutions from a previous trial\n",
      " |          f = ... # respective list of f-values\n",
      " |      \n",
      " |          # resume\n",
      " |          es = cma.CMAEvolutionStrategy(x0, sigma0)\n",
      " |          es.feed_for_resume(X, f)\n",
      " |      \n",
      " |          # continue with func as objective function\n",
      " |          while not es.stop():\n",
      " |              X = es.ask()\n",
      " |              es.tell(X, [func(x) for x in X])\n",
      " |      \n",
      " |      \n",
      " |      Credits to Dirk Bueche and Fabrice Marchal for the feeding idea.\n",
      " |      \n",
      " |      :See also: class `CMAEvolutionStrategy` for a simple dump/load\n",
      " |          to resume.\n",
      " |  \n",
      " |  get_mirror(self, x, preserve_length=False)\n",
      " |      return ``pheno(self.mean - (geno(x) - self.mean))``.\n",
      " |      \n",
      " |      >>> import numpy as np, cma\n",
      " |      >>> es = cma.CMAEvolutionStrategy(np.random.randn(3), 1)  #doctest: +ELLIPSIS\n",
      " |      (3_w,...\n",
      " |      >>> x = np.random.randn(3)\n",
      " |      >>> assert cma.utilities.math.Mh.vequals_approximately(es.mean - (x - es.mean), es.get_mirror(x, preserve_length=True))\n",
      " |      >>> x = es.ask(1)[0]\n",
      " |      >>> vals = (es.get_mirror(x) - es.mean) / (x - es.mean)\n",
      " |      >>> assert cma.utilities.math.Mh.equals_approximately(sum(vals), len(vals) * vals[0])\n",
      " |      \n",
      " |      TODO: this implementation is yet experimental.\n",
      " |      \n",
      " |      TODO: this implementation includes geno-pheno transformation,\n",
      " |      however in general GP-transformation should be separated from\n",
      " |      specific code.\n",
      " |      \n",
      " |      Selectively mirrored sampling improves to a moderate extend but\n",
      " |      overadditively with active CMA for quite understandable reasons.\n",
      " |      \n",
      " |      Optimal number of mirrors are suprisingly small: 1,2,3 for\n",
      " |      maxlam=7,13,20 where 3,6,10 are the respective maximal possible\n",
      " |      mirrors that must be clearly suboptimal.\n",
      " |  \n",
      " |  get_selective_mirrors(self, number=None)\n",
      " |      get mirror genotypic directions from worst solutions.\n",
      " |      \n",
      " |      Details:\n",
      " |      \n",
      " |      To be called after the mean has been updated.\n",
      " |      \n",
      " |      Takes the last ``number=sp.lam_mirr`` entries in the\n",
      " |      ``self.pop[self.fit.idx]`` as solutions to be mirrored.\n",
      " |      \n",
      " |      Do not take a mirror if it is suspected to stem from a\n",
      " |      previous mirror in order to not go endlessly back and forth.\n",
      " |  \n",
      " |  inject(self, solutions, force=None)\n",
      " |      inject list of one or several genotypic solution(s).\n",
      " |      \n",
      " |      This is the preferable way to pass outside proposal solutions\n",
      " |      into `CMAEvolutionStrategy`. Passing (bad) solutions directly\n",
      " |      via `tell` is likely to fail when ``CMA_active is True`` as by\n",
      " |      default.\n",
      " |      \n",
      " |      Unless ``force is True``, the `solutions` are used as direction\n",
      " |      relative to the distribution mean to compute a new candidate\n",
      " |      solution returned in method `ask_geno` which in turn is used in\n",
      " |      method `ask`. Even when ``force is True``, the update in `tell`\n",
      " |      takes later care of possibly trimming the update vector.\n",
      " |      \n",
      " |      `inject` is to be called before `ask` or after `tell` and can be\n",
      " |      called repeatedly.\n",
      " |      \n",
      " |      >>> import cma\n",
      " |      >>> es = cma.CMAEvolutionStrategy(4 * [1], 2)  #doctest: +ELLIPSIS\n",
      " |      (4_w,...\n",
      " |      >>> while not es.stop():\n",
      " |      ...     es.inject([4 * [0.0]])\n",
      " |      ...     X = es.ask()\n",
      " |      ...     if es.countiter == 0:\n",
      " |      ...         assert X[0][0] == X[0][1]  # injected sol. is on the diagonal\n",
      " |      ...     es.tell(X, [cma.ff.sphere(x) for x in X])\n",
      " |      \n",
      " |      Details: injected solutions are not used in the \"active\" update which\n",
      " |      would decrease variance in the covariance matrix in this direction.\n",
      " |  \n",
      " |  mahalanobis_norm(self, dx)\n",
      " |      return Mahalanobis norm based on the current sample\n",
      " |      distribution.\n",
      " |      \n",
      " |      The norm is based on Covariance matrix ``C`` times ``sigma**2``,\n",
      " |      and includes ``sigma_vec``. The expected Mahalanobis distance to\n",
      " |      the sample mean is about ``sqrt(dimension)``.\n",
      " |      \n",
      " |      Argument\n",
      " |      --------\n",
      " |      A *genotype* difference `dx`.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      >>> import cma, numpy\n",
      " |      >>> es = cma.CMAEvolutionStrategy(numpy.ones(10), 1)  #doctest: +ELLIPSIS\n",
      " |      (5_w,...\n",
      " |      >>> xx = numpy.random.randn(2, 10)\n",
      " |      >>> d = es.mahalanobis_norm(es.gp.geno(xx[0]-xx[1]))\n",
      " |      \n",
      " |      `d` is the distance \"in\" the true sample distribution,\n",
      " |      sampled points have a typical distance of ``sqrt(2*es.N)``,\n",
      " |      where ``es.N`` is the dimension, and an expected distance of\n",
      " |      close to ``sqrt(N)`` to the sample mean. In the example,\n",
      " |      `d` is the Euclidean distance, because C = I and sigma = 1.\n",
      " |  \n",
      " |  manage_plateaus(self, sigma_fac=1.5, sample_fraction=0.5)\n",
      " |      increase `sigma` by `sigma_fac` in case of a plateau.\n",
      " |      \n",
      " |      A plateau is assumed to be present if the best sample and\n",
      " |      ``popsize * sample_fraction``-th best sample have the same\n",
      " |      fitness.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> import cma\n",
      " |      >>> def f(X):\n",
      " |      ...     return (len(X) - 1) * [1] + [2]\n",
      " |      >>> es = cma.CMAEvolutionStrategy(4 * [0], 5, {'verbose':-9, 'tolflatfitness':1e4})\n",
      " |      >>> while not es.stop():\n",
      " |      ...     X = es.ask()\n",
      " |      ...     es.tell(X, f(X))\n",
      " |      ...     es.manage_plateaus()\n",
      " |      >>> if es.sigma < 1.5**es.countiter: print((es.sigma, 1.5**es.countiter, es.stop()))\n",
      " |  \n",
      " |  pickle_dumps(self)\n",
      " |      return ``pickle.dumps(self)``,\n",
      " |      \n",
      " |      if necessary remove unpickleable (and also unnecessary) local\n",
      " |      function reference beforehand.\n",
      " |      \n",
      " |      The resulting `bytes` string-object can be saved to a file like::\n",
      " |      \n",
      " |          import cma\n",
      " |          es = cma.CMAEvolutionStrategy(3 * [1], 1)\n",
      " |          es.optimize(cma.ff.elli, iterations=22)\n",
      " |          filename = 'es-pickle-test'\n",
      " |          open(filename, 'wb').write(es.pickle_dumps())\n",
      " |      \n",
      " |      and recovered like::\n",
      " |      \n",
      " |          import pickle\n",
      " |          es = pickle.load(open(filename, 'rb'))\n",
      " |      \n",
      " |      or::\n",
      " |      \n",
      " |          es = pickle.loads(open(filename, 'rb').read())\n",
      " |          es.optimize(cma.ff.elli, iterations=22)  # continue optimizing\n",
      " |  \n",
      " |  plot(self, *args, **kwargs)\n",
      " |      plot current state variables using `matplotlib`.\n",
      " |      \n",
      " |      Details: calls `self.logger.plot`.\n",
      " |  \n",
      " |  random_rescale_to_mahalanobis(self, x)\n",
      " |      change `x` like for injection, all on genotypic level\n",
      " |  \n",
      " |  repair_genotype(self, x, copy_if_changed=False)\n",
      " |      make sure that solutions fit to the sample distribution.\n",
      " |      \n",
      " |      This interface is versatile and likely to change.\n",
      " |      \n",
      " |      The Mahalanobis distance ``x - self.mean`` is clipping at\n",
      " |      ``N**0.5 + 2 * N / (N + 2)``, but the specific repair\n",
      " |      mechanism may change in future.\n",
      " |  \n",
      " |  result_pretty(self, number_of_runs=0, time_str=None, fbestever=None)\n",
      " |      pretty print result.\n",
      " |      \n",
      " |      Returns `result` of ``self``.\n",
      " |  \n",
      " |  stop(self, check=True, ignore_list=(), check_in_same_iteration=False, get_value=None)\n",
      " |      return the termination status as dictionary.\n",
      " |      \n",
      " |      With ``check == False``, the termination conditions are not checked\n",
      " |      and the status might not reflect the current situation.\n",
      " |      ``check_on_same_iteration == False`` (new) does not re-check during\n",
      " |      the same iteration. When termination options are manually changed,\n",
      " |      it must be set to `True` to advance afterwards.\n",
      " |      ``stop().clear()`` removes the currently active termination\n",
      " |      conditions.\n",
      " |      \n",
      " |      As a convenience feature, keywords in `ignore_list` are removed from\n",
      " |      the conditions.\n",
      " |      \n",
      " |      If `get_value` is set to a condition name (not the empty string),\n",
      " |      `stop` does not update the termination dictionary but returns the\n",
      " |      measured value that would be compared to the threshold. This only\n",
      " |      works for some conditions, like 'tolx'. If the condition name is\n",
      " |      not known or cannot be computed, `None` is returned and no warning\n",
      " |      is issued.\n",
      " |      \n",
      " |      Testing `get_value` functionality:\n",
      " |      \n",
      " |      >>> import cma\n",
      " |      >>> es = cma.CMAEvolutionStrategy(2 * [1], 1e4, {'verbose': -9})\n",
      " |      >>> with warnings.catch_warnings(record=True) as w:\n",
      " |      ...     es.stop(get_value='tolx')  # triggers zero iteration warning\n",
      " |      ...     assert len(w) == 1, [str(wi) for wi in w]\n",
      " |      >>> es = es.optimize(cma.ff.sphere, iterations=4)\n",
      " |      >>> assert 1e3 < es.stop(get_value='tolx') < 1e4, es.stop(get_value='tolx')\n",
      " |      >>> assert es.stop() == {}\n",
      " |      >>> assert es.stop(get_value='catch 22') is None\n",
      " |  \n",
      " |  tell(self, solutions, function_values, check_points=None, copy=False)\n",
      " |      pass objective function values to prepare for next\n",
      " |      iteration. This core procedure of the CMA-ES algorithm updates\n",
      " |      all state variables, in particular the two evolution paths, the\n",
      " |      distribution mean, the covariance matrix and a step-size.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      `solutions`\n",
      " |          list or array of candidate solution points (of\n",
      " |          type `numpy.ndarray`), most presumably before\n",
      " |          delivered by method `ask()` or `ask_and_eval()`.\n",
      " |      `function_values`\n",
      " |          list or array of objective function values\n",
      " |          corresponding to the respective points. Beside for termination\n",
      " |          decisions, only the ranking of values in `function_values`\n",
      " |          is used.\n",
      " |      `check_points`\n",
      " |          If ``check_points is None``, only solutions that are not generated\n",
      " |          by `ask()` are possibly clipped (recommended). ``False`` does not clip\n",
      " |          any solution (not recommended).\n",
      " |          If ``True``, clips solutions that realize long steps (i.e. also\n",
      " |          those that are unlikely to be generated with `ask()`). `check_points`\n",
      " |          can be a list of indices to be checked in solutions.\n",
      " |      `copy`\n",
      " |          ``solutions`` can be modified in this routine, if ``copy is False``\n",
      " |      \n",
      " |      Details\n",
      " |      -------\n",
      " |      `tell()` updates the parameters of the multivariate\n",
      " |      normal search distribution, namely covariance matrix and\n",
      " |      step-size and updates also the attributes ``countiter`` and\n",
      " |      ``countevals``. To check the points for consistency is quadratic\n",
      " |      in the dimension (like sampling points).\n",
      " |      \n",
      " |      Bugs\n",
      " |      ----\n",
      " |      The effect of changing the solutions delivered by `ask()`\n",
      " |      depends on whether boundary handling is applied. With boundary\n",
      " |      handling, modifications are disregarded. This is necessary to\n",
      " |      apply the default boundary handling that uses unrepaired\n",
      " |      solutions but might change in future.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      \n",
      " |      >>> import cma\n",
      " |      >>> func = cma.ff.sphere  # choose objective function\n",
      " |      >>> es = cma.CMAEvolutionStrategy(np.random.rand(2) / 3, 1.5)\n",
      " |      ... # doctest:+ELLIPSIS\n",
      " |      (3_...\n",
      " |      >>> while not es.stop():\n",
      " |      ...    X = es.ask()\n",
      " |      ...    es.tell(X, [func(x) for x in X])\n",
      " |      >>> es.result  # result is a `namedtuple` # doctest:+ELLIPSIS\n",
      " |      CMAEvolutionStrategyResult(xbest=array([...\n",
      " |      \n",
      " |      :See: class `CMAEvolutionStrategy`, `ask`, `ask_and_eval`, `fmin`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  condition_number\n",
      " |      condition number of the statistical-model sampler.\n",
      " |      \n",
      " |      Details: neither encoding/decoding from `sigma_vec`-scaling nor\n",
      " |      `gp`-transformation are taken into account for this computation.\n",
      " |  \n",
      " |  isotropic_mean_shift\n",
      " |      normalized last mean shift, under random selection N(0,I)\n",
      " |      \n",
      " |      distributed.\n",
      " |      \n",
      " |      Caveat: while it is finite and close to sqrt(n) under random\n",
      " |      selection, the length of the normalized mean shift under\n",
      " |      *systematic* selection (e.g. on a linear function) tends to\n",
      " |      infinity for mueff -> infty. Hence it must be used with great\n",
      " |      care for large mueff.\n",
      " |  \n",
      " |  popsize\n",
      " |      number of samples by default returned by `ask` ()\n",
      " |  \n",
      " |  result\n",
      " |      return a `CMAEvolutionStrategyResult` `namedtuple`.\n",
      " |      \n",
      " |      :See: `cma.evolution_strategy.CMAEvolutionStrategyResult`\n",
      " |          or try ``help(...result)`` on the ``result`` property\n",
      " |          of an `CMAEvolutionStrategy` instance or on the\n",
      " |          `CMAEvolutionStrategyResult` instance itself.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from cma.interfaces.OOOptimizer:\n",
      " |  \n",
      " |  initialize(self)\n",
      " |      (re-)set to the initial state\n",
      " |  \n",
      " |  optimize(self, objective_fct, maxfun=None, iterations=None, min_iterations=1, args=(), verb_disp=None, callback=None, n_jobs=0, **kwargs)\n",
      " |      find minimizer of ``objective_fct``.\n",
      " |      \n",
      " |      CAVEAT: the return value for `optimize` has changed to ``self``,\n",
      " |      allowing for a call like::\n",
      " |      \n",
      " |          solver = OOOptimizer(x0).optimize(f)\n",
      " |      \n",
      " |      and investigate the state of the solver.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      \n",
      " |      ``objective_fct``: f(x: array_like) -> float\n",
      " |          function be to minimized\n",
      " |      ``maxfun``: number\n",
      " |          maximal number of function evaluations\n",
      " |      ``iterations``: number\n",
      " |          number of (maximal) iterations, while ``not self.stop()``,\n",
      " |          it can be useful to conduct only one iteration at a time.\n",
      " |      ``min_iterations``: number\n",
      " |          minimal number of iterations, even if ``not self.stop()``\n",
      " |      ``args``: sequence_like\n",
      " |          arguments passed to ``objective_fct``\n",
      " |      ``verb_disp``: number\n",
      " |          print to screen every ``verb_disp`` iteration, if `None`\n",
      " |          the value from ``self.logger`` is \"inherited\", if\n",
      " |          available.\n",
      " |      ``callback``: callable or list of callables\n",
      " |          callback function called like ``callback(self)`` or\n",
      " |          a list of call back functions called in the same way. If\n",
      " |          available, ``self.logger.add`` is added to this list.\n",
      " |          TODO: currently there is no way to prevent this other than\n",
      " |          changing the code of `_prepare_callback_list`.\n",
      " |      ``n_jobs=0``: number of processes to be acquired for\n",
      " |          multiprocessing to parallelize calls to `objective_fct`.\n",
      " |          Must be >1 to expect any speed-up or `None` or `-1`, which\n",
      " |          both default to the number of available CPUs. The default\n",
      " |          ``n_jobs=0`` avoids the use of multiprocessing altogether.\n",
      " |      \n",
      " |      ``return self``, that is, the `OOOptimizer` instance.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      >>> import cma\n",
      " |      >>> es = cma.CMAEvolutionStrategy(7 * [0.1], 0.1\n",
      " |      ...              ).optimize(cma.ff.rosen, verb_disp=100)\n",
      " |      ...                   #doctest: +ELLIPSIS\n",
      " |      (4_w,9)-aCMA-ES (mu_w=2.8,w_1=49%) in dimension 7 (seed=...)\n",
      " |      Iterat #Fevals   function value  axis ratio  sigma ...\n",
      " |          1      9 ...\n",
      " |          2     18 ...\n",
      " |          3     27 ...\n",
      " |        100    900 ...\n",
      " |      >>> cma.s.Mh.vequals_approximately(es.result[0], 7 * [1], 1e-5)\n",
      " |      True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from cma.interfaces.OOOptimizer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cma.CMAEvolutionStrategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3bfad04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trongduong/opt/anaconda3/envs/QML/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in arctanh\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([       nan, 0.34701545])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_length = 2\n",
    "bounds = torch.tensor([[-1.0] * encoding_length, [1.0] * encoding_length])\n",
    "bounds.tolist()\n",
    "\n",
    "np.arctanh(np.random.normal(loc=0.5,scale=0.4,size=encoding_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2b29b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AdaptSigma': 'True  # or False or any CMAAdaptSigmaBase class e.g. CMAAdaptSigmaTPA, CMAAdaptSigmaCSA',\n",
       " 'CMA_active': 'True  # negative update, conducted after the original update',\n",
       " 'CMA_active_injected': '0  #v weight multiplier for negative weights of injected solutions',\n",
       " 'CMA_cmean': '1  # learning rate for the mean value',\n",
       " 'CMA_const_trace': 'False  # normalize trace, 1, True, \"arithm\", \"geom\", \"aeig\", \"geig\" are valid',\n",
       " 'CMA_diagonal': '0*100*N/popsize**0.5  # nb of iterations with diagonal covariance matrix, True for always',\n",
       " 'CMA_eigenmethod': 'np.linalg.eigh  # or cma.utilities.math.eig or pygsl.eigen.eigenvectors',\n",
       " 'CMA_elitist': 'False  #v or \"initial\" or True, elitism likely impairs global search performance',\n",
       " 'CMA_injections_threshold_keep_len': '1  #v keep length if Mahalanobis length is below the given relative threshold',\n",
       " 'CMA_mirrors': 'popsize < 6  # values <0.5 are interpreted as fraction, values >1 as numbers (rounded), for `True` about 0.16 is used',\n",
       " 'CMA_mirrormethod': '2  # 0=unconditional, 1=selective, 2=selective with delay',\n",
       " 'CMA_mu': 'None  # parents selection parameter, default is popsize // 2',\n",
       " 'CMA_on': '1  # multiplier for all covariance matrix updates',\n",
       " 'CMA_sampler': 'None  # a class or instance that implements the interface of `cma.interfaces.StatisticalModelSamplerWithZeroMeanBaseClass`',\n",
       " 'CMA_sampler_options': '{}  # options passed to `CMA_sampler` class init as keyword arguments',\n",
       " 'CMA_rankmu': '1.0  # multiplier for rank-mu update learning rate of covariance matrix',\n",
       " 'CMA_rankone': '1.0  # multiplier for rank-one update learning rate of covariance matrix',\n",
       " 'CMA_recombination_weights': 'None  # a list, see class RecombinationWeights, overwrites CMA_mu and popsize options',\n",
       " 'CMA_dampsvec_fac': 'np.Inf  # tentative and subject to changes, 0.5 would be a \"default\" damping for sigma vector update',\n",
       " 'CMA_dampsvec_fade': '0.1  # tentative fading out parameter for sigma vector update',\n",
       " 'CMA_teststds': 'None  # factors for non-isotropic initial distr. of C, mainly for test purpose, see CMA_stds for production',\n",
       " 'CMA_stds': 'None  # multipliers for sigma0 in each coordinate, not represented in C, makes scaling_of_variables obsolete',\n",
       " 'CSA_dampfac': '1  #v positive multiplier for step-size damping, 0.3 is close to optimal on the sphere',\n",
       " 'CSA_damp_mueff_exponent': '0.5  # zero would mean no dependency of damping on mueff, useful with CSA_disregard_length option',\n",
       " 'CSA_disregard_length': 'False  #v True is untested, also changes respective parameters',\n",
       " 'CSA_clip_length_value': 'None  #v poorly tested, [0, 0] means const length N**0.5, [-1, 1] allows a variation of +- N/(N+2), etc.',\n",
       " 'CSA_squared': 'False  #v use squared length for sigma-adaptation ',\n",
       " 'BoundaryHandler': 'BoundTransform  # or BoundPenalty, unused when ``bounds in (None, [None, None])``',\n",
       " 'bounds': '[None, None]  # lower (=bounds[0]) and upper domain boundaries, each a scalar or a list/vector',\n",
       " 'conditioncov_alleviate': '[1e8, 1e12]  # when to alleviate the condition in the coordinates and in main axes',\n",
       " 'eval_final_mean': 'True  # evaluate the final mean, which is a favorite return candidate',\n",
       " 'fixed_variables': 'None  # dictionary with index-value pairs like {0:1.1, 2:0.1} that are not optimized',\n",
       " 'ftarget': '-inf  #v target function value, minimization',\n",
       " 'integer_variables': '[]  # index list, invokes basic integer handling: prevent std dev to become too small in the given variables',\n",
       " 'is_feasible': 'is_feasible  #v a function that computes feasibility, by default lambda x, f: f not in (None, np.NaN)',\n",
       " 'maxfevals': 'inf  #v maximum number of function evaluations',\n",
       " 'maxiter': '100 + 150 * (N+3)**2 // popsize**0.5  #v maximum number of iterations',\n",
       " 'mean_shift_line_samples': 'False #v sample two new solutions colinear to previous mean shift',\n",
       " 'mindx': '0  #v minimal std in any arbitrary direction, cave interference with tol*',\n",
       " 'minstd': '0  #v minimal std (scalar or vector) in any coordinate direction, cave interference with tol*',\n",
       " 'maxstd': 'inf  #v maximal std in any coordinate direction',\n",
       " 'pc_line_samples': 'False #v one line sample along the evolution path pc',\n",
       " 'popsize': '4 + 3 * np.log(N)  # population size, AKA lambda, int(popsize) is the number of new solution per iteration',\n",
       " 'popsize_factor': '1  # multiplier for popsize, convenience option to increase default popsize',\n",
       " 'randn': 'np.random.randn  #v randn(lam, N) must return an np.array of shape (lam, N), see also cma.utilities.math.randhss',\n",
       " 'scaling_of_variables': 'None  # deprecated, rather use fitness_transformations.ScaleCoordinates instead (or possibly CMA_stds). Scale for each variable in that effective_sigma0 = sigma0*scaling. Internally the variables are divided by scaling_of_variables and sigma is unchanged, default is `np.ones(N)`',\n",
       " 'seed': 'time  # random number seed for `numpy.random`; `None` and `0` equate to `time`, `np.nan` means \"do nothing\", see also option \"randn\"',\n",
       " 'signals_filename': 'cma_signals.in  # read versatile options from this file (use `None` or `\"\"` for no file) which contains a single options dict, e.g. ``{\"timeout\": 0}`` to stop, string-values are evaluated, e.g. \"np.inf\" is valid',\n",
       " 'termination_callback': '[]  #v a function or list of functions returning True for termination, called in `stop` with `self` as argument, could be abused for side effects',\n",
       " 'timeout': 'inf  #v stop if timeout seconds are exceeded, the string \"2.5 * 60**2\" evaluates to 2 hours and 30 minutes',\n",
       " 'tolconditioncov': '1e14  #v stop if the condition of the covariance matrix is above `tolconditioncov`',\n",
       " 'tolfacupx': '1e3  #v termination when step-size increases by tolfacupx (diverges). That is, the initial step-size was chosen far too small and better solutions were found far away from the initial solution x0',\n",
       " 'tolupsigma': '1e20  #v sigma/sigma0 > tolupsigma * max(eivenvals(C)**0.5) indicates \"creeping behavior\" with usually minor improvements',\n",
       " 'tolflatfitness': '1  #v iterations tolerated with flat fitness before termination',\n",
       " 'tolfun': '1e-11  #v termination criterion: tolerance in function value, quite useful',\n",
       " 'tolfunhist': '1e-12  #v termination criterion: tolerance in function value history',\n",
       " 'tolfunrel': '0  #v termination criterion: relative tolerance in function value: Delta f current < tolfunrel * (median0 - median_min)',\n",
       " 'tolstagnation': 'int(100 + 100 * N**1.5 / popsize)  #v termination if no improvement over tolstagnation iterations',\n",
       " 'tolx': '1e-11  #v termination criterion: tolerance in x-changes',\n",
       " 'transformation': 'None  # depreciated, use cma.fitness_transformations.FitnessTransformation instead.\\n            [t0, t1] are two mappings, t0 transforms solutions from CMA-representation to f-representation (tf_pheno),\\n            t1 is the (optional) back transformation, see class GenoPheno',\n",
       " 'typical_x': 'None  # used with scaling_of_variables',\n",
       " 'updatecovwait': 'None  #v number of iterations without distribution update, name is subject to future changes',\n",
       " 'verbose': '3  #v verbosity e.g. of initial/final message, -1 is very quiet, -9 maximally quiet, may not be fully implemented',\n",
       " 'verb_append': '0  # initial evaluation counter, if append, do not overwrite output files',\n",
       " 'verb_disp': '100  #v verbosity: display console output every verb_disp iteration',\n",
       " 'verb_filenameprefix': 'outcmaes/  # output path and filenames prefix',\n",
       " 'verb_log': '1  #v verbosity: write data to files every verb_log iteration, writing can be time critical on fast to evaluate functions',\n",
       " 'verb_log_expensive': 'N * (N <= 50)  # allow to execute eigendecomposition for logging every verb_log_expensive iteration, 0 or False for never',\n",
       " 'verb_plot': '0  #v in fmin(): plot() is called every verb_plot iteration',\n",
       " 'verb_time': 'True  #v output timings on console',\n",
       " 'vv': '{}  #? versatile set or dictionary for hacking purposes, value found in self.opts[\"vv\"]'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cma.CMAOptions.defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b487bc07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25_w,50)-aCMA-ES (mu_w=14.0,w_1=14%) in dimension 2 (seed=334130, Thu Jan 27 23:51:23 2022)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "torch.Size([50, 2]) torch.Size([50]) (50,)\n",
      "tensor([0.2327, 0.0193])\n",
      "-1.9955536127090454\n"
     ]
    }
   ],
   "source": [
    "import cma\n",
    "import numpy as np\n",
    "\n",
    "# get initial condition for CMAES in numpy form\n",
    "# note that CMAES expects a different shape (no explicit q-batch dimension)\n",
    "x0 = np.random.normal(loc=0.5,scale=0.4,size=2)\n",
    "\n",
    "# create the CMA-ES optimizer\n",
    "es = cma.CMAEvolutionStrategy(\n",
    "    x0=x0,\n",
    "    sigma0=0.2,\n",
    "    #inopts={\"popsize\": 128, \"bounds\": bounds.tolist()},\n",
    "    inopts={\"popsize\": 50, \"maxiter\":100}\n",
    ")\n",
    "\n",
    "# speed up things by telling pytorch not to generate a compute graph in the background\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Run the optimization loop using the ask/tell interface -- this uses \n",
    "    # PyCMA's default settings, see the PyCMA documentation for how to modify these\n",
    "    while not es.stop():\n",
    "        xs = es.ask()  # as for new points to evaluate\n",
    "        # convert to Tensor for evaluating the acquisition function\n",
    "        X = torch.tensor(xs, device=X.device, dtype=X.dtype)\n",
    "        # evaluate the acquisition function (optimizer assumes we're minimizing)\n",
    "        Y = - UCB(X.unsqueeze(-2))  # acquisition functions require an explicit q-batch dimension\n",
    "        y = Y.view(-1).double().numpy()  # convert result to numpy array\n",
    "        print(X.shape, Y.shape, y.shape)\n",
    "        #print(y)\n",
    "        es.tell(xs, y)  # return the result to the optimizer\n",
    "\n",
    "# convert result back to a torch tensor\n",
    "best_x = torch.from_numpy(es.best.x).to(X)\n",
    "\n",
    "print(best_x)\n",
    "print(es.best.f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6651e4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CMAEvolutionStrategyResult(xbest=array([0.23287301, 0.01928219]), fbest=-1.995552659034729, evals_best=1427, evaluations=11000, iterations=220, xfavorite=array([0.23278461, 0.0193827 ]), stds=array([5.28270410e-10, 7.90330536e-10]), stop={'tolfunhist': 1e-12})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223bb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d2ff782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9955530166625977"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.best.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfc73444",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [0] at entry 0 and [4] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/km/wpxhny5j6h7c_prrd3x7j1mc0000gn/T/ipykernel_82148/1585672575.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [0] at entry 0 and [4] at entry 1"
     ]
    }
   ],
   "source": [
    "candidates = torch.tensor([]*4)\n",
    "x = torch.tensor([1,2,3,4])\n",
    "torch.stack((candidates,x),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5cc3670d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ops = 10\n",
    "np.linspace(0,10, 2*num_ops+1)[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48d0f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 5\n",
    "\n",
    "bounds = torch.stack([-torch.ones(d), torch.ones(d)])\n",
    "\n",
    "train_X = bounds[0] + (bounds[1] - bounds[0]) * torch.rand(50, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29de5489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1.],\n",
       "       [-1.,  1.],\n",
       "       [-1.,  1.],\n",
       "       [-1.,  1.],\n",
       "       [-1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(zip(bounds[0], bounds[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d639aff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "x = torch.from_numpy(a).unsqueeze(-1)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML",
   "language": "python",
   "name": "qml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
